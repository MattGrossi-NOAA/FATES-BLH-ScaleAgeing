{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d2016ee2",
    "outputId": "9687b6eb-5b00-48b8-b113-c07edc6ce59e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aotia\\anaconda3\\envs\\aging\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#@title imports\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data.dataset import Dataset  # For custom datasets\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import torchvision.models as models\n",
    "from tqdm import tqdm\n",
    "from torch.hub import load_state_dict_from_url\n",
    "from torchvision import models\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellView": "form",
    "id": "JltlZFIBjbZo",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#@title loss\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def get_one_hot(label, num_classes):\n",
    "    batch_size = label.shape[0]\n",
    "    onehot_label = torch.zeros((batch_size, num_classes))\n",
    "    onehot_label = onehot_label.scatter_(1, label.unsqueeze(1).detach().cpu(), 1)\n",
    "    onehot_label = (onehot_label.type(torch.FloatTensor)).to(label.device)\n",
    "    return onehot_label\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "\n",
    "    def __init__(self, weight=None,\n",
    "                 gamma=2., reduction='mean'):\n",
    "        nn.Module.__init__(self)\n",
    "        self.weight = weight\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, input_tensor, target_tensor):\n",
    "        log_prob = F.log_softmax(input_tensor, dim=-1)\n",
    "        prob = torch.exp(log_prob)\n",
    "        return F.nll_loss(\n",
    "            ((1 - prob) ** self.gamma) * log_prob,\n",
    "            target_tensor,\n",
    "            weight=self.weight,\n",
    "            reduction = self.reduction\n",
    "        )\n",
    "\n",
    "class FocalLoss2(nn.Module):\n",
    "\n",
    "    def __init__(self, weight=None,\n",
    "                 gamma=2., reduction='mean'):\n",
    "        nn.Module.__init__(self)\n",
    "        self.weight = weight\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "        self.num_classes = 5\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, input_tensor, target_tensor):\n",
    "        eps = 1e-6\n",
    "        label = get_one_hot(target_tensor, self.num_classes)\n",
    "        #p = self.sigmoid(input_tensor)\n",
    "        p = torch.clamp(self.sigmoid(input_tensor), min=eps, max=1-eps)\n",
    "        focal_weights = torch.pow((1-p)*label + p * (1-label), self.gamma)\n",
    "        loss = F.binary_cross_entropy_with_logits(input_tensor, label, reduction = 'none') * focal_weights\n",
    "        loss = (loss ).sum() / input_tensor.shape[0]\n",
    "        return loss\n",
    "\n",
    "class CBFocalLoss(nn.Module):\n",
    "\n",
    "    def __init__(self, weight=None,\n",
    "                 gamma=2., beta = 0.999, reduction='mean'):\n",
    "        nn.Module.__init__(self)\n",
    "        self.weight = weight\n",
    "        self.gamma = gamma\n",
    "        self.beta = beta\n",
    "        self.reduction = reduction\n",
    "        self.classlist = [1.0, 176.0, 911.0, 215.0, 41.0]#[75, 1414, 905, 242, 84]\n",
    "        self.num_classes = 5\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.class_balanced_weight = np.array([(1-self.beta)/(1- self.beta ** N) for N in self.classlist])\n",
    "        self.class_balanced_weight = torch.FloatTensor(self.class_balanced_weight / np.sum(self.class_balanced_weight) * self.num_classes*10).to(\"cuda\")\n",
    "\n",
    "    def forward(self, input_tensor, target_tensor):\n",
    "        eps = 1e-6\n",
    "        weight = (self.class_balanced_weight[target_tensor]).to(\"cuda\")\n",
    "        label = get_one_hot(target_tensor, self.num_classes)\n",
    "        p = torch.clamp(self.sigmoid(input_tensor), min=eps, max=1-eps)\n",
    "        focal_weights = torch.pow((1-p)*label + p * (1-label), self.gamma)\n",
    "        loss = F.binary_cross_entropy_with_logits(input_tensor, label, reduction = 'none') * focal_weights\n",
    "        loss = (loss * weight.view(-1, 1)).sum() / input_tensor.shape[0]\n",
    "        return loss\n",
    "\n",
    "class CBCrossEntropy(nn.Module):\n",
    "\n",
    "    def __init__(self, weight=None,\n",
    "                 beta = 0.999, reduction='mean'):\n",
    "        nn.Module.__init__(self)\n",
    "        self.weight = weight\n",
    "        self.beta = beta\n",
    "        self.reduction = reduction\n",
    "        self.classlist = [75, 1414, 905, 242, 84]\n",
    "        self.num_classes = 5\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.class_balanced_weight = np.array([(1-self.beta)/(1- self.beta ** N) for N in self.classlist])\n",
    "        self.class_balanced_weight = torch.FloatTensor(self.class_balanced_weight / np.sum(self.class_balanced_weight) * self.num_classes).to(\"cuda\")\n",
    "\n",
    "    def forward(self, input_tensor, target_tensor):\n",
    "        eps = 1e-6\n",
    "        weights = (self.class_balanced_weight).to(\"cuda\")\n",
    "\n",
    "        loss = F.cross_entropy(input_tensor, target_tensor, weight=weights)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "cellView": "form",
    "id": "826c523f"
   },
   "outputs": [],
   "source": [
    "#@title dataset\n",
    "class FishDataset(Dataset):\n",
    "    def __init__(self, csv_path, dataset_dir, transform=None):\n",
    "        # Read the csv file\n",
    "        self.data_info = pd.read_csv(csv_path, header=0)\n",
    "\n",
    "        # Get the directory dataset images\n",
    "        self.dataset_dir = dataset_dir\n",
    "\n",
    "        # Get the transform methods\n",
    "        self.transforms = transform\n",
    "\n",
    "\n",
    "        # Image Name\n",
    "        self.image_name = np.asarray(self.data_info.iloc[:, 2])\n",
    "\n",
    "\n",
    "        # Otolith length\n",
    "        self.length = np.asarray(self.data_info.iloc[:, 6])\n",
    "\n",
    "        # Otolith weight\n",
    "        self.wt = np.asarray(self.data_info.iloc[:, 7])\n",
    "\n",
    "        # Month\n",
    "        self.month = np.asarray(self.data_info.iloc[:, 4])\n",
    "\n",
    "        # Fish Age\n",
    "        self.age = np.asarray(self.data_info.iloc[:, 8])\n",
    "\n",
    "        print(len(self.age), len(self.image_name))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_info.index)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        #img_path = os.path.join(self.dataset_dir, str(self.image_name[index]) + '.jpg')\n",
    "        #image = Image.open(img_path)\n",
    "        wt_l_m = torch.tensor([(self.wt[index] - 163)/(82), (self.length[index] - 211)/ (35.5), (self.month[index]-7.4)/(1.9)])\n",
    "        if(self.age[index] < 5):\n",
    "          label_age = self.age[index]\n",
    "        else:\n",
    "          label_age = 4\n",
    "        #label = torch.from_numpy(np.array(label_age))\n",
    "\n",
    "        #if self.transforms:\n",
    "        #    image = self.transforms(image)\n",
    "\n",
    "        return (wt_l_m,wt_l_m) , label_age\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "53ede8f0",
    "outputId": "72f301da-6bde-4c1e-c593-01422810530d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3330 3330\n",
      "3330 3330\n",
      "3330 3330\n",
      "967 967\n",
      "499 499\n"
     ]
    }
   ],
   "source": [
    "#@title load data\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "data_dir = 'F:/Scales/Atlantic Menhaden'\n",
    "train_csv_path = os.path.join(data_dir, 'Atlantic_Menhaden_Train_Data.csv')\n",
    "test_csv_path = os.path.join(data_dir, 'Atlantic_Menhaden_Test_Data.csv')\n",
    "val_csv_path = os.path.join(data_dir, 'Atlantic_Menhaden_Val_Data.csv')\n",
    "gulf_train_csv_path = os.path.join(data_dir,\"Gulf Menhaden/gulf_train.csv\")\n",
    "gulf_test_csv_path = os.path.join(data_dir,\"Gulf Menhaden/gulf_test.csv\")\n",
    "img_dir = os.path.join(data_dir, 'Cropped Images')\n",
    "img_dir_gulf = os.path.join(data_dir, 'Gulf Menhaden/Gulf Cropped')\n",
    "\n",
    "\n",
    "data_transforms_train = transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize(299),\n",
    "            transforms.RandomCrop(299),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomRotation(degrees = 20),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "data_transforms = transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize(299),\n",
    "            transforms.CenterCrop(299),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "train_dataset = FishDataset(train_csv_path, img_dir, data_transforms_train)\n",
    "class_weight = np.array([1.0/75.0, 1.0/1414, 1.0/905, 1.0/242, 1.0/84])*1414\n",
    "samples_weight = np.array([class_weight[min(t,4)] for t in train_dataset.age])\n",
    "samples_weight = torch.from_numpy(samples_weight)\n",
    "samples_weigth = samples_weight.double()\n",
    "#print(samples_weight)\n",
    "sampler = torch.utils.data.sampler.WeightedRandomSampler(samples_weight, len(FishDataset(train_csv_path, img_dir, data_transforms_train)))\n",
    "\n",
    "\n",
    "#train_loader = DataLoader(FishDataset(gulf_train_csv_path, img_dir_gulf, data_transforms_train), batch_size=32, shuffle=True, drop_last=True)\n",
    "#train_loader = DataLoader(FishDataset(train_csv_path, img_dir, data_transforms_train), batch_size=32, shuffle=True, drop_last=True)\n",
    "#test_loader = DataLoader(FishDataset(gulf_test_csv_path, img_dir_gulf, data_transforms), batch_size=32, shuffle=True, drop_last=True)\n",
    "#val_loader = DataLoader(FishDataset(gulf_train_csv_path, img_dir_gulf, data_transforms), batch_size=3, shuffle=True, drop_last=True)\n",
    "\n",
    "train_loader = DataLoader(FishDataset(train_csv_path, img_dir, data_transforms_train), batch_size=24, shuffle=True, drop_last=False)\n",
    "#train_loader = DataLoader(FishDataset(train_csv_path, img_dir, data_transforms_train), batch_size=32, shuffle=True, drop_last=True)\n",
    "test_loader = DataLoader(FishDataset(test_csv_path, img_dir, data_transforms), batch_size=24, shuffle=True, drop_last=False)\n",
    "val_loader = DataLoader(FishDataset(val_csv_path, img_dir, data_transforms), batch_size=24, shuffle=True, drop_last=False)\n",
    "\n",
    "dataloaders = {\"train\": train_loader, \"val\": val_loader, \"test\": test_loader}\n",
    "dataset_sizes = {x: len(dataloaders[x].dataset) for x in [\"train\", \"val\", \"test\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "92528e95",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#@title Inception Network\n",
    "from collections import namedtuple\n",
    "import warnings\n",
    "from torch import nn, Tensor\n",
    "import torch.nn.functional as F\n",
    "from typing import Callable, Any, Optional, Tuple, List\n",
    "\n",
    "__all__ = ['Inception3', 'inception_v3', 'InceptionOutputs', '_InceptionOutputs']\n",
    "\n",
    "\n",
    "model_urls = {\n",
    "    # Inception v3 ported from TensorFlow\n",
    "    'inception_v3_google': 'https://download.pytorch.org/models/inception_v3_google-0cc3c7bd.pth',\n",
    "}\n",
    "\n",
    "InceptionOutputs = namedtuple('InceptionOutputs', ['logits', 'aux_logits'])\n",
    "InceptionOutputs.__annotations__ = {'logits': Tensor, 'aux_logits': Optional[Tensor]}\n",
    "\n",
    "# Script annotations failed with _GoogleNetOutputs = namedtuple ...\n",
    "# _InceptionOutputs set here for backwards compat\n",
    "_InceptionOutputs = InceptionOutputs\n",
    "\n",
    "def inception_v3_new(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> \"Inception3\":\n",
    "    r\"\"\"Inception v3 model architecture from\n",
    "    `\"Rethinking the Inception Architecture for Computer Vision\" <http://arxiv.org/abs/1512.00567>`_.\n",
    "    The required minimum input size of the model is 75x75.\n",
    "\n",
    "    .. note::\n",
    "        **Important**: In contrast to the other models the inception_v3 expects tensors with a size of\n",
    "        N x 3 x 299 x 299, so ensure your images are sized accordingly.\n",
    "\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "        aux_logits (bool): If True, add an auxiliary branch that can improve training.\n",
    "            Default: *True*\n",
    "        transform_input (bool): If True, preprocesses the input according to the method with which it\n",
    "            was trained on ImageNet. Default: *False*\n",
    "    \"\"\"\n",
    "    if pretrained:\n",
    "        if 'transform_input' not in kwargs:\n",
    "            kwargs['transform_input'] = True\n",
    "        if 'aux_logits' in kwargs:\n",
    "            original_aux_logits = kwargs['aux_logits']\n",
    "            kwargs['aux_logits'] = True\n",
    "        else:\n",
    "            original_aux_logits = True\n",
    "        kwargs['init_weights'] = False  # we are loading weights from a pretrained model\n",
    "        model = Inception3(**kwargs)\n",
    "        state_dict = load_state_dict_from_url(model_urls['inception_v3_google'],\n",
    "                                              progress=progress)\n",
    "        model.load_state_dict(state_dict)\n",
    "        if not original_aux_logits:\n",
    "            model.aux_logits = False\n",
    "            model.AuxLogits = None\n",
    "        return model\n",
    "\n",
    "    return Inception3(**kwargs)\n",
    "\n",
    "\n",
    "class Inception3(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_classes: int = 5,\n",
    "        aux_logits: bool = True,\n",
    "        transform_input: bool = False,\n",
    "        inception_blocks: Optional[List[Callable[..., nn.Module]]] = None,\n",
    "        init_weights: Optional[bool] = None\n",
    "    ) -> None:\n",
    "        super(Inception3, self).__init__()\n",
    "        if inception_blocks is None:\n",
    "            inception_blocks = [\n",
    "                BasicConv2d, InceptionA, InceptionB, InceptionC,\n",
    "                InceptionD, InceptionE, InceptionAux\n",
    "            ]\n",
    "        if init_weights is None:\n",
    "            warnings.warn('The default weight initialization of inception_v3 will be changed in future releases of '\n",
    "                          'torchvision. If you wish to keep the old behavior (which leads to long initialization times'\n",
    "                          ' due to scipy/scipy#11299), please set init_weights=True.', FutureWarning)\n",
    "            init_weights = True\n",
    "        assert len(inception_blocks) == 7\n",
    "        conv_block = inception_blocks[0]\n",
    "        inception_a = inception_blocks[1]\n",
    "        inception_b = inception_blocks[2]\n",
    "        inception_c = inception_blocks[3]\n",
    "        inception_d = inception_blocks[4]\n",
    "        inception_e = inception_blocks[5]\n",
    "        inception_aux = inception_blocks[6]\n",
    "\n",
    "        self.aux_logits = aux_logits\n",
    "        self.transform_input = transform_input\n",
    "        self.Conv2d_1a_3x3 = conv_block(3, 32, kernel_size=3, stride=2)\n",
    "        self.Conv2d_2a_3x3 = conv_block(32, 32, kernel_size=3)\n",
    "        self.Conv2d_2b_3x3 = conv_block(32, 64, kernel_size=3, padding=1)\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        self.Conv2d_3b_1x1 = conv_block(64, 80, kernel_size=1)\n",
    "        self.Conv2d_4a_3x3 = conv_block(80, 192, kernel_size=3)\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        self.Mixed_5b = inception_a(192, pool_features=32)\n",
    "        self.Mixed_5c = inception_a(256, pool_features=64)\n",
    "        self.Mixed_5d = inception_a(288, pool_features=64)\n",
    "        self.Mixed_6a = inception_b(288)\n",
    "        self.Mixed_6b = inception_c(768, channels_7x7=128)\n",
    "        self.Mixed_6c = inception_c(768, channels_7x7=160)\n",
    "        self.Mixed_6d = inception_c(768, channels_7x7=160)\n",
    "        self.Mixed_6e = inception_c(768, channels_7x7=192)\n",
    "        self.AuxLogits: Optional[nn.Module] = None\n",
    "        if aux_logits:\n",
    "            self.AuxLogits = inception_aux(768, num_classes)\n",
    "        self.Mixed_7a = inception_d(768)\n",
    "        self.Mixed_7b = inception_e(1280)\n",
    "        self.Mixed_7c = inception_e(2048)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.dropout = nn.Dropout()\n",
    "        self.fc_2_1 = nn.Linear(3, 64)\n",
    "        self.fc3 = nn.Linear(2048, 64)\n",
    "        self.fc2 = nn.Linear(64+64, num_classes)\n",
    "        if init_weights:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "                    stddev = float(m.stddev) if hasattr(m, 'stddev') else 0.1  # type: ignore\n",
    "                    torch.nn.init.trunc_normal_(m.weight, mean=0.0, std=stddev, a=-2, b=2)\n",
    "                elif isinstance(m, nn.BatchNorm2d):\n",
    "                    nn.init.constant_(m.weight, 1)\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def _transform_input(self, x: Tensor) -> Tensor:\n",
    "        if self.transform_input:\n",
    "            x_ch0 = torch.unsqueeze(x[:, 0], 1) * (0.229 / 0.5) + (0.485 - 0.5) / 0.5\n",
    "            x_ch1 = torch.unsqueeze(x[:, 1], 1) * (0.224 / 0.5) + (0.456 - 0.5) / 0.5\n",
    "            x_ch2 = torch.unsqueeze(x[:, 2], 1) * (0.225 / 0.5) + (0.406 - 0.5) / 0.5\n",
    "            x = torch.cat((x_ch0, x_ch1, x_ch2), 1)\n",
    "        return x\n",
    "\n",
    "    def get_feature_map(self, x: Tensor, layer):\n",
    "        x = self.Conv2d_1a_3x3(x)\n",
    "        # N x 32 x 149 x 149\n",
    "        x = self.Conv2d_2a_3x3(x)\n",
    "        # N x 32 x 147 x 147\n",
    "        x = self.Conv2d_2b_3x3(x)\n",
    "        if(layer == 0):\n",
    "          return x\n",
    "        # N x 64 x 147 x 147\n",
    "        x = self.maxpool1(x)\n",
    "        # N x 64 x 73 x 73\n",
    "        x = self.Conv2d_3b_1x1(x)\n",
    "        # N x 80 x 73 x 73\n",
    "        x = self.Conv2d_4a_3x3(x)\n",
    "        if(layer == 1):\n",
    "          return x\n",
    "        return x\n",
    "\n",
    "    def _forward(self, x: Tensor, x2: Tensor) -> Tuple[Tensor, Optional[Tensor]]:\n",
    "        # N x 3 x 299 x 299\n",
    "        x = self.Conv2d_1a_3x3(x)\n",
    "        # N x 32 x 149 x 149\n",
    "        x = self.Conv2d_2a_3x3(x)\n",
    "        # N x 32 x 147 x 147\n",
    "        x = self.Conv2d_2b_3x3(x)\n",
    "        # N x 64 x 147 x 147\n",
    "        x = self.maxpool1(x)\n",
    "        # N x 64 x 73 x 73\n",
    "        x = self.Conv2d_3b_1x1(x)\n",
    "        # N x 80 x 73 x 73\n",
    "        x = self.Conv2d_4a_3x3(x)\n",
    "        # N x 192 x 71 x 71\n",
    "        x = self.maxpool2(x)\n",
    "        # N x 192 x 35 x 35\n",
    "        x = self.Mixed_5b(x)\n",
    "        # N x 256 x 35 x 35\n",
    "        x = self.Mixed_5c(x)\n",
    "        # N x 288 x 35 x 35\n",
    "        x = self.Mixed_5d(x)\n",
    "        # N x 288 x 35 x 35\n",
    "        x = self.Mixed_6a(x)\n",
    "        # N x 768 x 17 x 17\n",
    "        x = self.Mixed_6b(x)\n",
    "        # N x 768 x 17 x 17\n",
    "        x = self.Mixed_6c(x)\n",
    "        # N x 768 x 17 x 17\n",
    "        x = self.Mixed_6d(x)\n",
    "        # N x 768 x 17 x 17\n",
    "        x = self.Mixed_6e(x)\n",
    "        # N x 768 x 17 x 17\n",
    "        aux: Optional[Tensor] = None\n",
    "\n",
    "        if self.AuxLogits is not None:\n",
    "            if self.training:\n",
    "                aux = self.AuxLogits(x, x2)\n",
    "        # N x 768 x 17 x 17\n",
    "        x = self.Mixed_7a(x)\n",
    "        # N x 1280 x 8 x 8\n",
    "        x = self.Mixed_7b(x)\n",
    "        # N x 2048 x 8 x 8\n",
    "        x = self.Mixed_7c(x)\n",
    "        # N x 2048 x 8 x 8\n",
    "        # Adaptive average pooling\n",
    "        x = self.avgpool(x)\n",
    "        # N x 2048 x 1 x 1\n",
    "        x = self.dropout(x)\n",
    "        # N x 2048 x 1 x 1\n",
    "\n",
    "        x2 = F.relu(self.fc_2_1(x2))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc3(x)\n",
    "        x = torch.cat([x, x2], dim = 1)\n",
    "\n",
    "\n",
    "        # N x 2056\n",
    "        x = self.fc2(x)\n",
    "        # N x 1000 (num_classes)\n",
    "        return x, aux\n",
    "\n",
    "    def get_fea(self, x: Tensor, x2: Tensor) -> Tuple[Tensor, Optional[Tensor]]:\n",
    "        # N x 3 x 299 x 299\n",
    "        x = self.Conv2d_1a_3x3(x)\n",
    "        # N x 32 x 149 x 149\n",
    "        x = self.Conv2d_2a_3x3(x)\n",
    "        # N x 32 x 147 x 147\n",
    "        x = self.Conv2d_2b_3x3(x)\n",
    "        # N x 64 x 147 x 147\n",
    "        x = self.maxpool1(x)\n",
    "        # N x 64 x 73 x 73\n",
    "        x = self.Conv2d_3b_1x1(x)\n",
    "        # N x 80 x 73 x 73\n",
    "        x = self.Conv2d_4a_3x3(x)\n",
    "        # N x 192 x 71 x 71\n",
    "        x = self.maxpool2(x)\n",
    "        # N x 192 x 35 x 35\n",
    "        x = self.Mixed_5b(x)\n",
    "        # N x 256 x 35 x 35\n",
    "        x = self.Mixed_5c(x)\n",
    "        # N x 288 x 35 x 35\n",
    "        x = self.Mixed_5d(x)\n",
    "        # N x 288 x 35 x 35\n",
    "        x = self.Mixed_6a(x)\n",
    "        # N x 768 x 17 x 17\n",
    "        x = self.Mixed_6b(x)\n",
    "        # N x 768 x 17 x 17\n",
    "        x = self.Mixed_6c(x)\n",
    "        # N x 768 x 17 x 17\n",
    "        x = self.Mixed_6d(x)\n",
    "        # N x 768 x 17 x 17\n",
    "        x = self.Mixed_6e(x)\n",
    "        # N x 768 x 17 x 17\n",
    "        aux: Optional[Tensor] = None\n",
    "\n",
    "        if self.AuxLogits is not None:\n",
    "            if self.training:\n",
    "                aux = self.AuxLogits(x, x2)\n",
    "        # N x 768 x 17 x 17\n",
    "        x = self.Mixed_7a(x)\n",
    "        # N x 1280 x 8 x 8\n",
    "        x = self.Mixed_7b(x)\n",
    "        # N x 2048 x 8 x 8\n",
    "        x = self.Mixed_7c(x)\n",
    "        # N x 2048 x 8 x 8\n",
    "        # Adaptive average pooling\n",
    "        x = self.avgpool(x)\n",
    "        # N x 2048 x 1 x 1\n",
    "        x = self.dropout(x)\n",
    "        # N x 2048 x 1 x 1\n",
    "\n",
    "        x2 = F.relu(self.fc_2_1(x2))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc3(x)\n",
    "        fea = torch.cat([x, x2], dim = 1)\n",
    "\n",
    "\n",
    "        # N x 2056\n",
    "        x = self.fc2(fea)\n",
    "        # N x 1000 (num_classes)\n",
    "        return x, fea\n",
    "\n",
    "    @torch.jit.unused\n",
    "    def eager_outputs(self, x: Tensor, aux: Optional[Tensor]) -> InceptionOutputs:\n",
    "        if self.training and self.aux_logits:\n",
    "            return InceptionOutputs(x, aux)\n",
    "        else:\n",
    "            return x  # type: ignore[return-value]\n",
    "\n",
    "    def forward(self, x: Tensor, x2: Tensor) -> InceptionOutputs:\n",
    "        x = self._transform_input(x)\n",
    "        x, aux = self._forward(x, x2)\n",
    "        aux_defined = self.training and self.aux_logits\n",
    "        if torch.jit.is_scripting():\n",
    "            if not aux_defined:\n",
    "                warnings.warn(\"Scripted Inception3 always returns Inception3 Tuple\")\n",
    "            return InceptionOutputs(x, aux)\n",
    "        else:\n",
    "            return self.eager_outputs(x, aux)\n",
    "\n",
    "\n",
    "class InceptionA(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        pool_features: int,\n",
    "        conv_block: Optional[Callable[..., nn.Module]] = None\n",
    "    ) -> None:\n",
    "        super(InceptionA, self).__init__()\n",
    "        if conv_block is None:\n",
    "            conv_block = BasicConv2d\n",
    "        self.branch1x1 = conv_block(in_channels, 64, kernel_size=1)\n",
    "\n",
    "        self.branch5x5_1 = conv_block(in_channels, 48, kernel_size=1)\n",
    "        self.branch5x5_2 = conv_block(48, 64, kernel_size=5, padding=2)\n",
    "\n",
    "        self.branch3x3dbl_1 = conv_block(in_channels, 64, kernel_size=1)\n",
    "        self.branch3x3dbl_2 = conv_block(64, 96, kernel_size=3, padding=1)\n",
    "        self.branch3x3dbl_3 = conv_block(96, 96, kernel_size=3, padding=1)\n",
    "\n",
    "        self.branch_pool = conv_block(in_channels, pool_features, kernel_size=1)\n",
    "\n",
    "    def _forward(self, x: Tensor) -> List[Tensor]:\n",
    "        branch1x1 = self.branch1x1(x)\n",
    "\n",
    "        branch5x5 = self.branch5x5_1(x)\n",
    "        branch5x5 = self.branch5x5_2(branch5x5)\n",
    "\n",
    "        branch3x3dbl = self.branch3x3dbl_1(x)\n",
    "        branch3x3dbl = self.branch3x3dbl_2(branch3x3dbl)\n",
    "        branch3x3dbl = self.branch3x3dbl_3(branch3x3dbl)\n",
    "\n",
    "        branch_pool = F.avg_pool2d(x, kernel_size=3, stride=1, padding=1)\n",
    "        branch_pool = self.branch_pool(branch_pool)\n",
    "\n",
    "        outputs = [branch1x1, branch5x5, branch3x3dbl, branch_pool]\n",
    "        return outputs\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        outputs = self._forward(x)\n",
    "        return torch.cat(outputs, 1)\n",
    "\n",
    "\n",
    "class InceptionB(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        conv_block: Optional[Callable[..., nn.Module]] = None\n",
    "    ) -> None:\n",
    "        super(InceptionB, self).__init__()\n",
    "        if conv_block is None:\n",
    "            conv_block = BasicConv2d\n",
    "        self.branch3x3 = conv_block(in_channels, 384, kernel_size=3, stride=2)\n",
    "\n",
    "        self.branch3x3dbl_1 = conv_block(in_channels, 64, kernel_size=1)\n",
    "        self.branch3x3dbl_2 = conv_block(64, 96, kernel_size=3, padding=1)\n",
    "        self.branch3x3dbl_3 = conv_block(96, 96, kernel_size=3, stride=2)\n",
    "\n",
    "    def _forward(self, x: Tensor) -> List[Tensor]:\n",
    "        branch3x3 = self.branch3x3(x)\n",
    "\n",
    "        branch3x3dbl = self.branch3x3dbl_1(x)\n",
    "        branch3x3dbl = self.branch3x3dbl_2(branch3x3dbl)\n",
    "        branch3x3dbl = self.branch3x3dbl_3(branch3x3dbl)\n",
    "\n",
    "        branch_pool = F.max_pool2d(x, kernel_size=3, stride=2)\n",
    "\n",
    "        outputs = [branch3x3, branch3x3dbl, branch_pool]\n",
    "        return outputs\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        outputs = self._forward(x)\n",
    "        return torch.cat(outputs, 1)\n",
    "\n",
    "\n",
    "class InceptionC(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        channels_7x7: int,\n",
    "        conv_block: Optional[Callable[..., nn.Module]] = None\n",
    "    ) -> None:\n",
    "        super(InceptionC, self).__init__()\n",
    "        if conv_block is None:\n",
    "            conv_block = BasicConv2d\n",
    "        self.branch1x1 = conv_block(in_channels, 192, kernel_size=1)\n",
    "\n",
    "        c7 = channels_7x7\n",
    "        self.branch7x7_1 = conv_block(in_channels, c7, kernel_size=1)\n",
    "        self.branch7x7_2 = conv_block(c7, c7, kernel_size=(1, 7), padding=(0, 3))\n",
    "        self.branch7x7_3 = conv_block(c7, 192, kernel_size=(7, 1), padding=(3, 0))\n",
    "\n",
    "        self.branch7x7dbl_1 = conv_block(in_channels, c7, kernel_size=1)\n",
    "        self.branch7x7dbl_2 = conv_block(c7, c7, kernel_size=(7, 1), padding=(3, 0))\n",
    "        self.branch7x7dbl_3 = conv_block(c7, c7, kernel_size=(1, 7), padding=(0, 3))\n",
    "        self.branch7x7dbl_4 = conv_block(c7, c7, kernel_size=(7, 1), padding=(3, 0))\n",
    "        self.branch7x7dbl_5 = conv_block(c7, 192, kernel_size=(1, 7), padding=(0, 3))\n",
    "\n",
    "        self.branch_pool = conv_block(in_channels, 192, kernel_size=1)\n",
    "\n",
    "    def _forward(self, x: Tensor) -> List[Tensor]:\n",
    "        branch1x1 = self.branch1x1(x)\n",
    "\n",
    "        branch7x7 = self.branch7x7_1(x)\n",
    "        branch7x7 = self.branch7x7_2(branch7x7)\n",
    "        branch7x7 = self.branch7x7_3(branch7x7)\n",
    "\n",
    "        branch7x7dbl = self.branch7x7dbl_1(x)\n",
    "        branch7x7dbl = self.branch7x7dbl_2(branch7x7dbl)\n",
    "        branch7x7dbl = self.branch7x7dbl_3(branch7x7dbl)\n",
    "        branch7x7dbl = self.branch7x7dbl_4(branch7x7dbl)\n",
    "        branch7x7dbl = self.branch7x7dbl_5(branch7x7dbl)\n",
    "\n",
    "        branch_pool = F.avg_pool2d(x, kernel_size=3, stride=1, padding=1)\n",
    "        branch_pool = self.branch_pool(branch_pool)\n",
    "\n",
    "        outputs = [branch1x1, branch7x7, branch7x7dbl, branch_pool]\n",
    "        return outputs\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        outputs = self._forward(x)\n",
    "        return torch.cat(outputs, 1)\n",
    "\n",
    "\n",
    "class InceptionD(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        conv_block: Optional[Callable[..., nn.Module]] = None\n",
    "    ) -> None:\n",
    "        super(InceptionD, self).__init__()\n",
    "        if conv_block is None:\n",
    "            conv_block = BasicConv2d\n",
    "        self.branch3x3_1 = conv_block(in_channels, 192, kernel_size=1)\n",
    "        self.branch3x3_2 = conv_block(192, 320, kernel_size=3, stride=2)\n",
    "\n",
    "        self.branch7x7x3_1 = conv_block(in_channels, 192, kernel_size=1)\n",
    "        self.branch7x7x3_2 = conv_block(192, 192, kernel_size=(1, 7), padding=(0, 3))\n",
    "        self.branch7x7x3_3 = conv_block(192, 192, kernel_size=(7, 1), padding=(3, 0))\n",
    "        self.branch7x7x3_4 = conv_block(192, 192, kernel_size=3, stride=2)\n",
    "\n",
    "    def _forward(self, x: Tensor) -> List[Tensor]:\n",
    "        branch3x3 = self.branch3x3_1(x)\n",
    "        branch3x3 = self.branch3x3_2(branch3x3)\n",
    "\n",
    "        branch7x7x3 = self.branch7x7x3_1(x)\n",
    "        branch7x7x3 = self.branch7x7x3_2(branch7x7x3)\n",
    "        branch7x7x3 = self.branch7x7x3_3(branch7x7x3)\n",
    "        branch7x7x3 = self.branch7x7x3_4(branch7x7x3)\n",
    "\n",
    "        branch_pool = F.max_pool2d(x, kernel_size=3, stride=2)\n",
    "        outputs = [branch3x3, branch7x7x3, branch_pool]\n",
    "        return outputs\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        outputs = self._forward(x)\n",
    "        return torch.cat(outputs, 1)\n",
    "\n",
    "\n",
    "class InceptionE(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        conv_block: Optional[Callable[..., nn.Module]] = None\n",
    "    ) -> None:\n",
    "        super(InceptionE, self).__init__()\n",
    "        if conv_block is None:\n",
    "            conv_block = BasicConv2d\n",
    "        self.branch1x1 = conv_block(in_channels, 320, kernel_size=1)\n",
    "\n",
    "        self.branch3x3_1 = conv_block(in_channels, 384, kernel_size=1)\n",
    "        self.branch3x3_2a = conv_block(384, 384, kernel_size=(1, 3), padding=(0, 1))\n",
    "        self.branch3x3_2b = conv_block(384, 384, kernel_size=(3, 1), padding=(1, 0))\n",
    "\n",
    "        self.branch3x3dbl_1 = conv_block(in_channels, 448, kernel_size=1)\n",
    "        self.branch3x3dbl_2 = conv_block(448, 384, kernel_size=3, padding=1)\n",
    "        self.branch3x3dbl_3a = conv_block(384, 384, kernel_size=(1, 3), padding=(0, 1))\n",
    "        self.branch3x3dbl_3b = conv_block(384, 384, kernel_size=(3, 1), padding=(1, 0))\n",
    "\n",
    "        self.branch_pool = conv_block(in_channels, 192, kernel_size=1)\n",
    "\n",
    "    def _forward(self, x: Tensor) -> List[Tensor]:\n",
    "        branch1x1 = self.branch1x1(x)\n",
    "\n",
    "        branch3x3 = self.branch3x3_1(x)\n",
    "        branch3x3 = [\n",
    "            self.branch3x3_2a(branch3x3),\n",
    "            self.branch3x3_2b(branch3x3),\n",
    "        ]\n",
    "        branch3x3 = torch.cat(branch3x3, 1)\n",
    "\n",
    "        branch3x3dbl = self.branch3x3dbl_1(x)\n",
    "        branch3x3dbl = self.branch3x3dbl_2(branch3x3dbl)\n",
    "        branch3x3dbl = [\n",
    "            self.branch3x3dbl_3a(branch3x3dbl),\n",
    "            self.branch3x3dbl_3b(branch3x3dbl),\n",
    "        ]\n",
    "        branch3x3dbl = torch.cat(branch3x3dbl, 1)\n",
    "\n",
    "        branch_pool = F.avg_pool2d(x, kernel_size=3, stride=1, padding=1)\n",
    "        branch_pool = self.branch_pool(branch_pool)\n",
    "\n",
    "        outputs = [branch1x1, branch3x3, branch3x3dbl, branch_pool]\n",
    "        return outputs\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        outputs = self._forward(x)\n",
    "        return torch.cat(outputs, 1)\n",
    "\n",
    "\n",
    "class InceptionAux(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        num_classes: int,\n",
    "        conv_block: Optional[Callable[..., nn.Module]] = None\n",
    "    ) -> None:\n",
    "        super(InceptionAux, self).__init__()\n",
    "        if conv_block is None:\n",
    "            conv_block = BasicConv2d\n",
    "        self.conv0 = conv_block(in_channels, 128, kernel_size=1)\n",
    "        self.conv1 = conv_block(128, 768, kernel_size=5)\n",
    "        self.conv1.stddev = 0.01  # type: ignore[assignment]\n",
    "        self.fc2 = nn.Linear(768 + 3, num_classes)\n",
    "        self.fc2.stddev = 0.001  # type: ignore[assignment]\n",
    "        self.fc_2_1 = nn.Linear(3, 3)\n",
    "\n",
    "    def forward(self, x: Tensor, x2: Tensor) -> Tensor:\n",
    "        x2 = F.relu(self.fc_2_1(x2))\n",
    "        # N x 768 x 17 x 17\n",
    "        x = F.avg_pool2d(x, kernel_size=5, stride=3)\n",
    "        # N x 768 x 5 x 5\n",
    "        x = self.conv0(x)\n",
    "        # N x 128 x 5 x 5\n",
    "        x = self.conv1(x)\n",
    "        # N x 768 x 1 x 1\n",
    "        # Adaptive average pooling\n",
    "        x = F.adaptive_avg_pool2d(x, (1, 1))\n",
    "        # N x 768 x 1 x 1\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = torch.cat([x, x2], dim = 1)\n",
    "        # N x 768\n",
    "        x = self.fc2(x)\n",
    "        # N x 1000\n",
    "        return x\n",
    "\n",
    "\n",
    "class BasicConv2d(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        **kwargs: Any\n",
    "    ) -> None:\n",
    "        super(BasicConv2d, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, bias=False, **kwargs)\n",
    "        self.bn = nn.BatchNorm2d(out_channels, eps=0.001)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        return F.relu(x, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Inception Merge\n",
    "from collections import namedtuple\n",
    "import warnings\n",
    "from torch import nn, Tensor\n",
    "import torch.nn.functional as F\n",
    "from typing import Callable, Any, Optional, Tuple, List\n",
    "\n",
    "__all__ = ['Inception3', 'inception_v3', 'InceptionOutputs', '_InceptionOutputs']\n",
    "\n",
    "\n",
    "model_urls = {\n",
    "    # Inception v3 ported from TensorFlow\n",
    "    'inception_v3_google': 'https://download.pytorch.org/models/inception_v3_google-0cc3c7bd.pth',\n",
    "}\n",
    "\n",
    "InceptionOutputs = namedtuple('InceptionOutputs', ['logits', 'aux_logits'])\n",
    "InceptionOutputs.__annotations__ = {'logits': Tensor, 'aux_logits': Optional[Tensor]}\n",
    "\n",
    "# Script annotations failed with _GoogleNetOutputs = namedtuple ...\n",
    "# _InceptionOutputs set here for backwards compat\n",
    "_InceptionOutputs = InceptionOutputs\n",
    "\n",
    "def inception_v3_merge(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> \"Inception3\":\n",
    "    r\"\"\"Inception v3 model architecture from\n",
    "    `\"Rethinking the Inception Architecture for Computer Vision\" <http://arxiv.org/abs/1512.00567>`_.\n",
    "    The required minimum input size of the model is 75x75.\n",
    "\n",
    "    .. note::\n",
    "        **Important**: In contrast to the other models the inception_v3 expects tensors with a size of\n",
    "        N x 3 x 299 x 299, so ensure your images are sized accordingly.\n",
    "\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "        aux_logits (bool): If True, add an auxiliary branch that can improve training.\n",
    "            Default: *True*\n",
    "        transform_input (bool): If True, preprocesses the input according to the method with which it\n",
    "            was trained on ImageNet. Default: *False*\n",
    "    \"\"\"\n",
    "    if pretrained:\n",
    "        if 'transform_input' not in kwargs:\n",
    "            kwargs['transform_input'] = True\n",
    "        if 'aux_logits' in kwargs:\n",
    "            original_aux_logits = kwargs['aux_logits']\n",
    "            kwargs['aux_logits'] = True\n",
    "        else:\n",
    "            original_aux_logits = True\n",
    "        kwargs['init_weights'] = False  # we are loading weights from a pretrained model\n",
    "        model = Inception3(**kwargs)\n",
    "        state_dict = load_state_dict_from_url(model_urls['inception_v3_google'],\n",
    "                                              progress=progress)\n",
    "        model.load_state_dict(state_dict)\n",
    "        if not original_aux_logits:\n",
    "            model.aux_logits = False\n",
    "            model.AuxLogits = None\n",
    "        return model\n",
    "\n",
    "    return Inception3(**kwargs)\n",
    "\n",
    "\n",
    "class Inception3(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_classes: int = 5,\n",
    "        aux_logits: bool = True,\n",
    "        transform_input: bool = False,\n",
    "        inception_blocks: Optional[List[Callable[..., nn.Module]]] = None,\n",
    "        init_weights: Optional[bool] = None\n",
    "    ) -> None:\n",
    "        super(Inception3, self).__init__()\n",
    "        if inception_blocks is None:\n",
    "            inception_blocks = [\n",
    "                BasicConv2d, InceptionA, InceptionB, InceptionC,\n",
    "                InceptionD, InceptionE, InceptionAux\n",
    "            ]\n",
    "        if init_weights is None:\n",
    "            warnings.warn('The default weight initialization of inception_v3 will be changed in future releases of '\n",
    "                          'torchvision. If you wish to keep the old behavior (which leads to long initialization times'\n",
    "                          ' due to scipy/scipy#11299), please set init_weights=True.', FutureWarning)\n",
    "            init_weights = True\n",
    "        assert len(inception_blocks) == 7\n",
    "        conv_block = inception_blocks[0]\n",
    "        inception_a = inception_blocks[1]\n",
    "        inception_b = inception_blocks[2]\n",
    "        inception_c = inception_blocks[3]\n",
    "        inception_d = inception_blocks[4]\n",
    "        inception_e = inception_blocks[5]\n",
    "        inception_aux = inception_blocks[6]\n",
    "\n",
    "        self.aux_logits = aux_logits\n",
    "        self.transform_input = transform_input\n",
    "        self.Conv2d_1a_3x3 = conv_block(3, 32, kernel_size=3, stride=2)\n",
    "        self.Conv2d_2a_3x3 = conv_block(32, 32, kernel_size=3)\n",
    "        self.Conv2d_2b_3x3 = conv_block(32, 64, kernel_size=3, padding=1)\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        self.Conv2d_3b_1x1 = conv_block(64, 80, kernel_size=1)\n",
    "        self.Conv2d_4a_3x3 = conv_block(80, 192, kernel_size=3)\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        self.Mixed_5b = inception_a(192, pool_features=32)\n",
    "        self.Mixed_5c = inception_a(256, pool_features=64)\n",
    "        self.Mixed_5d = inception_a(288, pool_features=64)\n",
    "        self.Mixed_6a = inception_b(288)\n",
    "        self.Mixed_6b = inception_c(768, channels_7x7=128)\n",
    "        self.Mixed_6c = inception_c(768, channels_7x7=160)\n",
    "        self.Mixed_6d = inception_c(768, channels_7x7=160)\n",
    "        self.Mixed_6e = inception_c(768, channels_7x7=192)\n",
    "        self.AuxLogits: Optional[nn.Module] = None\n",
    "        if aux_logits:\n",
    "            self.AuxLogits = inception_aux(768, num_classes)\n",
    "        self.Mixed_7a = inception_d(768)\n",
    "        self.Mixed_7b = inception_e(1280)\n",
    "        self.Mixed_7c = inception_e(2048)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.dropout = nn.Dropout()\n",
    "        self.fc_2_1 = nn.Linear(3, 64)\n",
    "        self.fc3 = nn.Linear(2048, 64)\n",
    "        self.fc2 = nn.Linear(64+64, num_classes)\n",
    "    \n",
    "        self.cond0 = nn.Linear(3,64)\n",
    "        self.cond1 = nn.Linear(64, 64)\n",
    "\n",
    "        self.condproj0 = nn.Linear(64, 32)\n",
    "  \n",
    "        self.condproj1 = nn.Linear(64, 192)\n",
    "        self.condproj2 = nn.Linear(64, 768)\n",
    "\n",
    "        self.gnorm0 = nn.GroupNorm(32, 32)\n",
    "        self.gnorm1 = nn.GroupNorm(192, 192)\n",
    "        self.gnorm2 = nn.GroupNorm(768, 768)\n",
    "        if init_weights:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "                    stddev = float(m.stddev) if hasattr(m, 'stddev') else 0.1  # type: ignore\n",
    "                    torch.nn.init.trunc_normal_(m.weight, mean=0.0, std=stddev, a=-2, b=2)\n",
    "                elif isinstance(m, nn.BatchNorm2d):\n",
    "                    nn.init.constant_(m.weight, 1)\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def _transform_input(self, x: Tensor) -> Tensor:\n",
    "        if self.transform_input:\n",
    "            x_ch0 = torch.unsqueeze(x[:, 0], 1) * (0.229 / 0.5) + (0.485 - 0.5) / 0.5\n",
    "            x_ch1 = torch.unsqueeze(x[:, 1], 1) * (0.224 / 0.5) + (0.456 - 0.5) / 0.5\n",
    "            x_ch2 = torch.unsqueeze(x[:, 2], 1) * (0.225 / 0.5) + (0.406 - 0.5) / 0.5\n",
    "            x = torch.cat((x_ch0, x_ch1, x_ch2), 1)\n",
    "        return x\n",
    "\n",
    "    def get_feature_map(self, x: Tensor, layer):\n",
    "        x = self.Conv2d_1a_3x3(x)\n",
    "        # N x 32 x 149 x 149\n",
    "        x = self.Conv2d_2a_3x3(x)\n",
    "        # N x 32 x 147 x 147\n",
    "        x = self.Conv2d_2b_3x3(x)\n",
    "        if(layer == 0):\n",
    "          return x\n",
    "        # N x 64 x 147 x 147\n",
    "        x = self.maxpool1(x)\n",
    "        # N x 64 x 73 x 73\n",
    "        x = self.Conv2d_3b_1x1(x)\n",
    "        # N x 80 x 73 x 73\n",
    "        x = self.Conv2d_4a_3x3(x)\n",
    "        if(layer == 1):\n",
    "          return x\n",
    "        return x\n",
    "\n",
    "    def _forward(self, x: Tensor, x2: Tensor) -> Tuple[Tensor, Optional[Tensor]]:\n",
    "        temb = F.relu(self.cond0(x2))\n",
    "        temb = F.relu(self.cond1(temb))\n",
    "\n",
    "        # N x 3 x 299 x 299\n",
    "        x = self.Conv2d_1a_3x3(x)\n",
    "        \n",
    "        # N x 32 x 149 x 149\n",
    "        #temb0 = F.relu(self.condproj0(temb))\n",
    "        #x = x+ temb0[:,:,None,None]\n",
    "        #x = self.gnorm0(x)\n",
    "        x = self.Conv2d_2a_3x3(x)\n",
    "        # N x 32 x 147 x 147\n",
    "        x = self.Conv2d_2b_3x3(x)\n",
    "        # N x 64 x 147 x 147\n",
    "        x = self.maxpool1(x)\n",
    "        # N x 64 x 73 x 73\n",
    "        x = self.Conv2d_3b_1x1(x)\n",
    "        # N x 80 x 73 x 73\n",
    "        x = self.Conv2d_4a_3x3(x)\n",
    "        # N x 192 x 71 x 71\n",
    "        x = self.maxpool2(x)\n",
    "        \n",
    "        # N x 192 x 35 x 35\n",
    "        temb1 = F.relu(self.condproj1(temb))\n",
    "        x += temb1[:,:,None,None]\n",
    "        x = self.gnorm1(x)\n",
    "        x = self.Mixed_5b(x)\n",
    "        # N x 256 x 35 x 35\n",
    "        x = self.Mixed_5c(x)\n",
    "        # N x 288 x 35 x 35\n",
    "        x = self.Mixed_5d(x)\n",
    "        # N x 288 x 35 x 35\n",
    "        x = self.Mixed_6a(x)\n",
    "        \n",
    "        # N x 768 x 17 x 17\n",
    "        temb2 = F.relu(self.condproj2(temb))\n",
    "        x += temb2[:,:,None,None]\n",
    "        x = self.gnorm2(x)\n",
    "        x = self.Mixed_6b(x)\n",
    "        # N x 768 x 17 x 17\n",
    "        x = self.Mixed_6c(x)\n",
    "        # N x 768 x 17 x 17\n",
    "        x = self.Mixed_6d(x)\n",
    "        # N x 768 x 17 x 17\n",
    "        x = self.Mixed_6e(x)\n",
    "        # N x 768 x 17 x 17\n",
    "        aux: Optional[Tensor] = None\n",
    "        if self.AuxLogits is not None:\n",
    "            if self.training:\n",
    "                aux = self.AuxLogits(x)\n",
    "        # N x 768 x 17 x 17\n",
    "        x = self.Mixed_7a(x)\n",
    "        # N x 1280 x 8 x 8\n",
    "        x = self.Mixed_7b(x)\n",
    "        # N x 2048 x 8 x 8\n",
    "        x = self.Mixed_7c(x)\n",
    "        # N x 2048 x 8 x 8\n",
    "        # Adaptive average pooling\n",
    "        x = self.avgpool(x)\n",
    "        # N x 2048 x 1 x 1\n",
    "        x = self.dropout(x)\n",
    "        # N x 2048 x 1 x 1\n",
    "\n",
    "        x2 = F.relu(self.fc_2_1(x2))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc3(x)\n",
    "        x = torch.cat([x, x2], dim = 1)\n",
    "\n",
    "        \n",
    "\n",
    "        # N x 2056\n",
    "        x = self.fc2(x)\n",
    "        # N x 1000 (num_classes)\n",
    "        return x, aux\n",
    "\n",
    "    def get_fea(self, x: Tensor, x2: Tensor) -> Tuple[Tensor, Optional[Tensor]]:\n",
    "        # N x 3 x 299 x 299\n",
    "        x = self.Conv2d_1a_3x3(x)\n",
    "        # N x 32 x 149 x 149\n",
    "        x = self.Conv2d_2a_3x3(x)\n",
    "        # N x 32 x 147 x 147\n",
    "        x = self.Conv2d_2b_3x3(x)\n",
    "        # N x 64 x 147 x 147\n",
    "        x = self.maxpool1(x)\n",
    "        # N x 64 x 73 x 73\n",
    "        x = self.Conv2d_3b_1x1(x)\n",
    "        # N x 80 x 73 x 73\n",
    "        x = self.Conv2d_4a_3x3(x)\n",
    "        # N x 192 x 71 x 71\n",
    "        x = self.maxpool2(x)\n",
    "        # N x 192 x 35 x 35\n",
    "        x = self.Mixed_5b(x)\n",
    "        # N x 256 x 35 x 35\n",
    "        x = self.Mixed_5c(x)\n",
    "        # N x 288 x 35 x 35\n",
    "        x = self.Mixed_5d(x)\n",
    "        # N x 288 x 35 x 35\n",
    "        x = self.Mixed_6a(x)\n",
    "        # N x 768 x 17 x 17\n",
    "        x = self.Mixed_6b(x)\n",
    "        # N x 768 x 17 x 17\n",
    "        x = self.Mixed_6c(x)\n",
    "        # N x 768 x 17 x 17\n",
    "        x = self.Mixed_6d(x)\n",
    "        # N x 768 x 17 x 17\n",
    "        x = self.Mixed_6e(x)\n",
    "        # N x 768 x 17 x 17\n",
    "        aux: Optional[Tensor] = None\n",
    "\n",
    "        if self.AuxLogits is not None:\n",
    "            if self.training:\n",
    "                aux = self.AuxLogits(x)\n",
    "        # N x 768 x 17 x 17\n",
    "        x = self.Mixed_7a(x)\n",
    "        # N x 1280 x 8 x 8\n",
    "        x = self.Mixed_7b(x)\n",
    "        # N x 2048 x 8 x 8\n",
    "        x = self.Mixed_7c(x)\n",
    "        # N x 2048 x 8 x 8\n",
    "        # Adaptive average pooling\n",
    "        x = self.avgpool(x)\n",
    "        # N x 2048 x 1 x 1\n",
    "        x = self.dropout(x)\n",
    "        # N x 2048 x 1 x 1\n",
    "\n",
    "        x2 = F.relu(self.fc_2_1(x2))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc3(x)\n",
    "        fea = torch.cat([x, x2], dim = 1)\n",
    "\n",
    "\n",
    "        # N x 2056\n",
    "        x = self.fc2(fea)\n",
    "        # N x 1000 (num_classes)\n",
    "        return x, fea\n",
    "\n",
    "    @torch.jit.unused\n",
    "    def eager_outputs(self, x: Tensor, aux: Optional[Tensor]) -> InceptionOutputs:\n",
    "        if self.training and self.aux_logits:\n",
    "            return InceptionOutputs(x, aux)\n",
    "        else:\n",
    "            return x  # type: ignore[return-value]\n",
    "\n",
    "    def forward(self, x: Tensor, x2: Tensor) -> InceptionOutputs:\n",
    "        x = self._transform_input(x)\n",
    "        x, aux = self._forward(x, x2)\n",
    "        aux_defined = self.training and self.aux_logits\n",
    "        if torch.jit.is_scripting():\n",
    "            if not aux_defined:\n",
    "                warnings.warn(\"Scripted Inception3 always returns Inception3 Tuple\")\n",
    "            return InceptionOutputs(x, aux)\n",
    "        else:\n",
    "            return self.eager_outputs(x, aux)\n",
    "\n",
    "\n",
    "class InceptionA(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        pool_features: int,\n",
    "        conv_block: Optional[Callable[..., nn.Module]] = None\n",
    "    ) -> None:\n",
    "        super(InceptionA, self).__init__()\n",
    "        if conv_block is None:\n",
    "            conv_block = BasicConv2d\n",
    "        self.branch1x1 = conv_block(in_channels, 64, kernel_size=1)\n",
    "\n",
    "        self.branch5x5_1 = conv_block(in_channels, 48, kernel_size=1)\n",
    "        self.branch5x5_2 = conv_block(48, 64, kernel_size=5, padding=2)\n",
    "\n",
    "        self.branch3x3dbl_1 = conv_block(in_channels, 64, kernel_size=1)\n",
    "        self.branch3x3dbl_2 = conv_block(64, 96, kernel_size=3, padding=1)\n",
    "        self.branch3x3dbl_3 = conv_block(96, 96, kernel_size=3, padding=1)\n",
    "\n",
    "        self.branch_pool = conv_block(in_channels, pool_features, kernel_size=1)\n",
    "\n",
    "    def _forward(self, x: Tensor) -> List[Tensor]:\n",
    "        branch1x1 = self.branch1x1(x)\n",
    "\n",
    "        branch5x5 = self.branch5x5_1(x)\n",
    "        branch5x5 = self.branch5x5_2(branch5x5)\n",
    "\n",
    "        branch3x3dbl = self.branch3x3dbl_1(x)\n",
    "        branch3x3dbl = self.branch3x3dbl_2(branch3x3dbl)\n",
    "        branch3x3dbl = self.branch3x3dbl_3(branch3x3dbl)\n",
    "\n",
    "        branch_pool = F.avg_pool2d(x, kernel_size=3, stride=1, padding=1)\n",
    "        branch_pool = self.branch_pool(branch_pool)\n",
    "\n",
    "        outputs = [branch1x1, branch5x5, branch3x3dbl, branch_pool]\n",
    "        return outputs\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        outputs = self._forward(x)\n",
    "        return torch.cat(outputs, 1)\n",
    "\n",
    "\n",
    "class InceptionB(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        conv_block: Optional[Callable[..., nn.Module]] = None\n",
    "    ) -> None:\n",
    "        super(InceptionB, self).__init__()\n",
    "        if conv_block is None:\n",
    "            conv_block = BasicConv2d\n",
    "        self.branch3x3 = conv_block(in_channels, 384, kernel_size=3, stride=2)\n",
    "\n",
    "        self.branch3x3dbl_1 = conv_block(in_channels, 64, kernel_size=1)\n",
    "        self.branch3x3dbl_2 = conv_block(64, 96, kernel_size=3, padding=1)\n",
    "        self.branch3x3dbl_3 = conv_block(96, 96, kernel_size=3, stride=2)\n",
    "\n",
    "    def _forward(self, x: Tensor) -> List[Tensor]:\n",
    "        branch3x3 = self.branch3x3(x)\n",
    "\n",
    "        branch3x3dbl = self.branch3x3dbl_1(x)\n",
    "        branch3x3dbl = self.branch3x3dbl_2(branch3x3dbl)\n",
    "        branch3x3dbl = self.branch3x3dbl_3(branch3x3dbl)\n",
    "\n",
    "        branch_pool = F.max_pool2d(x, kernel_size=3, stride=2)\n",
    "\n",
    "        outputs = [branch3x3, branch3x3dbl, branch_pool]\n",
    "        return outputs\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        outputs = self._forward(x)\n",
    "        return torch.cat(outputs, 1)\n",
    "\n",
    "\n",
    "class InceptionC(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        channels_7x7: int,\n",
    "        conv_block: Optional[Callable[..., nn.Module]] = None\n",
    "    ) -> None:\n",
    "        super(InceptionC, self).__init__()\n",
    "        if conv_block is None:\n",
    "            conv_block = BasicConv2d\n",
    "        self.branch1x1 = conv_block(in_channels, 192, kernel_size=1)\n",
    "\n",
    "        c7 = channels_7x7\n",
    "        self.branch7x7_1 = conv_block(in_channels, c7, kernel_size=1)\n",
    "        self.branch7x7_2 = conv_block(c7, c7, kernel_size=(1, 7), padding=(0, 3))\n",
    "        self.branch7x7_3 = conv_block(c7, 192, kernel_size=(7, 1), padding=(3, 0))\n",
    "\n",
    "        self.branch7x7dbl_1 = conv_block(in_channels, c7, kernel_size=1)\n",
    "        self.branch7x7dbl_2 = conv_block(c7, c7, kernel_size=(7, 1), padding=(3, 0))\n",
    "        self.branch7x7dbl_3 = conv_block(c7, c7, kernel_size=(1, 7), padding=(0, 3))\n",
    "        self.branch7x7dbl_4 = conv_block(c7, c7, kernel_size=(7, 1), padding=(3, 0))\n",
    "        self.branch7x7dbl_5 = conv_block(c7, 192, kernel_size=(1, 7), padding=(0, 3))\n",
    "\n",
    "        self.branch_pool = conv_block(in_channels, 192, kernel_size=1)\n",
    "\n",
    "    def _forward(self, x: Tensor) -> List[Tensor]:\n",
    "        branch1x1 = self.branch1x1(x)\n",
    "\n",
    "        branch7x7 = self.branch7x7_1(x)\n",
    "        branch7x7 = self.branch7x7_2(branch7x7)\n",
    "        branch7x7 = self.branch7x7_3(branch7x7)\n",
    "\n",
    "        branch7x7dbl = self.branch7x7dbl_1(x)\n",
    "        branch7x7dbl = self.branch7x7dbl_2(branch7x7dbl)\n",
    "        branch7x7dbl = self.branch7x7dbl_3(branch7x7dbl)\n",
    "        branch7x7dbl = self.branch7x7dbl_4(branch7x7dbl)\n",
    "        branch7x7dbl = self.branch7x7dbl_5(branch7x7dbl)\n",
    "\n",
    "        branch_pool = F.avg_pool2d(x, kernel_size=3, stride=1, padding=1)\n",
    "        branch_pool = self.branch_pool(branch_pool)\n",
    "\n",
    "        outputs = [branch1x1, branch7x7, branch7x7dbl, branch_pool]\n",
    "        return outputs\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        outputs = self._forward(x)\n",
    "        return torch.cat(outputs, 1)\n",
    "\n",
    "\n",
    "class InceptionD(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        conv_block: Optional[Callable[..., nn.Module]] = None\n",
    "    ) -> None:\n",
    "        super(InceptionD, self).__init__()\n",
    "        if conv_block is None:\n",
    "            conv_block = BasicConv2d\n",
    "        self.branch3x3_1 = conv_block(in_channels, 192, kernel_size=1)\n",
    "        self.branch3x3_2 = conv_block(192, 320, kernel_size=3, stride=2)\n",
    "\n",
    "        self.branch7x7x3_1 = conv_block(in_channels, 192, kernel_size=1)\n",
    "        self.branch7x7x3_2 = conv_block(192, 192, kernel_size=(1, 7), padding=(0, 3))\n",
    "        self.branch7x7x3_3 = conv_block(192, 192, kernel_size=(7, 1), padding=(3, 0))\n",
    "        self.branch7x7x3_4 = conv_block(192, 192, kernel_size=3, stride=2)\n",
    "\n",
    "    def _forward(self, x: Tensor) -> List[Tensor]:\n",
    "        branch3x3 = self.branch3x3_1(x)\n",
    "        branch3x3 = self.branch3x3_2(branch3x3)\n",
    "\n",
    "        branch7x7x3 = self.branch7x7x3_1(x)\n",
    "        branch7x7x3 = self.branch7x7x3_2(branch7x7x3)\n",
    "        branch7x7x3 = self.branch7x7x3_3(branch7x7x3)\n",
    "        branch7x7x3 = self.branch7x7x3_4(branch7x7x3)\n",
    "\n",
    "        branch_pool = F.max_pool2d(x, kernel_size=3, stride=2)\n",
    "        outputs = [branch3x3, branch7x7x3, branch_pool]\n",
    "        return outputs\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        outputs = self._forward(x)\n",
    "        return torch.cat(outputs, 1)\n",
    "\n",
    "\n",
    "class InceptionE(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        conv_block: Optional[Callable[..., nn.Module]] = None\n",
    "    ) -> None:\n",
    "        super(InceptionE, self).__init__()\n",
    "        if conv_block is None:\n",
    "            conv_block = BasicConv2d\n",
    "        self.branch1x1 = conv_block(in_channels, 320, kernel_size=1)\n",
    "\n",
    "        self.branch3x3_1 = conv_block(in_channels, 384, kernel_size=1)\n",
    "        self.branch3x3_2a = conv_block(384, 384, kernel_size=(1, 3), padding=(0, 1))\n",
    "        self.branch3x3_2b = conv_block(384, 384, kernel_size=(3, 1), padding=(1, 0))\n",
    "\n",
    "        self.branch3x3dbl_1 = conv_block(in_channels, 448, kernel_size=1)\n",
    "        self.branch3x3dbl_2 = conv_block(448, 384, kernel_size=3, padding=1)\n",
    "        self.branch3x3dbl_3a = conv_block(384, 384, kernel_size=(1, 3), padding=(0, 1))\n",
    "        self.branch3x3dbl_3b = conv_block(384, 384, kernel_size=(3, 1), padding=(1, 0))\n",
    "\n",
    "        self.branch_pool = conv_block(in_channels, 192, kernel_size=1)\n",
    "\n",
    "    def _forward(self, x: Tensor) -> List[Tensor]:\n",
    "        branch1x1 = self.branch1x1(x)\n",
    "\n",
    "        branch3x3 = self.branch3x3_1(x)\n",
    "        branch3x3 = [\n",
    "            self.branch3x3_2a(branch3x3),\n",
    "            self.branch3x3_2b(branch3x3),\n",
    "        ]\n",
    "        branch3x3 = torch.cat(branch3x3, 1)\n",
    "\n",
    "        branch3x3dbl = self.branch3x3dbl_1(x)\n",
    "        branch3x3dbl = self.branch3x3dbl_2(branch3x3dbl)\n",
    "        branch3x3dbl = [\n",
    "            self.branch3x3dbl_3a(branch3x3dbl),\n",
    "            self.branch3x3dbl_3b(branch3x3dbl),\n",
    "        ]\n",
    "        branch3x3dbl = torch.cat(branch3x3dbl, 1)\n",
    "\n",
    "        branch_pool = F.avg_pool2d(x, kernel_size=3, stride=1, padding=1)\n",
    "        branch_pool = self.branch_pool(branch_pool)\n",
    "\n",
    "        outputs = [branch1x1, branch3x3, branch3x3dbl, branch_pool]\n",
    "        return outputs\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        outputs = self._forward(x)\n",
    "        return torch.cat(outputs, 1)\n",
    "\n",
    "\n",
    "class InceptionAux(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        num_classes: int,\n",
    "        conv_block: Optional[Callable[..., nn.Module]] = None\n",
    "    ) -> None:\n",
    "        super(InceptionAux, self).__init__()\n",
    "        if conv_block is None:\n",
    "            conv_block = BasicConv2d\n",
    "        self.conv0 = conv_block(in_channels, 128, kernel_size=1)\n",
    "        self.conv1 = conv_block(128, 768, kernel_size=5)\n",
    "        self.conv1.stddev = 0.01  # type: ignore[assignment]\n",
    "        self.fc2 = nn.Linear(768, num_classes)\n",
    "        self.fc2.stddev = 0.001  # type: ignore[assignment]\n",
    "        self.fc_2_1 = nn.Linear(3, 3)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        # N x 768 x 17 x 17\n",
    "        x = F.avg_pool2d(x, kernel_size=5, stride=3)\n",
    "        # N x 768 x 5 x 5\n",
    "        x = self.conv0(x)\n",
    "        # N x 128 x 5 x 5\n",
    "        x = self.conv1(x)\n",
    "        # N x 768 x 1 x 1\n",
    "        # Adaptive average pooling\n",
    "        x = F.adaptive_avg_pool2d(x, (1, 1))\n",
    "        # N x 768 x 1 x 1\n",
    "        x = torch.flatten(x, 1)\n",
    "        # N x 768\n",
    "        x = self.fc2(x)\n",
    "        # N x 1000\n",
    "        return x\n",
    "\n",
    "\n",
    "class BasicConv2d(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        **kwargs: Any\n",
    "    ) -> None:\n",
    "        super(BasicConv2d, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, bias=False, **kwargs)\n",
    "        self.bn = nn.BatchNorm2d(out_channels, eps=0.001)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        return F.relu(x, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "cellView": "form",
    "id": "jwOb-HogqZnT",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#@title ViT network backbone\n",
    "import math\n",
    "from functools import partial\n",
    "from itertools import repeat\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "#from torch._six import container_abcs\n",
    "import collections.abc as container_abcs\n",
    "\n",
    "# From PyTorch internals\n",
    "def _ntuple(n):\n",
    "    def parse(x):\n",
    "        if isinstance(x, container_abcs.Iterable):\n",
    "            return x\n",
    "        return tuple(repeat(x, n))\n",
    "    return parse\n",
    "\n",
    "IMAGENET_DEFAULT_MEAN = (0.485, 0.456, 0.406)\n",
    "IMAGENET_DEFAULT_STD = (0.229, 0.224, 0.225)\n",
    "to_2tuple = _ntuple(2)\n",
    "\n",
    "def drop_path(x, drop_prob: float = 0., training: bool = False):\n",
    "    \"\"\"Drop paths (Stochastic Depth) per sample (when applied in main path of residual blocks).\n",
    "\n",
    "    This is the same as the DropConnect impl I created for EfficientNet, etc networks, however,\n",
    "    the original name is misleading as 'Drop Connect' is a different form of dropout in a separate paper...\n",
    "    See discussion: https://github.com/tensorflow/tpu/issues/494#issuecomment-532968956 ... I've opted for\n",
    "    changing the layer and argument names to 'drop path' rather than mix DropConnect as a layer name and use\n",
    "    'survival rate' as the argument.\n",
    "\n",
    "    \"\"\"\n",
    "    if drop_prob == 0. or not training:\n",
    "        return x\n",
    "    keep_prob = 1 - drop_prob\n",
    "    shape = (x.shape[0],) + (1,) * (x.ndim - 1)  # work with diff dim tensors, not just 2D ConvNets\n",
    "    random_tensor = keep_prob + torch.rand(shape, dtype=x.dtype, device=x.device)\n",
    "    random_tensor.floor_()  # binarize\n",
    "    output = x.div(keep_prob) * random_tensor\n",
    "    return output\n",
    "\n",
    "class DropPath(nn.Module):\n",
    "    \"\"\"Drop paths (Stochastic Depth) per sample  (when applied in main path of residual blocks).\n",
    "    \"\"\"\n",
    "    def __init__(self, drop_prob=None):\n",
    "        super(DropPath, self).__init__()\n",
    "        self.drop_prob = drop_prob\n",
    "\n",
    "    def forward(self, x):\n",
    "        return drop_path(x, self.drop_prob, self.training)\n",
    "\n",
    "\n",
    "\n",
    "def _cfg(url='', **kwargs):\n",
    "    return {\n",
    "        'url': url,\n",
    "        'num_classes': 1000, 'input_size': (3, 224, 224), 'pool_size': None,\n",
    "        'crop_pct': .9, 'interpolation': 'bicubic',\n",
    "        'mean': IMAGENET_DEFAULT_MEAN, 'std': IMAGENET_DEFAULT_STD,\n",
    "        'first_conv': 'patch_embed.proj', 'classifier': 'head',\n",
    "        **kwargs\n",
    "    }\n",
    "\n",
    "\n",
    "default_cfgs = {\n",
    "    # patch models\n",
    "    'vit_small_patch16_224': _cfg(\n",
    "        url='https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/vit_small_p16_224-15ec54c9.pth',\n",
    "    ),\n",
    "    'vit_base_patch16_224': _cfg(\n",
    "        url='https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-vitjx/jx_vit_base_p16_224-80ecf9dd.pth',\n",
    "        mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5),\n",
    "    ),\n",
    "    'vit_base_patch16_384': _cfg(\n",
    "        url='https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-vitjx/jx_vit_base_p16_384-83fb41ba.pth',\n",
    "        input_size=(3, 384, 384), mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5), crop_pct=1.0),\n",
    "    'vit_base_patch32_384': _cfg(\n",
    "        url='https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-vitjx/jx_vit_base_p32_384-830016f5.pth',\n",
    "        input_size=(3, 384, 384), mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5), crop_pct=1.0),\n",
    "    'vit_large_patch16_224': _cfg(\n",
    "        url='https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-vitjx/jx_vit_large_p16_224-4ee7a4dc.pth',\n",
    "        mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),\n",
    "    'vit_large_patch16_384': _cfg(\n",
    "        url='https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-vitjx/jx_vit_large_p16_384-b3be5167.pth',\n",
    "        input_size=(3, 384, 384), mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5), crop_pct=1.0),\n",
    "    'vit_large_patch32_384': _cfg(\n",
    "        url='https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-vitjx/jx_vit_large_p32_384-9b920ba8.pth',\n",
    "        input_size=(3, 384, 384), mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5), crop_pct=1.0),\n",
    "    'vit_huge_patch16_224': _cfg(),\n",
    "    'vit_huge_patch32_384': _cfg(input_size=(3, 384, 384)),\n",
    "    # hybrid models\n",
    "    'vit_small_resnet26d_224': _cfg(),\n",
    "    'vit_small_resnet50d_s3_224': _cfg(),\n",
    "    'vit_base_resnet26d_224': _cfg(),\n",
    "    'vit_base_resnet50d_224': _cfg(),\n",
    "}\n",
    "\n",
    "\n",
    "class Mlp(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features=None, out_features=None, act_layer=nn.GELU, drop=0.):\n",
    "        super().__init__()\n",
    "        out_features = out_features or in_features\n",
    "        hidden_features = hidden_features or in_features\n",
    "        self.fc1 = nn.Linear(in_features, hidden_features)\n",
    "        self.act = act_layer()\n",
    "        self.fc2 = nn.Linear(hidden_features, out_features)\n",
    "        self.drop = nn.Dropout(drop)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.drop(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, dim, num_heads=8, qkv_bias=False, qk_scale=None, attn_drop=0., proj_drop=0.):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        head_dim = dim // num_heads\n",
    "        # NOTE scale factor was wrong in my original version, can set manually to be compat with prev weights\n",
    "        self.scale = qk_scale or head_dim ** -0.5\n",
    "\n",
    "        self.qkv = nn.Linear(dim, dim * 3, bias=qkv_bias)\n",
    "        self.attn_drop = nn.Dropout(attn_drop)\n",
    "        self.proj = nn.Linear(dim, dim)\n",
    "        self.proj_drop = nn.Dropout(proj_drop)\n",
    "        self.attn = None\n",
    "    def forward(self, x):\n",
    "        B, N, C = x.shape\n",
    "        qkv = self.qkv(x).reshape(B, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n",
    "        q, k, v = qkv[0], qkv[1], qkv[2]   # make torchscript happy (cannot use tensor as tuple)\n",
    "\n",
    "        attn = (q @ k.transpose(-2, -1)) * self.scale\n",
    "\n",
    "        attn = attn.softmax(dim=-1)\n",
    "        self.attn = attn\n",
    "        attn = self.attn_drop(attn)\n",
    "\n",
    "        x = (attn @ v).transpose(1, 2).reshape(B, N, C)\n",
    "        x = self.proj(x)\n",
    "        x = self.proj_drop(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Block(nn.Module):\n",
    "\n",
    "    def __init__(self, dim, num_heads, mlp_ratio=4., qkv_bias=False, qk_scale=None, drop=0., attn_drop=0.,\n",
    "                 drop_path=0., act_layer=nn.GELU, norm_layer=nn.LayerNorm):\n",
    "        super().__init__()\n",
    "        self.norm1 = norm_layer(dim)\n",
    "        self.attn = Attention(\n",
    "            dim, num_heads=num_heads, qkv_bias=qkv_bias, qk_scale=qk_scale, attn_drop=attn_drop, proj_drop=drop)\n",
    "        # NOTE: drop path for stochastic depth, we shall see if this is better than dropout here\n",
    "        self.drop_path = DropPath(drop_path) if drop_path > 0. else nn.Identity()\n",
    "        self.norm2 = norm_layer(dim)\n",
    "        mlp_hidden_dim = int(dim * mlp_ratio)\n",
    "        self.mlp = Mlp(in_features=dim, hidden_features=mlp_hidden_dim, act_layer=act_layer, drop=drop)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.drop_path(self.attn(self.norm1(x)))\n",
    "        x = x + self.drop_path(self.mlp(self.norm2(x)))\n",
    "        return x\n",
    "\n",
    "\n",
    "class PatchEmbed(nn.Module):\n",
    "    \"\"\" Image to Patch Embedding\n",
    "    \"\"\"\n",
    "    def __init__(self, img_size=224, patch_size=16, in_chans=3, embed_dim=768):\n",
    "        super().__init__()\n",
    "        img_size = to_2tuple(img_size)\n",
    "        patch_size = to_2tuple(patch_size)\n",
    "        num_patches = (img_size[1] // patch_size[1]) * (img_size[0] // patch_size[0])\n",
    "        self.img_size = img_size\n",
    "        self.patch_size = patch_size\n",
    "        self.num_patches = num_patches\n",
    "\n",
    "        self.proj = nn.Conv2d(in_chans, embed_dim, kernel_size=patch_size, stride=patch_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.shape\n",
    "        # FIXME look at relaxing size constraints\n",
    "        assert H == self.img_size[0] and W == self.img_size[1], \\\n",
    "            f\"Input image size ({H}*{W}) doesn't match model ({self.img_size[0]}*{self.img_size[1]}).\"\n",
    "        x = self.proj(x).flatten(2).transpose(1, 2)\n",
    "        return x\n",
    "\n",
    "class HybridEmbed(nn.Module):\n",
    "    \"\"\" CNN Feature Map Embedding\n",
    "    Extract feature map from CNN, flatten, project to embedding dim.\n",
    "    \"\"\"\n",
    "    def __init__(self, backbone, img_size=224, feature_size=None, in_chans=3, embed_dim=768):\n",
    "        super().__init__()\n",
    "        assert isinstance(backbone, nn.Module)\n",
    "        img_size = to_2tuple(img_size)\n",
    "        self.img_size = img_size\n",
    "        self.backbone = backbone\n",
    "        if feature_size is None:\n",
    "            with torch.no_grad():\n",
    "                # FIXME this is hacky, but most reliable way of determining the exact dim of the output feature\n",
    "                # map for all networks, the feature metadata has reliable channel and stride info, but using\n",
    "                # stride to calc feature dim requires info about padding of each stage that isn't captured.\n",
    "                training = backbone.training\n",
    "                if training:\n",
    "                    backbone.eval()\n",
    "                o = self.backbone(torch.zeros(1, in_chans, img_size[0], img_size[1]))[-1]\n",
    "                feature_size = o.shape[-2:]\n",
    "                feature_dim = o.shape[1]\n",
    "                backbone.train(training)\n",
    "        else:\n",
    "            feature_size = to_2tuple(feature_size)\n",
    "            feature_dim = self.backbone.feature_info.channels()[-1]\n",
    "        self.num_patches = feature_size[0] * feature_size[1]\n",
    "        self.proj = nn.Linear(feature_dim, embed_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)[-1]\n",
    "        x = x.flatten(2).transpose(1, 2)\n",
    "        x = self.proj(x)\n",
    "        return x\n",
    "\n",
    "class VisionTransformer(nn.Module):\n",
    "    \"\"\" Vision Transformer with support for patch or hybrid CNN input stage\n",
    "    \"\"\"\n",
    "    def __init__(self, img_size=224, patch_size=16, in_chans=3, num_classes=1000, embed_dim=768, depth=12,\n",
    "                 num_heads=12, mlp_ratio=4., qkv_bias=False, qk_scale=None, drop_rate=0., attn_drop_rate=0.,\n",
    "                 drop_path_rate=0., hybrid_backbone=None, norm_layer=nn.LayerNorm):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.num_features = self.embed_dim = embed_dim  # num_features for consistency with other models\n",
    "\n",
    "        if hybrid_backbone is not None:\n",
    "            self.patch_embed = HybridEmbed(\n",
    "                hybrid_backbone, img_size=img_size, in_chans=in_chans, embed_dim=embed_dim)\n",
    "        else:\n",
    "            self.patch_embed = PatchEmbed(\n",
    "                img_size=img_size, patch_size=patch_size, in_chans=in_chans, embed_dim=embed_dim)\n",
    "        num_patches = self.patch_embed.num_patches\n",
    "\n",
    "        self.cls_token = nn.Parameter(torch.zeros(1, 1, embed_dim))\n",
    "        self.pos_embed = nn.Parameter(torch.zeros(1, num_patches + 1, embed_dim))\n",
    "        # self.pos_embed_2 = nn.Parameter(torch.zeros(1, num_patches + 1, embed_dim))\n",
    "        # print('pos_embed_2')\n",
    "        self.pos_drop = nn.Dropout(p=drop_rate)\n",
    "        print(drop_path_rate, 'drop_path_rate')\n",
    "        print(drop_rate, 'drop_rate')\n",
    "        dpr = [x.item() for x in torch.linspace(0, drop_path_rate, depth)]  # stochastic depth decay rule\n",
    "        self.blocks = nn.ModuleList([\n",
    "            Block(\n",
    "                dim=embed_dim, num_heads=num_heads, mlp_ratio=mlp_ratio, qkv_bias=qkv_bias, qk_scale=qk_scale,\n",
    "                drop=drop_rate, attn_drop=attn_drop_rate, drop_path=dpr[i], norm_layer=norm_layer)\n",
    "            for i in range(depth)])\n",
    "        self.norm = norm_layer(embed_dim)\n",
    "\n",
    "        # NOTE as per official impl, we could have a pre-logits representation dense layer + tanh here\n",
    "\n",
    "        # Classifier head\n",
    "        self.fc = nn.Linear(embed_dim, num_classes) if num_classes > 0 else nn.Identity()\n",
    "\n",
    "        trunc_normal_(self.pos_embed, std=.02)\n",
    "        trunc_normal_(self.cls_token, std=.02)\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            trunc_normal_(m.weight, std=.02)\n",
    "            if isinstance(m, nn.Linear) and m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.LayerNorm):\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "            nn.init.constant_(m.weight, 1.0)\n",
    "\n",
    "    @torch.jit.ignore\n",
    "    def no_weight_decay(self):\n",
    "        return {'pos_embed', 'cls_token'}\n",
    "\n",
    "    def get_classifier(self):\n",
    "        return self.head\n",
    "\n",
    "    def reset_classifier(self, num_classes, global_pool=''):\n",
    "        self.num_classes = num_classes\n",
    "        self.fc = nn.Linear(self.embed_dim, num_classes) if num_classes > 0 else nn.Identity()\n",
    "\n",
    "    def forward_features(self, x):\n",
    "        B = x.shape[0]\n",
    "        x = self.patch_embed(x)\n",
    "\n",
    "        cls_tokens = self.cls_token.expand(B, -1, -1)  # stole cls_tokens impl from Phil Wang, thanks\n",
    "        x = torch.cat((cls_tokens, x), dim=1)\n",
    "        # x = x + self.pos_embed + self.pos_embed_2\n",
    "        x = x + self.pos_embed\n",
    "        x = self.pos_drop(x)\n",
    "\n",
    "        for blk in self.blocks:\n",
    "            x = blk(x)\n",
    "\n",
    "        x = self.norm(x)\n",
    "        return x[:, 0]\n",
    "\n",
    "    def forward(self, x, cam_label=None):\n",
    "        x = self.forward_features(x)\n",
    "        #x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "    def load_param(self, model_path):\n",
    "        param_dict = torch.load(model_path, map_location='cpu')\n",
    "        if 'state_dict' in param_dict:\n",
    "            param_dict = param_dict['state_dict']\n",
    "        for i in param_dict:\n",
    "            # if 'head' in i:\n",
    "            #     continue\n",
    "            if 'head' in i or 'attn.qkv.bias' in i:\n",
    "                print('{} parameter is ignore'.format(i))\n",
    "                continue\n",
    "            try:\n",
    "                self.state_dict()[i].copy_(param_dict[i])\n",
    "            except:\n",
    "                print('===========================ERROR=========================')\n",
    "                print('shape do not match in i :{}: param_dict{} vs self.state_dict(){}'.format(i, param_dict[i].shape, self.state_dict()[i].shape))\n",
    "\n",
    "    def load_un_param(self, trained_path):\n",
    "        param_dict = torch.load(trained_path)\n",
    "        if 'state_dict' in param_dict:\n",
    "            param_dict = param_dict['state_dict']\n",
    "        for k in list(param_dict.keys()):\n",
    "            # retain only encoder_q up to before the embedding layer\n",
    "            if k.startswith('module.encoder_q') and not k.startswith('module.encoder_q.fc'):\n",
    "                # remove prefix\n",
    "                param_dict[k[len(\"module.encoder_q.\"):]] = param_dict[k]\n",
    "            # delete renamed or unused k\n",
    "            del param_dict[k]\n",
    "        for i in param_dict:\n",
    "            if 'fc' in i or 'head' in i:\n",
    "                continue\n",
    "            self.state_dict()[i].copy_(param_dict[i])\n",
    "\n",
    "import random\n",
    "\n",
    "class VisionTransformer_mask(nn.Module):\n",
    "    \"\"\" Vision Transformer with support for patch or hybrid CNN input stage\n",
    "    \"\"\"\n",
    "    def __init__(self, img_size=224, patch_size=16, in_chans=3, num_classes=1000, embed_dim=768, depth=12,\n",
    "                 num_heads=12, mlp_ratio=4., qkv_bias=False, qk_scale=None, drop_rate=0., attn_drop_rate=0.,\n",
    "                 drop_path_rate=0., hybrid_backbone=None, norm_layer=nn.LayerNorm, thresh=0.0, prob=0.0):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.num_features = self.embed_dim = embed_dim  # num_features for consistency with other models\n",
    "\n",
    "        if hybrid_backbone is not None:\n",
    "            self.patch_embed = HybridEmbed(\n",
    "                hybrid_backbone, img_size=img_size, in_chans=in_chans, embed_dim=embed_dim)\n",
    "        else:\n",
    "            self.patch_embed = PatchEmbed(\n",
    "                img_size=img_size, patch_size=patch_size, in_chans=in_chans, embed_dim=embed_dim)\n",
    "        num_patches = self.patch_embed.num_patches\n",
    "\n",
    "        self.cls_token = nn.Parameter(torch.zeros(1, 1, embed_dim))\n",
    "        self.pos_embed = nn.Parameter(torch.zeros(1, num_patches + 1, embed_dim))\n",
    "        self.thresh = thresh\n",
    "        print(thresh, 'thresh')\n",
    "        self.prob = prob\n",
    "        print(prob, 'prob')\n",
    "        self.pos_drop = nn.Dropout(p=drop_rate)\n",
    "        print(drop_path_rate, 'drop_path_rate')\n",
    "        print(drop_rate, 'drop_rate')\n",
    "        dpr = [x.item() for x in torch.linspace(0, drop_path_rate, depth)]  # stochastic depth decay rule\n",
    "        self.blocks = nn.ModuleList([\n",
    "            Block(\n",
    "                dim=embed_dim, num_heads=num_heads, mlp_ratio=mlp_ratio, qkv_bias=qkv_bias, qk_scale=qk_scale,\n",
    "                drop=drop_rate, attn_drop=attn_drop_rate, drop_path=dpr[i], norm_layer=norm_layer)\n",
    "            for i in range(depth)])\n",
    "        self.norm = norm_layer(embed_dim)\n",
    "\n",
    "        # Classifier head\n",
    "        self.fc = nn.Linear(embed_dim, num_classes) if num_classes > 0 else nn.Identity()\n",
    "\n",
    "        trunc_normal_(self.pos_embed, std=.02)\n",
    "        trunc_normal_(self.cls_token, std=.02)\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "        self.mask_embedding = nn.Parameter(torch.zeros(64, num_patches, embed_dim)) # 【768】\n",
    "\n",
    "        trunc_normal_(self.mask_embedding, std=.02)\n",
    "\n",
    "    def _init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            trunc_normal_(m.weight, std=.02)\n",
    "            if isinstance(m, nn.Linear) and m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.LayerNorm):\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "            nn.init.constant_(m.weight, 1.0)\n",
    "\n",
    "    @torch.jit.ignore\n",
    "    def no_weight_decay(self):\n",
    "        return {'pos_embed', 'cls_token'}\n",
    "\n",
    "    def get_classifier(self):\n",
    "        return self.head\n",
    "\n",
    "    def reset_classifier(self, num_classes, global_pool=''):\n",
    "        self.num_classes = num_classes\n",
    "        self.fc = nn.Linear(self.embed_dim, num_classes) if num_classes > 0 else nn.Identity()\n",
    "\n",
    "    def forward_features(self, x):\n",
    "        B = x.shape[0]\n",
    "        x = self.patch_embed(x)\n",
    "        if self.training:\n",
    "            prob = random.random()\n",
    "            if prob < self.prob:\n",
    "                mask = torch.rand(1, 128, 1).cuda()\n",
    "                mask = torch.where(mask > self.thresh, torch.Tensor([1]).cuda(), torch.Tensor([0]).cuda())  # [64, 16, 8]\n",
    "                x = mask * x + (1 - mask) * self.mask_embedding\n",
    "\n",
    "        cls_tokens = self.cls_token.expand(B, -1, -1)  # stole cls_tokens impl from Phil Wang, thanks\n",
    "        x = torch.cat((cls_tokens, x), dim=1)\n",
    "\n",
    "        x = x + self.pos_embed\n",
    "        x = self.pos_drop(x)\n",
    "\n",
    "        for blk in self.blocks:\n",
    "            x = blk(x)\n",
    "\n",
    "        x = self.norm(x)\n",
    "        return x[:, 0]\n",
    "\n",
    "    def forward(self, x, cam_label=None):\n",
    "        x = self.forward_features(x)\n",
    "        return x\n",
    "\n",
    "    def load_param(self, model_path):\n",
    "        param_dict = torch.load(model_path, map_location='cpu')\n",
    "        if 'state_dict' in param_dict:\n",
    "            param_dict = param_dict['state_dict']\n",
    "        for i in param_dict:\n",
    "            if 'head' in i:\n",
    "                continue\n",
    "            try:\n",
    "                self.state_dict()[i].copy_(param_dict[i])\n",
    "            except:\n",
    "                print('===========================ERROR=========================')\n",
    "                print('shape do not match in i :{}: param_dict{} vs self.state_dict(){}'.format(i, param_dict[i].shape, self.state_dict()[i].shape))\n",
    "\n",
    "    def load_un_param(self, trained_path):\n",
    "        param_dict = torch.load(trained_path)\n",
    "        if 'state_dict' in param_dict:\n",
    "            param_dict = param_dict['state_dict']\n",
    "        for k in list(param_dict.keys()):\n",
    "            # retain only encoder_q up to before the embedding layer\n",
    "            if k.startswith('module.encoder_q') and not k.startswith('module.encoder_q.fc'):\n",
    "                # remove prefix\n",
    "                param_dict[k[len(\"module.encoder_q.\"):]] = param_dict[k]\n",
    "            # delete renamed or unused k\n",
    "            del param_dict[k]\n",
    "        for i in param_dict:\n",
    "            if 'fc' in i or 'head' in i:\n",
    "                continue\n",
    "            self.state_dict()[i].copy_(param_dict[i])\n",
    "\n",
    "\n",
    "class PatchEmbed_stride(nn.Module):\n",
    "    \"\"\" Image to Patch Embedding\n",
    "    \"\"\"\n",
    "    def __init__(self, img_size=224, patch_size=16, stride_size=20, in_chans=3, embed_dim=768):\n",
    "        super().__init__()\n",
    "        img_size = to_2tuple(img_size)\n",
    "        patch_size = to_2tuple(patch_size)\n",
    "        stride_size_tuple = to_2tuple(stride_size)\n",
    "        self.num_x = (img_size[1] - patch_size[1]) // stride_size_tuple[1] + 1\n",
    "        self.num_y = (img_size[0] - patch_size[0]) // stride_size_tuple[0] + 1\n",
    "        print('using stride: {}, and part number is num_y{} * num_x{}'.format(stride_size, self.num_y, self.num_x))\n",
    "        num_patches = self.num_x * self.num_y\n",
    "        self.img_size = img_size\n",
    "        self.patch_size = patch_size\n",
    "        self.num_patches = num_patches\n",
    "\n",
    "        self.proj = nn.Conv2d(in_chans, embed_dim, kernel_size=patch_size, stride=stride_size)\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.InstanceNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.shape\n",
    "\n",
    "        # FIXME look at relaxing size constraints\n",
    "        assert H == self.img_size[0] and W == self.img_size[1], \\\n",
    "            f\"Input image size ({H}*{W}) doesn't match model ({self.img_size[0]}*{self.img_size[1]}).\"\n",
    "        x = self.proj(x)\n",
    "\n",
    "        x = x.flatten(2).transpose(1, 2) # [64, 8, 768]\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "class TransReID(nn.Module):\n",
    "    \"\"\" Vision Transformer with support for patch or hybrid CNN input stage\n",
    "    \"\"\"\n",
    "    def __init__(self, img_size=224, patch_size=16, stride_size=16, in_chans=3, num_classes=1000, embed_dim=768, depth=12,\n",
    "                 num_heads=12, mlp_ratio=4., qkv_bias=False, qk_scale=None, drop_rate=0., attn_drop_rate=0.,\n",
    "                 drop_path_rate=0., hybrid_backbone=None, norm_layer=nn.LayerNorm,local_feature=False, aie_xishu =1.0):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.num_features = self.embed_dim = embed_dim  # num_features for consistency with other models\n",
    "        self.local_feature = local_feature\n",
    "        if hybrid_backbone is not None:\n",
    "            self.patch_embed = HybridEmbed(\n",
    "                hybrid_backbone, img_size=img_size, in_chans=in_chans, embed_dim=embed_dim)\n",
    "        else:\n",
    "            self.patch_embed = PatchEmbed_stride(\n",
    "                img_size=img_size, patch_size=patch_size, stride_size=stride_size, in_chans=in_chans,\n",
    "                embed_dim=embed_dim)\n",
    "\n",
    "        num_patches = self.patch_embed.num_patches\n",
    "        self.cls_token = nn.Parameter(torch.zeros(1, 1, embed_dim))\n",
    "        self.pos_embed = nn.Parameter(torch.zeros(1, num_patches + 1, embed_dim))\n",
    "\n",
    "        print('using drop_path_rate is : {}'.format(drop_path_rate))\n",
    "        print('using aie_xishu is : {}'.format(aie_xishu))\n",
    "        self.pos_drop = nn.Dropout(p=drop_rate)\n",
    "        print('embed_diim {} mlp_ratio {}'.format(embed_dim, mlp_ratio))\n",
    "        dpr = [x.item() for x in torch.linspace(0, drop_path_rate, depth)]  # stochastic depth decay rule\n",
    "        self.blocks = nn.ModuleList([\n",
    "            Block(\n",
    "                dim=embed_dim, num_heads=num_heads, mlp_ratio=mlp_ratio, qkv_bias=qkv_bias, qk_scale=qk_scale,\n",
    "                drop=drop_rate, attn_drop=attn_drop_rate, drop_path=dpr[i], norm_layer=norm_layer)\n",
    "            for i in range(depth)])\n",
    "\n",
    "        self.norm = norm_layer(embed_dim)\n",
    "        self.AIE_MULTI = aie_xishu\n",
    "        # Classifier head\n",
    "        self.fc = nn.Linear(embed_dim, num_classes) if num_classes > 0 else nn.Identity()\n",
    "        trunc_normal_(self.cls_token, std=.02) # 0.01 better\n",
    "        trunc_normal_(self.pos_embed, std=.02)\n",
    "\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            trunc_normal_(m.weight, std=.02) # 0.01 bette # 0.01 betterr\n",
    "            if isinstance(m, nn.Linear) and m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.LayerNorm):\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "            nn.init.constant_(m.weight, 1.0)\n",
    "\n",
    "    @torch.jit.ignore\n",
    "    def no_weight_decay(self):\n",
    "        return {'pos_embed', 'cls_token'}\n",
    "\n",
    "    def get_classifier(self):\n",
    "        return self.head\n",
    "\n",
    "    def reset_classifier(self, num_classes, global_pool=''):\n",
    "        self.num_classes = num_classes\n",
    "        self.fc = nn.Linear(self.embed_dim, num_classes) if num_classes > 0 else nn.Identity()\n",
    "\n",
    "    def forward_features(self, x, camera_id, view_id):\n",
    "        B = x.shape[0]\n",
    "        x = self.patch_embed(x)\n",
    "\n",
    "        cls_tokens = self.cls_token.expand(B, -1, -1)  # stole cls_tokens impl from Phil Wang, thanks\n",
    "        x = torch.cat((cls_tokens, x), dim=1)\n",
    "        x = x + self.pos_embed\n",
    "        x = self.pos_drop(x)\n",
    "        if self.local_feature:\n",
    "            for blk in self.blocks[:-1]:\n",
    "                x = blk(x)\n",
    "            return x\n",
    "        else:\n",
    "            for blk in self.blocks:\n",
    "                x = blk(x)\n",
    "            x = self.norm(x)\n",
    "            return x[:, 0]\n",
    "\n",
    "    def forward(self, x, cam_label=None, view_label=None):\n",
    "        x = self.forward_features(x, cam_label, view_label)\n",
    "        return x\n",
    "\n",
    "    def load_param(self, model_path):\n",
    "        param_dict = torch.load(model_path, map_location='cpu')\n",
    "        if 'model' in param_dict:\n",
    "            param_dict = param_dict['model']\n",
    "\n",
    "        if 'state_dict' in param_dict:\n",
    "            param_dict = param_dict['state_dict']\n",
    "\n",
    "        for k, v in param_dict.items():\n",
    "            if 'head' in k or 'dist' in k:\n",
    "                continue\n",
    "            if 'patch_embed.proj.weight' in k and len(v.shape) < 4:\n",
    "                # For old models that I trained prior to conv based patchification\n",
    "                O, I, H, W = self.patch_embed.proj.weight.shape\n",
    "                v = v.reshape(O, -1, H, W)\n",
    "            elif k == 'pos_embed' and v.shape != self.pos_embed.shape:\n",
    "                # To resize pos embedding when using model at different size from pretrained weights\n",
    "                if 'distilled' in model_path:\n",
    "                    print('distill need to choose right cls token in the pth')\n",
    "                    v = torch.cat([v[:, 0:1], v[:, 2:]], dim=1)\n",
    "                v = resize_pos_embed(v, self.pos_embed, self.patch_embed.num_y, self.patch_embed.num_x)\n",
    "                # self.state_dict()[k].copy_(revise)\n",
    "            try:\n",
    "                self.state_dict()[k].copy_(v)\n",
    "            except:\n",
    "                print('===========================ERROR=========================')\n",
    "                print('shape do not match in k :{}: param_dict{} vs self.state_dict(){}'.format(k, v.shape, self.state_dict()[k].shape))\n",
    "\n",
    "    def load_un_param(self, trained_path):\n",
    "        param_dict = torch.load(trained_path)\n",
    "        if 'state_dict' in param_dict:\n",
    "            param_dict = param_dict['state_dict']\n",
    "        for k in list(param_dict.keys()):\n",
    "            # retain only encoder_q up to before the embedding layer\n",
    "            if k.startswith('module.encoder_q') and not k.startswith('module.encoder_q.fc'):\n",
    "                # remove prefix\n",
    "                param_dict[k[len(\"module.encoder_q.\"):]] = param_dict[k]\n",
    "            # delete renamed or unused k\n",
    "            del param_dict[k]\n",
    "        for i in param_dict:\n",
    "            if 'fc' in i or 'head' in i:\n",
    "                continue\n",
    "            self.state_dict()[i].copy_(param_dict[i])\n",
    "\n",
    "def resize_pos_embed(posemb, posemb_new, hight, width):\n",
    "    # Rescale the grid of position embeddings when loading from state_dict. Adapted from\n",
    "    # https://github.com/google-research/vision_transformer/blob/00883dd691c63a6830751563748663526e811cee/vit_jax/checkpoint.py#L224\n",
    "    print('Resized position embedding: %s to %s', posemb.shape, posemb_new.shape)\n",
    "    ntok_new = posemb_new.shape[1]\n",
    "    if True:\n",
    "        posemb_tok, posemb_grid = posemb[:, :1], posemb[0, 1:]\n",
    "        ntok_new -= 1\n",
    "    else:\n",
    "        posemb_tok, posemb_grid = posemb[:, :0], posemb[0]\n",
    "    gs_old = int(math.sqrt(len(posemb_grid)))\n",
    "\n",
    "    print('Position embedding resize to height:{} width: {}'.format(hight, width))\n",
    "    posemb_grid = posemb_grid.reshape(1, gs_old, gs_old, -1).permute(0, 3, 1, 2)\n",
    "    posemb_grid = F.interpolate(posemb_grid, size=(hight, width), mode='bilinear')\n",
    "    # posemb_grid = F.interpolate(posemb_grid, size=(width, hight), mode='bilinear')\n",
    "    posemb_grid = posemb_grid.permute(0, 2, 3, 1).reshape(1, hight * width, -1)\n",
    "    posemb = torch.cat([posemb_tok, posemb_grid], dim=1)\n",
    "    return posemb\n",
    "\n",
    "def _conv_filter(state_dict, patch_size=16):\n",
    "    \"\"\" convert patch embedding weight from manual patchify + linear proj to conv\"\"\"\n",
    "    out_dict = {}\n",
    "    for k, v in state_dict.items():\n",
    "        if 'patch_embed.proj.weight' in k:\n",
    "            v = v.reshape((v.shape[0], 3, patch_size, patch_size))\n",
    "        out_dict[k] = v\n",
    "    return out_dict\n",
    "\n",
    "def vit_small_patch16_224_TransReID(img_size=(256, 128), stride_size=16, drop_path_rate=0.1, drop_rate=0.0, attn_drop_rate=0.0, local_feature=False, aie_xishu=1.5, **kwargs):\n",
    "    model = TransReID(\n",
    "        img_size=img_size, patch_size=16, stride_size=stride_size, embed_dim=384, depth=12, num_heads=6, mlp_ratio=4, qkv_bias=True,\n",
    "        drop_path_rate=drop_path_rate, drop_rate=drop_rate, attn_drop_rate=attn_drop_rate, aie_xishu=aie_xishu, local_feature=local_feature,\n",
    "        norm_layer=partial(nn.LayerNorm, eps=1e-6), **kwargs)\n",
    "\n",
    "    return model\n",
    "\n",
    "def vit_base_patch16_224_TransReID(img_size=(256, 128), stride_size=16, drop_path_rate=0.1, local_feature=False,aie_xishu=1.5, **kwargs):\n",
    "    model = TransReID(\n",
    "        img_size=img_size, patch_size=16, stride_size=stride_size, embed_dim=768, depth=12, num_heads=12, mlp_ratio=4, qkv_bias=True, drop_path_rate = drop_path_rate,\\\n",
    "        norm_layer=partial(nn.LayerNorm, eps=1e-6),  aie_xishu=aie_xishu, local_feature=local_feature, **kwargs)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def _no_grad_trunc_normal_(tensor, mean, std, a, b):\n",
    "    # Cut & paste from PyTorch official master until it's in a few official releases - RW\n",
    "    # Method based on https://people.sc.fsu.edu/~jburkardt/presentations/truncated_normal.pdf\n",
    "    def norm_cdf(x):\n",
    "        # Computes standard normal cumulative distribution function\n",
    "        return (1. + math.erf(x / math.sqrt(2.))) / 2.\n",
    "\n",
    "    if (mean < a - 2 * std) or (mean > b + 2 * std):\n",
    "        print(\"mean is more than 2 std from [a, b] in nn.init.trunc_normal_. \"\n",
    "                      \"The distribution of values may be incorrect.\",)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Values are generated by using a truncated uniform distribution and\n",
    "        # then using the inverse CDF for the normal distribution.\n",
    "        # Get upper and lower cdf values\n",
    "        l = norm_cdf((a - mean) / std)\n",
    "        u = norm_cdf((b - mean) / std)\n",
    "\n",
    "        # Uniformly fill tensor with values from [l, u], then translate to\n",
    "        # [2l-1, 2u-1].\n",
    "        tensor.uniform_(2 * l - 1, 2 * u - 1)\n",
    "\n",
    "        # Use inverse cdf transform for normal distribution to get truncated\n",
    "        # standard normal\n",
    "        tensor.erfinv_()\n",
    "\n",
    "        # Transform to proper mean, std\n",
    "        tensor.mul_(std * math.sqrt(2.))\n",
    "        tensor.add_(mean)\n",
    "\n",
    "        # Clamp to ensure it's in the proper range\n",
    "        tensor.clamp_(min=a, max=b)\n",
    "        return tensor\n",
    "\n",
    "def trunc_normal_(tensor, mean=0., std=1., a=-2., b=2.):\n",
    "    # type: (Tensor, float, float, float, float) -> Tensor\n",
    "    r\"\"\"Fills the input Tensor with values drawn from a truncated\n",
    "    normal distribution. The values are effectively drawn from the\n",
    "    normal distribution :math:`\\mathcal{N}(\\text{mean}, \\text{std}^2)`\n",
    "    with values outside :math:`[a, b]` redrawn until they are within\n",
    "    the bounds. The method used for generating the random values works\n",
    "    best when :math:`a \\leq \\text{mean} \\leq b`.\n",
    "    Args:\n",
    "        tensor: an n-dimensional `torch.Tensor`\n",
    "        mean: the mean of the normal distribution\n",
    "        std: the standard deviation of the normal distribution\n",
    "        a: the minimum cutoff value\n",
    "        b: the maximum cutoff value\n",
    "    Examples:\n",
    "        >>> w = torch.empty(3, 5)\n",
    "        >>> nn.init.trunc_normal_(w)\n",
    "    \"\"\"\n",
    "    return _no_grad_trunc_normal_(tensor, mean, std, a, b)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "cellView": "form",
    "id": "jMJxg1IHxtLM",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#@title ViT model create\n",
    "factory_hh = {\n",
    "    'vit_base_patch16_224_TransReID': vit_base_patch16_224_TransReID,\n",
    "    'vit_small_patch16_224_TransReID': vit_small_patch16_224_TransReID,\n",
    "    # 'resnet101': resnet101,\n",
    "}\n",
    "def weights_init_kaiming(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Linear') != -1:\n",
    "        nn.init.kaiming_normal_(m.weight, a=0, mode='fan_out')\n",
    "        nn.init.constant_(m.bias, 0.0)\n",
    "\n",
    "    elif classname.find('Conv') != -1:\n",
    "        nn.init.kaiming_normal_(m.weight, a=0, mode='fan_in')\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias, 0.0)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        if m.affine:\n",
    "            nn.init.constant_(m.weight, 1.0)\n",
    "            nn.init.constant_(m.bias, 0.0)\n",
    "\n",
    "def weights_init_classifier(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Linear') != -1:\n",
    "        nn.init.normal_(m.weight, std=0.001)\n",
    "        if m.bias:\n",
    "            nn.init.constant_(m.bias, 0.0)\n",
    "class build_transformer(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(build_transformer, self).__init__()\n",
    "        last_stride = 1\n",
    "        #model_path = cfg.MODEL.PRETRAIN_PATH\n",
    "        model_name = \"transformer\"\n",
    "        pretrain_choice = \"imagenet\"\n",
    "        self.cos_layer = False\n",
    "        self.neck = \"bnneck\"\n",
    "        self.neck_feat = \"after\"\n",
    "        self.task_type = \"classify_DA\"\n",
    "        self.in_planes = 384\n",
    "        self.bottleneck_dim = 256\n",
    "        print('using Transformer_type: {} as a backbone'.format(\"vit_small_patch16_224_TransReID\"))\n",
    "\n",
    "        self.base = factory_hh[\"vit_small_patch16_224_TransReID\"](img_size=224, aie_xishu=1.5,local_feature=False, stride_size=[16, 16], drop_path_rate=0.1)\n",
    "\n",
    "        self.gap = nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "        self.ID_LOSS_TYPE = \"softmax\"\n",
    "        if self.ID_LOSS_TYPE == 'arcface':\n",
    "            print('using {} with s:{}, m: {}'.format(self.ID_LOSS_TYPE,cfg.SOLVER.COSINE_SCALE,cfg.SOLVER.COSINE_MARGIN))\n",
    "            self.classifier = Arcface(self.in_planes, self.num_classes,\n",
    "                                    s=cfg.SOLVER.COSINE_SCALE, m=cfg.SOLVER.COSINE_MARGIN)\n",
    "        elif self.ID_LOSS_TYPE == 'cosface':\n",
    "            print('using {} with s:{}, m: {}'.format(self.ID_LOSS_TYPE,cfg.SOLVER.COSINE_SCALE,cfg.SOLVER.COSINE_MARGIN))\n",
    "            self.classifier = Cosface(self.in_planes, self.num_classes,\n",
    "                                    s=cfg.SOLVER.COSINE_SCALE, m=cfg.SOLVER.COSINE_MARGIN)\n",
    "        elif self.ID_LOSS_TYPE == 'amsoftmax':\n",
    "            print('using {} with s:{}, m: {}'.format(self.ID_LOSS_TYPE,cfg.SOLVER.COSINE_SCALE,cfg.SOLVER.COSINE_MARGIN))\n",
    "            self.classifier = AMSoftmax(self.in_planes, self.num_classes,\n",
    "                                        s=cfg.SOLVER.COSINE_SCALE, m=cfg.SOLVER.COSINE_MARGIN)\n",
    "        elif self.ID_LOSS_TYPE == 'circle':\n",
    "            print('using {} with s:{}, m: {}'.format(self.ID_LOSS_TYPE, cfg.SOLVER.COSINE_SCALE, cfg.SOLVER.COSINE_MARGIN))\n",
    "            self.classifier = CircleLoss(self.in_planes, self.num_classes,\n",
    "                                        s=cfg.SOLVER.COSINE_SCALE, m=cfg.SOLVER.COSINE_MARGIN)\n",
    "        else:\n",
    "            self.classifier = nn.Linear(self.in_planes, self.num_classes, bias=False)\n",
    "            self.classifier.apply(weights_init_classifier)\n",
    "\n",
    "        self.bottleneck = nn.BatchNorm1d(self.in_planes)\n",
    "        self.bottleneck.bias.requires_grad_(False)\n",
    "        self.bottleneck.apply(weights_init_kaiming)\n",
    "\n",
    "        #self._load_parameter(pretrain_choice, model_path)\n",
    "\n",
    "    def _load_parameter(self, pretrain_choice, model_path):\n",
    "        if pretrain_choice == 'imagenet':\n",
    "            self.base.load_param(model_path)\n",
    "            print('Loading pretrained ImageNet model......from {}'.format(model_path))\n",
    "        elif pretrain_choice == 'un_pretrain':\n",
    "            self.base.load_un_param(model_path)\n",
    "            print('Loading trans_tune model......from {}'.format(model_path))\n",
    "        elif pretrain_choice == 'pretrain':\n",
    "            self.load_param_finetune(model_path)\n",
    "            print('Loading pretrained model......from {}'.format(model_path))\n",
    "\n",
    "    def forward(self, x, label=None, cam_label= None, view_label=None, return_logits=True):  # label is unused if self.cos_layer == 'no'\n",
    "        global_feat = self.base(x, cam_label=cam_label, view_label=view_label)\n",
    "        feat = self.bottleneck(global_feat)\n",
    "        if return_logits:\n",
    "            if self.cos_layer:\n",
    "                cls_score = self.arcface(feat, label)\n",
    "            else:\n",
    "                cls_score = self.classifier(feat)\n",
    "            return cls_score\n",
    "        elif self.training:\n",
    "            if self.ID_LOSS_TYPE in ('arcface', 'cosface', 'amsoftmax', 'circle'):\n",
    "                cls_score = self.classifier(feat, label)\n",
    "            else:\n",
    "                cls_score = self.classifier(feat)\n",
    "\n",
    "            return cls_score, global_feat  # global feature for triplet loss\n",
    "        else:\n",
    "            if self.neck_feat == 'after':\n",
    "                # print(\"Test with feature after BN\")\n",
    "                return feat\n",
    "            else:\n",
    "                # print(\"Test with feature before BN\")\n",
    "                return global_feat\n",
    "\n",
    "    def load_param(self, param_dict):\n",
    "        #param_dict = torch.load(trained_path)\n",
    "        print(self.state_dict().keys())\n",
    "        print(param_dict.keys())\n",
    "        for i in param_dict:\n",
    "            if 'classifier' in i or 'arcface' in i or 'bottleneck' in i or 'gap' in i:\n",
    "                continue\n",
    "            #self.state_dict()[i.replace('module.', '')].copy_(param_dict[i])\n",
    "            if(i in self.state_dict()):\n",
    "              self.state_dict()[i.replace('base.', '')].copy_(param_dict[i])\n",
    "        #print('Loading pretrained model from {}'.format(trained_path))\n",
    "\n",
    "\n",
    "    def load_param_finetune(self, model_path):\n",
    "        param_dict = torch.load(model_path)\n",
    "        for i in param_dict:\n",
    "            if 'module.' in i: new_i = i.replace('module.','')\n",
    "            else: new_i = i\n",
    "            if new_i not in self.state_dict().keys():\n",
    "                print('model parameter: {} not match'.format(new_i))\n",
    "                continue\n",
    "            self.state_dict()[new_i].copy_(param_dict[i])\n",
    "        print('Loading pretrained model for finetuning from {}'.format(model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "cellView": "form",
    "id": "qrIf5jw54xOh",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#@title mobilenet\n",
    "def _make_divisible(v, divisor, min_value=None):\n",
    "    \"\"\"\n",
    "    This function is taken from the original tf repo.\n",
    "    It ensures that all layers have a channel number that is divisible by 8\n",
    "    It can be seen here:\n",
    "    https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet/mobilenet.py\n",
    "    :param v:\n",
    "    :param divisor:\n",
    "    :param min_value:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if min_value is None:\n",
    "        min_value = divisor\n",
    "    new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n",
    "    # Make sure that round down does not go down by more than 10%.\n",
    "    if new_v < 0.9 * v:\n",
    "        new_v += divisor\n",
    "    return new_v\n",
    "\n",
    "\n",
    "def conv_3x3_bn(inp, oup, stride):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(inp, oup, 3, stride, 1, bias=False),\n",
    "        nn.BatchNorm2d(oup),\n",
    "        nn.ReLU6(inplace=True)\n",
    "    )\n",
    "\n",
    "\n",
    "def conv_1x1_bn(inp, oup):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(inp, oup, 1, 1, 0, bias=False),\n",
    "        nn.BatchNorm2d(oup),\n",
    "        nn.ReLU6(inplace=True)\n",
    "    )\n",
    "\n",
    "\n",
    "class InvertedResidual(nn.Module):\n",
    "    def __init__(self, inp, oup, stride, expand_ratio):\n",
    "        super(InvertedResidual, self).__init__()\n",
    "        assert stride in [1, 2]\n",
    "\n",
    "        hidden_dim = round(inp * expand_ratio)\n",
    "        self.identity = stride == 1 and inp == oup\n",
    "\n",
    "        if expand_ratio == 1:\n",
    "            self.conv = nn.Sequential(\n",
    "                # dw\n",
    "                nn.Conv2d(hidden_dim, hidden_dim, 3, stride, 1, groups=hidden_dim, bias=False),\n",
    "                nn.BatchNorm2d(hidden_dim),\n",
    "                nn.ReLU6(inplace=True),\n",
    "                # pw-linear\n",
    "                nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n",
    "                nn.BatchNorm2d(oup),\n",
    "            )\n",
    "        else:\n",
    "            self.conv = nn.Sequential(\n",
    "                # pw\n",
    "                nn.Conv2d(inp, hidden_dim, 1, 1, 0, bias=False),\n",
    "                nn.BatchNorm2d(hidden_dim),\n",
    "                nn.ReLU6(inplace=True),\n",
    "                # dw\n",
    "                nn.Conv2d(hidden_dim, hidden_dim, 3, stride, 1, groups=hidden_dim, bias=False),\n",
    "                nn.BatchNorm2d(hidden_dim),\n",
    "                nn.ReLU6(inplace=True),\n",
    "                # pw-linear\n",
    "                nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n",
    "                nn.BatchNorm2d(oup),\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.identity:\n",
    "            return x + self.conv(x)\n",
    "        else:\n",
    "            return self.conv(x)\n",
    "\n",
    "\n",
    "class MobileNetV2(nn.Module):\n",
    "    def __init__(self, num_classes=1000, width_mult=1.):\n",
    "        super(MobileNetV2, self).__init__()\n",
    "        # setting of inverted residual blocks\n",
    "        self.cfgs = [\n",
    "            # t, c, n, s\n",
    "            [1,  16, 1, 1],\n",
    "            [6,  24, 2, 2],\n",
    "            [6,  32, 3, 2],\n",
    "            [6,  64, 4, 2],\n",
    "            [6,  96, 3, 1],\n",
    "            [6, 160, 3, 2],\n",
    "            [6, 320, 1, 1],\n",
    "        ]\n",
    "\n",
    "        # building first layer\n",
    "        input_channel = _make_divisible(32 * width_mult, 4 if width_mult == 0.1 else 8)\n",
    "        layers = [conv_3x3_bn(3, input_channel, 2)]\n",
    "        # building inverted residual blocks\n",
    "        block = InvertedResidual\n",
    "        for t, c, n, s in self.cfgs:\n",
    "            output_channel = _make_divisible(c * width_mult, 4 if width_mult == 0.1 else 8)\n",
    "            for i in range(n):\n",
    "                layers.append(block(input_channel, output_channel, s if i == 0 else 1, t))\n",
    "                input_channel = output_channel\n",
    "        self.features = nn.Sequential(*layers)\n",
    "        # building last several layers\n",
    "        output_channel = _make_divisible(1280 * width_mult, 4 if width_mult == 0.1 else 8) if width_mult > 1.0 else 1280\n",
    "        self.conv = conv_1x1_bn(input_channel, output_channel)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.classifier = nn.Linear(output_channel, num_classes)\n",
    "\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.conv(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                m.weight.data.normal_(0, 0.01)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "def mobilenetv2(**kwargs):\n",
    "    \"\"\"\n",
    "    Constructs a MobileNet V2 model\n",
    "    \"\"\"\n",
    "    return MobileNetV2(**kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NCciymuJwjIs",
    "jupyter": {
     "source_hidden": true
    },
    "outputId": "7a9404af-2a04-4e32-99b6-fbb9df170867"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using Transformer_type: vit_small_patch16_224_TransReID as a backbone\n",
      "using stride: [16, 16], and part number is num_y14 * num_x14\n",
      "using drop_path_rate is : 0.1\n",
      "using aie_xishu is : 1.5\n",
      "embed_diim 384 mlp_ratio 4\n",
      "odict_keys(['base.cls_token', 'base.pos_embed', 'base.patch_embed.proj.weight', 'base.patch_embed.proj.bias', 'base.blocks.0.norm1.weight', 'base.blocks.0.norm1.bias', 'base.blocks.0.attn.qkv.weight', 'base.blocks.0.attn.qkv.bias', 'base.blocks.0.attn.proj.weight', 'base.blocks.0.attn.proj.bias', 'base.blocks.0.norm2.weight', 'base.blocks.0.norm2.bias', 'base.blocks.0.mlp.fc1.weight', 'base.blocks.0.mlp.fc1.bias', 'base.blocks.0.mlp.fc2.weight', 'base.blocks.0.mlp.fc2.bias', 'base.blocks.1.norm1.weight', 'base.blocks.1.norm1.bias', 'base.blocks.1.attn.qkv.weight', 'base.blocks.1.attn.qkv.bias', 'base.blocks.1.attn.proj.weight', 'base.blocks.1.attn.proj.bias', 'base.blocks.1.norm2.weight', 'base.blocks.1.norm2.bias', 'base.blocks.1.mlp.fc1.weight', 'base.blocks.1.mlp.fc1.bias', 'base.blocks.1.mlp.fc2.weight', 'base.blocks.1.mlp.fc2.bias', 'base.blocks.2.norm1.weight', 'base.blocks.2.norm1.bias', 'base.blocks.2.attn.qkv.weight', 'base.blocks.2.attn.qkv.bias', 'base.blocks.2.attn.proj.weight', 'base.blocks.2.attn.proj.bias', 'base.blocks.2.norm2.weight', 'base.blocks.2.norm2.bias', 'base.blocks.2.mlp.fc1.weight', 'base.blocks.2.mlp.fc1.bias', 'base.blocks.2.mlp.fc2.weight', 'base.blocks.2.mlp.fc2.bias', 'base.blocks.3.norm1.weight', 'base.blocks.3.norm1.bias', 'base.blocks.3.attn.qkv.weight', 'base.blocks.3.attn.qkv.bias', 'base.blocks.3.attn.proj.weight', 'base.blocks.3.attn.proj.bias', 'base.blocks.3.norm2.weight', 'base.blocks.3.norm2.bias', 'base.blocks.3.mlp.fc1.weight', 'base.blocks.3.mlp.fc1.bias', 'base.blocks.3.mlp.fc2.weight', 'base.blocks.3.mlp.fc2.bias', 'base.blocks.4.norm1.weight', 'base.blocks.4.norm1.bias', 'base.blocks.4.attn.qkv.weight', 'base.blocks.4.attn.qkv.bias', 'base.blocks.4.attn.proj.weight', 'base.blocks.4.attn.proj.bias', 'base.blocks.4.norm2.weight', 'base.blocks.4.norm2.bias', 'base.blocks.4.mlp.fc1.weight', 'base.blocks.4.mlp.fc1.bias', 'base.blocks.4.mlp.fc2.weight', 'base.blocks.4.mlp.fc2.bias', 'base.blocks.5.norm1.weight', 'base.blocks.5.norm1.bias', 'base.blocks.5.attn.qkv.weight', 'base.blocks.5.attn.qkv.bias', 'base.blocks.5.attn.proj.weight', 'base.blocks.5.attn.proj.bias', 'base.blocks.5.norm2.weight', 'base.blocks.5.norm2.bias', 'base.blocks.5.mlp.fc1.weight', 'base.blocks.5.mlp.fc1.bias', 'base.blocks.5.mlp.fc2.weight', 'base.blocks.5.mlp.fc2.bias', 'base.blocks.6.norm1.weight', 'base.blocks.6.norm1.bias', 'base.blocks.6.attn.qkv.weight', 'base.blocks.6.attn.qkv.bias', 'base.blocks.6.attn.proj.weight', 'base.blocks.6.attn.proj.bias', 'base.blocks.6.norm2.weight', 'base.blocks.6.norm2.bias', 'base.blocks.6.mlp.fc1.weight', 'base.blocks.6.mlp.fc1.bias', 'base.blocks.6.mlp.fc2.weight', 'base.blocks.6.mlp.fc2.bias', 'base.blocks.7.norm1.weight', 'base.blocks.7.norm1.bias', 'base.blocks.7.attn.qkv.weight', 'base.blocks.7.attn.qkv.bias', 'base.blocks.7.attn.proj.weight', 'base.blocks.7.attn.proj.bias', 'base.blocks.7.norm2.weight', 'base.blocks.7.norm2.bias', 'base.blocks.7.mlp.fc1.weight', 'base.blocks.7.mlp.fc1.bias', 'base.blocks.7.mlp.fc2.weight', 'base.blocks.7.mlp.fc2.bias', 'base.blocks.8.norm1.weight', 'base.blocks.8.norm1.bias', 'base.blocks.8.attn.qkv.weight', 'base.blocks.8.attn.qkv.bias', 'base.blocks.8.attn.proj.weight', 'base.blocks.8.attn.proj.bias', 'base.blocks.8.norm2.weight', 'base.blocks.8.norm2.bias', 'base.blocks.8.mlp.fc1.weight', 'base.blocks.8.mlp.fc1.bias', 'base.blocks.8.mlp.fc2.weight', 'base.blocks.8.mlp.fc2.bias', 'base.blocks.9.norm1.weight', 'base.blocks.9.norm1.bias', 'base.blocks.9.attn.qkv.weight', 'base.blocks.9.attn.qkv.bias', 'base.blocks.9.attn.proj.weight', 'base.blocks.9.attn.proj.bias', 'base.blocks.9.norm2.weight', 'base.blocks.9.norm2.bias', 'base.blocks.9.mlp.fc1.weight', 'base.blocks.9.mlp.fc1.bias', 'base.blocks.9.mlp.fc2.weight', 'base.blocks.9.mlp.fc2.bias', 'base.blocks.10.norm1.weight', 'base.blocks.10.norm1.bias', 'base.blocks.10.attn.qkv.weight', 'base.blocks.10.attn.qkv.bias', 'base.blocks.10.attn.proj.weight', 'base.blocks.10.attn.proj.bias', 'base.blocks.10.norm2.weight', 'base.blocks.10.norm2.bias', 'base.blocks.10.mlp.fc1.weight', 'base.blocks.10.mlp.fc1.bias', 'base.blocks.10.mlp.fc2.weight', 'base.blocks.10.mlp.fc2.bias', 'base.blocks.11.norm1.weight', 'base.blocks.11.norm1.bias', 'base.blocks.11.attn.qkv.weight', 'base.blocks.11.attn.qkv.bias', 'base.blocks.11.attn.proj.weight', 'base.blocks.11.attn.proj.bias', 'base.blocks.11.norm2.weight', 'base.blocks.11.norm2.bias', 'base.blocks.11.mlp.fc1.weight', 'base.blocks.11.mlp.fc1.bias', 'base.blocks.11.mlp.fc2.weight', 'base.blocks.11.mlp.fc2.bias', 'base.norm.weight', 'base.norm.bias', 'base.fc.weight', 'base.fc.bias', 'classifier.weight', 'bottleneck.weight', 'bottleneck.bias', 'bottleneck.running_mean', 'bottleneck.running_var', 'bottleneck.num_batches_tracked'])\n",
      "odict_keys(['dist_token', 'cls_token', 'pos_embed', 'patch_embed.proj.weight', 'patch_embed.proj.bias', 'blocks.0.norm1.weight', 'blocks.0.norm1.bias', 'blocks.0.attn.qkv.weight', 'blocks.0.attn.qkv.bias', 'blocks.0.attn.proj.weight', 'blocks.0.attn.proj.bias', 'blocks.0.norm2.weight', 'blocks.0.norm2.bias', 'blocks.0.mlp.fc1.weight', 'blocks.0.mlp.fc1.bias', 'blocks.0.mlp.fc2.weight', 'blocks.0.mlp.fc2.bias', 'blocks.1.norm1.weight', 'blocks.1.norm1.bias', 'blocks.1.attn.qkv.weight', 'blocks.1.attn.qkv.bias', 'blocks.1.attn.proj.weight', 'blocks.1.attn.proj.bias', 'blocks.1.norm2.weight', 'blocks.1.norm2.bias', 'blocks.1.mlp.fc1.weight', 'blocks.1.mlp.fc1.bias', 'blocks.1.mlp.fc2.weight', 'blocks.1.mlp.fc2.bias', 'blocks.2.norm1.weight', 'blocks.2.norm1.bias', 'blocks.2.attn.qkv.weight', 'blocks.2.attn.qkv.bias', 'blocks.2.attn.proj.weight', 'blocks.2.attn.proj.bias', 'blocks.2.norm2.weight', 'blocks.2.norm2.bias', 'blocks.2.mlp.fc1.weight', 'blocks.2.mlp.fc1.bias', 'blocks.2.mlp.fc2.weight', 'blocks.2.mlp.fc2.bias', 'blocks.3.norm1.weight', 'blocks.3.norm1.bias', 'blocks.3.attn.qkv.weight', 'blocks.3.attn.qkv.bias', 'blocks.3.attn.proj.weight', 'blocks.3.attn.proj.bias', 'blocks.3.norm2.weight', 'blocks.3.norm2.bias', 'blocks.3.mlp.fc1.weight', 'blocks.3.mlp.fc1.bias', 'blocks.3.mlp.fc2.weight', 'blocks.3.mlp.fc2.bias', 'blocks.4.norm1.weight', 'blocks.4.norm1.bias', 'blocks.4.attn.qkv.weight', 'blocks.4.attn.qkv.bias', 'blocks.4.attn.proj.weight', 'blocks.4.attn.proj.bias', 'blocks.4.norm2.weight', 'blocks.4.norm2.bias', 'blocks.4.mlp.fc1.weight', 'blocks.4.mlp.fc1.bias', 'blocks.4.mlp.fc2.weight', 'blocks.4.mlp.fc2.bias', 'blocks.5.norm1.weight', 'blocks.5.norm1.bias', 'blocks.5.attn.qkv.weight', 'blocks.5.attn.qkv.bias', 'blocks.5.attn.proj.weight', 'blocks.5.attn.proj.bias', 'blocks.5.norm2.weight', 'blocks.5.norm2.bias', 'blocks.5.mlp.fc1.weight', 'blocks.5.mlp.fc1.bias', 'blocks.5.mlp.fc2.weight', 'blocks.5.mlp.fc2.bias', 'blocks.6.norm1.weight', 'blocks.6.norm1.bias', 'blocks.6.attn.qkv.weight', 'blocks.6.attn.qkv.bias', 'blocks.6.attn.proj.weight', 'blocks.6.attn.proj.bias', 'blocks.6.norm2.weight', 'blocks.6.norm2.bias', 'blocks.6.mlp.fc1.weight', 'blocks.6.mlp.fc1.bias', 'blocks.6.mlp.fc2.weight', 'blocks.6.mlp.fc2.bias', 'blocks.7.norm1.weight', 'blocks.7.norm1.bias', 'blocks.7.attn.qkv.weight', 'blocks.7.attn.qkv.bias', 'blocks.7.attn.proj.weight', 'blocks.7.attn.proj.bias', 'blocks.7.norm2.weight', 'blocks.7.norm2.bias', 'blocks.7.mlp.fc1.weight', 'blocks.7.mlp.fc1.bias', 'blocks.7.mlp.fc2.weight', 'blocks.7.mlp.fc2.bias', 'blocks.8.norm1.weight', 'blocks.8.norm1.bias', 'blocks.8.attn.qkv.weight', 'blocks.8.attn.qkv.bias', 'blocks.8.attn.proj.weight', 'blocks.8.attn.proj.bias', 'blocks.8.norm2.weight', 'blocks.8.norm2.bias', 'blocks.8.mlp.fc1.weight', 'blocks.8.mlp.fc1.bias', 'blocks.8.mlp.fc2.weight', 'blocks.8.mlp.fc2.bias', 'blocks.9.norm1.weight', 'blocks.9.norm1.bias', 'blocks.9.attn.qkv.weight', 'blocks.9.attn.qkv.bias', 'blocks.9.attn.proj.weight', 'blocks.9.attn.proj.bias', 'blocks.9.norm2.weight', 'blocks.9.norm2.bias', 'blocks.9.mlp.fc1.weight', 'blocks.9.mlp.fc1.bias', 'blocks.9.mlp.fc2.weight', 'blocks.9.mlp.fc2.bias', 'blocks.10.norm1.weight', 'blocks.10.norm1.bias', 'blocks.10.attn.qkv.weight', 'blocks.10.attn.qkv.bias', 'blocks.10.attn.proj.weight', 'blocks.10.attn.proj.bias', 'blocks.10.norm2.weight', 'blocks.10.norm2.bias', 'blocks.10.mlp.fc1.weight', 'blocks.10.mlp.fc1.bias', 'blocks.10.mlp.fc2.weight', 'blocks.10.mlp.fc2.bias', 'blocks.11.norm1.weight', 'blocks.11.norm1.bias', 'blocks.11.attn.qkv.weight', 'blocks.11.attn.qkv.bias', 'blocks.11.attn.proj.weight', 'blocks.11.attn.proj.bias', 'blocks.11.norm2.weight', 'blocks.11.norm2.bias', 'blocks.11.mlp.fc1.weight', 'blocks.11.mlp.fc1.bias', 'blocks.11.mlp.fc2.weight', 'blocks.11.mlp.fc2.bias', 'norm.weight', 'norm.bias', 'head.weight', 'head.bias', 'head_dist.weight', 'head_dist.bias'])\n"
     ]
    }
   ],
   "source": [
    "ViT = build_transformer(num_classes = 5)\n",
    "state_dict = load_state_dict_from_url(\"https://dl.fbaipublicfiles.com/deit/deit_small_distilled_patch16_224-649709d9.pth\", progress=True)\n",
    "ViT.load_param(state_dict[\"model\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "cellView": "form",
    "id": "4fcdcd5f"
   },
   "outputs": [],
   "source": [
    "#@title Train Function\n",
    "def train_model_classification(\n",
    "    model, dataloaders, criterion, optimizer, scheduler, device, num_epochs=25, is_inception=False\n",
    "):\n",
    "    loss_list = []\n",
    "    acc_list = []\n",
    "    res = []\n",
    "    training_res = []\n",
    "\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0\n",
    "    best_train_acc = 0\n",
    "\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(\"Epoch {}/{}\".format(epoch, num_epochs - 1))\n",
    "        print(\"-\" * 10)\n",
    "\n",
    "        running_corr = [0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "        running_total = [0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "        running_res = []\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in [\"train\", \"val\", \"test\"]:\n",
    "            if phase == \"train\":\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()  # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            count_3 = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            print(\"expecting data\")\n",
    "            running_corr = [0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "            running_total = [0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "            for (inputs,wt_l), labels in tqdm(dataloaders[phase]):\n",
    "\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                wt_l = wt_l.to(device).float()\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == \"train\"):\n",
    "                    # Get model outputs and calculate loss\n",
    "                    # Special case for inception because in training it has an auxiliary output. In train\n",
    "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
    "                    #   but in testing we only consider the final output.\n",
    "                    if is_inception and phase == \"train\":\n",
    "                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
    "                        #outputs, aux_outputs = model(inputs, wt_l)\n",
    "                        outputs = model(wt_l)#inputs)\n",
    "                        loss1 = criterion(outputs, labels)\n",
    "                        \n",
    "                        #loss2 = criterion(aux_outputs, labels)\n",
    "                        loss = loss1 #+ 0.4 * loss2\n",
    "                    else:\n",
    "                        #outputs = model(inputs)#, wt_l)\n",
    "                        outputs = model(wt_l)#, wt_l)\n",
    "                        outputs = torch.squeeze(outputs)\n",
    "\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == \"train\":\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "\n",
    "                # statistics\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "                for i in range(0, len(preds)):\n",
    "                    if labels.data[i].cpu().detach().numpy() == 3:\n",
    "                        count_3 += 1\n",
    "\n",
    "                    if preds[i] == labels.data[i]:\n",
    "                        running_corr[int(labels.data[i].cpu().detach().numpy())] += 1.0\n",
    "                    running_total[int(labels.data[i].cpu().detach().numpy())] += 1.0\n",
    "            print(running_total)\n",
    "\n",
    "            scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = 100.0 * running_corrects / len(dataloaders[phase].dataset)\n",
    "            running_res = [100.0 * i / max(1,j) for i, j in zip(running_corr, running_total)]\n",
    "            print(running_res)\n",
    "\n",
    "            print(\"{} Loss: {:.4f} Average Accuracy: {:.4f}\".format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == \"train\" and epoch_acc > best_train_acc:\n",
    "                best_train_acc = epoch_acc\n",
    "                training_res = running_res.copy()\n",
    "\n",
    "            if phase == \"val\" and epoch_acc >= best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                res = running_res.copy()\n",
    "                torch.save(model.state_dict(), 'F:/Scales/inception_v3_classification_image_only_temp.pth')\n",
    "\n",
    "            if phase == \"val\":\n",
    "                loss_list.append(epoch_loss)\n",
    "                acc_list.append(epoch_acc.cpu().clone().numpy())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(\n",
    "        \"Training complete in {:.0f}m {:.0f}s\".format(\n",
    "            time_elapsed // 60, time_elapsed % 60\n",
    "        )\n",
    "    )\n",
    "    print(\"Best Accuracy: {:4f}\".format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "\n",
    "    # plt.plot(loss_list, error_list)\n",
    "    return [model, loss_list, acc_list, res, training_res]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title simplenet\n",
    "class SimpleNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(3, 120)  # 5*5 from image dimension\n",
    "        self.fc2 = nn.Linear(120, 64)\n",
    "        self.fc3 = nn.Linear(64, 5)\n",
    "\n",
    "    def forward(self, input):\n",
    "        f1 = F.relu(self.fc1(input))\n",
    "        f2 = F.relu(self.fc2(f1))\n",
    "        f3 = self.fc3(f2)\n",
    "        \n",
    "        return f3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aotia\\AppData\\Local\\Temp\\ipykernel_15872\\2729715631.py:633: UserWarning: Overwriting tiny_vit_5m_224 in registry with __main__.tiny_vit_5m_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  def tiny_vit_5m_224(pretrained=False, **kwargs):\n",
      "C:\\Users\\aotia\\AppData\\Local\\Temp\\ipykernel_15872\\2729715631.py:646: UserWarning: Overwriting tiny_vit_11m_224 in registry with __main__.tiny_vit_11m_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  def tiny_vit_11m_224(pretrained=False, **kwargs):\n",
      "C:\\Users\\aotia\\AppData\\Local\\Temp\\ipykernel_15872\\2729715631.py:659: UserWarning: Overwriting tiny_vit_21m_224 in registry with __main__.tiny_vit_21m_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  def tiny_vit_21m_224(pretrained=False, **kwargs):\n",
      "C:\\Users\\aotia\\AppData\\Local\\Temp\\ipykernel_15872\\2729715631.py:672: UserWarning: Overwriting tiny_vit_21m_384 in registry with __main__.tiny_vit_21m_384. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  def tiny_vit_21m_384(pretrained=False, **kwargs):\n",
      "C:\\Users\\aotia\\AppData\\Local\\Temp\\ipykernel_15872\\2729715631.py:686: UserWarning: Overwriting tiny_vit_21m_512 in registry with __main__.tiny_vit_21m_512. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  def tiny_vit_21m_512(pretrained=False, **kwargs):\n"
     ]
    }
   ],
   "source": [
    "#@title TinyVit\n",
    "import itertools\n",
    "from typing import Tuple\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.checkpoint as checkpoint\n",
    "import timm\n",
    "from timm.models.layers import DropPath as TimmDropPath,\\\n",
    "    to_2tuple, trunc_normal_\n",
    "from timm.models.registry import register_model\n",
    "try:\n",
    "    # timm.__version__ >= \"0.6\"\n",
    "    from timm.models._builder import build_model_with_cfg\n",
    "except (ImportError, ModuleNotFoundError):\n",
    "    # timm.__version__ < \"0.6\"\n",
    "    from timm.models.helpers import build_model_with_cfg\n",
    "\n",
    "\n",
    "class Conv2d_BN(torch.nn.Sequential):\n",
    "    def __init__(self, a, b, ks=1, stride=1, pad=0, dilation=1,\n",
    "                 groups=1, bn_weight_init=1):\n",
    "        super().__init__()\n",
    "        self.add_module('c', torch.nn.Conv2d(\n",
    "            a, b, ks, stride, pad, dilation, groups, bias=False))\n",
    "        bn = torch.nn.BatchNorm2d(b)\n",
    "        torch.nn.init.constant_(bn.weight, bn_weight_init)\n",
    "        torch.nn.init.constant_(bn.bias, 0)\n",
    "        self.add_module('bn', bn)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def fuse(self):\n",
    "        c, bn = self._modules.values()\n",
    "        w = bn.weight / (bn.running_var + bn.eps)**0.5\n",
    "        w = c.weight * w[:, None, None, None]\n",
    "        b = bn.bias - bn.running_mean * bn.weight / \\\n",
    "            (bn.running_var + bn.eps)**0.5\n",
    "        m = torch.nn.Conv2d(w.size(1) * self.c.groups, w.size(\n",
    "            0), w.shape[2:], stride=self.c.stride, padding=self.c.padding, dilation=self.c.dilation, groups=self.c.groups)\n",
    "        m.weight.data.copy_(w)\n",
    "        m.bias.data.copy_(b)\n",
    "        return m\n",
    "\n",
    "\n",
    "class DropPath(TimmDropPath):\n",
    "    def __init__(self, drop_prob=None):\n",
    "        super().__init__(drop_prob=drop_prob)\n",
    "        self.drop_prob = drop_prob\n",
    "\n",
    "    def __repr__(self):\n",
    "        msg = super().__repr__()\n",
    "        msg += f'(drop_prob={self.drop_prob})'\n",
    "        return msg\n",
    "\n",
    "\n",
    "class PatchEmbed(nn.Module):\n",
    "    def __init__(self, in_chans, embed_dim, resolution, activation):\n",
    "        super().__init__()\n",
    "        img_size: Tuple[int, int] = to_2tuple(resolution)\n",
    "        self.patches_resolution = (img_size[0] // 4, img_size[1] // 4)\n",
    "        self.num_patches = self.patches_resolution[0] * \\\n",
    "            self.patches_resolution[1]\n",
    "        self.in_chans = in_chans\n",
    "        self.embed_dim = embed_dim\n",
    "        n = embed_dim\n",
    "        self.seq = nn.Sequential(\n",
    "            Conv2d_BN(in_chans, n // 2, 3, 2, 1),\n",
    "            activation(),\n",
    "            Conv2d_BN(n // 2, n, 3, 2, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.seq(x)\n",
    "\n",
    "\n",
    "class MBConv(nn.Module):\n",
    "    def __init__(self, in_chans, out_chans, expand_ratio,\n",
    "                 activation, drop_path):\n",
    "        super().__init__()\n",
    "        self.in_chans = in_chans\n",
    "        self.hidden_chans = int(in_chans * expand_ratio)\n",
    "        self.out_chans = out_chans\n",
    "\n",
    "        self.conv1 = Conv2d_BN(in_chans, self.hidden_chans, ks=1)\n",
    "        self.act1 = activation()\n",
    "\n",
    "        self.conv2 = Conv2d_BN(self.hidden_chans, self.hidden_chans,\n",
    "                               ks=3, stride=1, pad=1, groups=self.hidden_chans)\n",
    "        self.act2 = activation()\n",
    "\n",
    "        self.conv3 = Conv2d_BN(\n",
    "            self.hidden_chans, out_chans, ks=1, bn_weight_init=0.0)\n",
    "        self.act3 = activation()\n",
    "\n",
    "        self.drop_path = DropPath(\n",
    "            drop_path) if drop_path > 0. else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        shortcut = x\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.act1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.act2(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "\n",
    "        x = self.drop_path(x)\n",
    "\n",
    "        x += shortcut\n",
    "        x = self.act3(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class PatchMerging(nn.Module):\n",
    "    def __init__(self, input_resolution, dim, out_dim, activation):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_resolution = input_resolution\n",
    "        self.dim = dim\n",
    "        self.out_dim = out_dim\n",
    "        self.act = activation()\n",
    "        self.conv1 = Conv2d_BN(dim, out_dim, 1, 1, 0)\n",
    "        self.conv2 = Conv2d_BN(out_dim, out_dim, 3, 2, 1, groups=out_dim)\n",
    "        self.conv3 = Conv2d_BN(out_dim, out_dim, 1, 1, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if x.ndim == 3:\n",
    "            H, W = self.input_resolution\n",
    "            B = len(x)\n",
    "            # (B, C, H, W)\n",
    "            x = x.view(B, H, W, -1).permute(0, 3, 1, 2)\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.act(x)\n",
    "        x = self.conv3(x)\n",
    "\n",
    "        x = x.flatten(2).transpose(1, 2)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ConvLayer(nn.Module):\n",
    "    def __init__(self, dim, input_resolution, depth,\n",
    "                 activation,\n",
    "                 drop_path=0., downsample=None, use_checkpoint=False,\n",
    "                 out_dim=None,\n",
    "                 conv_expand_ratio=4.,\n",
    "                 ):\n",
    "\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.input_resolution = input_resolution\n",
    "        self.depth = depth\n",
    "        self.use_checkpoint = use_checkpoint\n",
    "\n",
    "        # build blocks\n",
    "        self.blocks = nn.ModuleList([\n",
    "            MBConv(dim, dim, conv_expand_ratio, activation,\n",
    "                   drop_path[i] if isinstance(drop_path, list) else drop_path,\n",
    "                   )\n",
    "            for i in range(depth)])\n",
    "\n",
    "        # patch merging layer\n",
    "        if downsample is not None:\n",
    "            self.downsample = downsample(\n",
    "                input_resolution, dim=dim, out_dim=out_dim, activation=activation)\n",
    "        else:\n",
    "            self.downsample = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        for blk in self.blocks:\n",
    "            if self.use_checkpoint:\n",
    "                x = checkpoint.checkpoint(blk, x)\n",
    "            else:\n",
    "                x = blk(x)\n",
    "        if self.downsample is not None:\n",
    "            x = self.downsample(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Mlp(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features=None,\n",
    "                 out_features=None, act_layer=nn.GELU, drop=0.):\n",
    "        super().__init__()\n",
    "        out_features = out_features or in_features\n",
    "        hidden_features = hidden_features or in_features\n",
    "        self.norm = nn.LayerNorm(in_features)\n",
    "        self.fc1 = nn.Linear(in_features, hidden_features)\n",
    "        self.fc2 = nn.Linear(hidden_features, out_features)\n",
    "        self.act = act_layer()\n",
    "        self.drop = nn.Dropout(drop)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.norm(x)\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.drop(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Attention(torch.nn.Module):\n",
    "    def __init__(self, dim, key_dim, num_heads=8,\n",
    "                 attn_ratio=4,\n",
    "                 resolution=(14, 14),\n",
    "                 ):\n",
    "        super().__init__()\n",
    "        # (h, w)\n",
    "        assert isinstance(resolution, tuple) and len(resolution) == 2\n",
    "        self.num_heads = num_heads\n",
    "        self.scale = key_dim ** -0.5\n",
    "        self.key_dim = key_dim\n",
    "        self.nh_kd = nh_kd = key_dim * num_heads\n",
    "        self.d = int(attn_ratio * key_dim)\n",
    "        self.dh = int(attn_ratio * key_dim) * num_heads\n",
    "        self.attn_ratio = attn_ratio\n",
    "        h = self.dh + nh_kd * 2\n",
    "\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "        self.qkv = nn.Linear(dim, h)\n",
    "        self.proj = nn.Linear(self.dh, dim)\n",
    "\n",
    "        points = list(itertools.product(\n",
    "            range(resolution[0]), range(resolution[1])))\n",
    "        N = len(points)\n",
    "        attention_offsets = {}\n",
    "        idxs = []\n",
    "        for p1 in points:\n",
    "            for p2 in points:\n",
    "                offset = (abs(p1[0] - p2[0]), abs(p1[1] - p2[1]))\n",
    "                if offset not in attention_offsets:\n",
    "                    attention_offsets[offset] = len(attention_offsets)\n",
    "                idxs.append(attention_offsets[offset])\n",
    "        self.attention_biases = torch.nn.Parameter(\n",
    "            torch.zeros(num_heads, len(attention_offsets)))\n",
    "        self.register_buffer('attention_bias_idxs',\n",
    "                             torch.LongTensor(idxs).view(N, N),\n",
    "                             persistent=False)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def train(self, mode=True):\n",
    "        super().train(mode)\n",
    "        if mode and hasattr(self, 'ab'):\n",
    "            del self.ab\n",
    "        else:\n",
    "            self.ab = self.attention_biases[:, self.attention_bias_idxs]\n",
    "\n",
    "    def forward(self, x):  # x (B,N,C)\n",
    "        B, N, _ = x.shape\n",
    "\n",
    "        # Normalization\n",
    "        x = self.norm(x)\n",
    "\n",
    "        qkv = self.qkv(x)\n",
    "        # (B, N, num_heads, d)\n",
    "        q, k, v = qkv.view(B, N, self.num_heads, -\n",
    "                           1).split([self.key_dim, self.key_dim, self.d], dim=3)\n",
    "        # (B, num_heads, N, d)\n",
    "        q = q.permute(0, 2, 1, 3)\n",
    "        k = k.permute(0, 2, 1, 3)\n",
    "        v = v.permute(0, 2, 1, 3)\n",
    "\n",
    "        attn = (\n",
    "            (q @ k.transpose(-2, -1)) * self.scale\n",
    "            +\n",
    "            (self.attention_biases[:, self.attention_bias_idxs]\n",
    "             if self.training else self.ab)\n",
    "        )\n",
    "        attn = attn.softmax(dim=-1)\n",
    "        x = (attn @ v).transpose(1, 2).reshape(B, N, self.dh)\n",
    "        x = self.proj(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class TinyViTBlock(nn.Module):\n",
    "    r\"\"\" TinyViT Block.\n",
    "\n",
    "    Args:\n",
    "        dim (int): Number of input channels.\n",
    "        input_resolution (tuple[int, int]): Input resulotion.\n",
    "        num_heads (int): Number of attention heads.\n",
    "        window_size (int): Window size.\n",
    "        mlp_ratio (float): Ratio of mlp hidden dim to embedding dim.\n",
    "        drop (float, optional): Dropout rate. Default: 0.0\n",
    "        drop_path (float, optional): Stochastic depth rate. Default: 0.0\n",
    "        local_conv_size (int): the kernel size of the convolution between\n",
    "                               Attention and MLP. Default: 3\n",
    "        activation: the activation function. Default: nn.GELU\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dim, input_resolution, num_heads, window_size=7,\n",
    "                 mlp_ratio=4., drop=0., drop_path=0.,\n",
    "                 local_conv_size=3,\n",
    "                 activation=nn.GELU,\n",
    "                 ):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.input_resolution = input_resolution\n",
    "        self.num_heads = num_heads\n",
    "        assert window_size > 0, 'window_size must be greater than 0'\n",
    "        self.window_size = window_size\n",
    "        self.mlp_ratio = mlp_ratio\n",
    "\n",
    "        self.drop_path = DropPath(\n",
    "            drop_path) if drop_path > 0. else nn.Identity()\n",
    "\n",
    "        assert dim % num_heads == 0, 'dim must be divisible by num_heads'\n",
    "        head_dim = dim // num_heads\n",
    "\n",
    "        window_resolution = (window_size, window_size)\n",
    "        self.attn = Attention(dim, head_dim, num_heads,\n",
    "                              attn_ratio=1, resolution=window_resolution)\n",
    "\n",
    "        mlp_hidden_dim = int(dim * mlp_ratio)\n",
    "        mlp_activation = activation\n",
    "        self.mlp = Mlp(in_features=dim, hidden_features=mlp_hidden_dim,\n",
    "                       act_layer=mlp_activation, drop=drop)\n",
    "\n",
    "        pad = local_conv_size // 2\n",
    "        self.local_conv = Conv2d_BN(\n",
    "            dim, dim, ks=local_conv_size, stride=1, pad=pad, groups=dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        H, W = self.input_resolution\n",
    "        B, L, C = x.shape\n",
    "        assert L == H * W, \"input feature has wrong size\"\n",
    "        res_x = x\n",
    "        if H == self.window_size and W == self.window_size:\n",
    "            x = self.attn(x)\n",
    "        else:\n",
    "            x = x.view(B, H, W, C)\n",
    "            pad_b = (self.window_size - H %\n",
    "                     self.window_size) % self.window_size\n",
    "            pad_r = (self.window_size - W %\n",
    "                     self.window_size) % self.window_size\n",
    "            padding = pad_b > 0 or pad_r > 0\n",
    "\n",
    "            if padding:\n",
    "                x = F.pad(x, (0, 0, 0, pad_r, 0, pad_b))\n",
    "\n",
    "            pH, pW = H + pad_b, W + pad_r\n",
    "            nH = pH // self.window_size\n",
    "            nW = pW // self.window_size\n",
    "            # window partition\n",
    "            x = x.view(B, nH, self.window_size, nW, self.window_size, C).transpose(2, 3).reshape(\n",
    "                B * nH * nW, self.window_size * self.window_size, C\n",
    "            )\n",
    "            x = self.attn(x)\n",
    "            # window reverse\n",
    "            x = x.view(B, nH, nW, self.window_size, self.window_size,\n",
    "                       C).transpose(2, 3).reshape(B, pH, pW, C)\n",
    "\n",
    "            if padding:\n",
    "                x = x[:, :H, :W].contiguous()\n",
    "\n",
    "            x = x.view(B, L, C)\n",
    "\n",
    "        x = res_x + self.drop_path(x)\n",
    "\n",
    "        x = x.transpose(1, 2).reshape(B, C, H, W)\n",
    "        x = self.local_conv(x)\n",
    "        x = x.view(B, C, L).transpose(1, 2)\n",
    "\n",
    "        x = x + self.drop_path(self.mlp(x))\n",
    "        return x\n",
    "\n",
    "    def extra_repr(self) -> str:\n",
    "        return f\"dim={self.dim}, input_resolution={self.input_resolution}, num_heads={self.num_heads}, \" \\\n",
    "               f\"window_size={self.window_size}, mlp_ratio={self.mlp_ratio}\"\n",
    "\n",
    "\n",
    "class BasicLayer(nn.Module):\n",
    "    \"\"\" A basic TinyViT layer for one stage.\n",
    "\n",
    "    Args:\n",
    "        dim (int): Number of input channels.\n",
    "        input_resolution (tuple[int]): Input resolution.\n",
    "        depth (int): Number of blocks.\n",
    "        num_heads (int): Number of attention heads.\n",
    "        window_size (int): Local window size.\n",
    "        mlp_ratio (float): Ratio of mlp hidden dim to embedding dim.\n",
    "        drop (float, optional): Dropout rate. Default: 0.0\n",
    "        drop_path (float | tuple[float], optional): Stochastic depth rate. Default: 0.0\n",
    "        downsample (nn.Module | None, optional): Downsample layer at the end of the layer. Default: None\n",
    "        use_checkpoint (bool): Whether to use checkpointing to save memory. Default: False.\n",
    "        local_conv_size: the kernel size of the depthwise convolution between attention and MLP. Default: 3\n",
    "        activation: the activation function. Default: nn.GELU\n",
    "        out_dim: the output dimension of the layer. Default: dim\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dim, input_resolution, depth, num_heads, window_size,\n",
    "                 mlp_ratio=4., drop=0.,\n",
    "                 drop_path=0., downsample=None, use_checkpoint=False,\n",
    "                 local_conv_size=3,\n",
    "                 activation=nn.GELU,\n",
    "                 out_dim=None,\n",
    "                 ):\n",
    "\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.input_resolution = input_resolution\n",
    "        self.depth = depth\n",
    "        self.use_checkpoint = use_checkpoint\n",
    "\n",
    "        # build blocks\n",
    "        self.blocks = nn.ModuleList([\n",
    "            TinyViTBlock(dim=dim, input_resolution=input_resolution,\n",
    "                         num_heads=num_heads, window_size=window_size,\n",
    "                         mlp_ratio=mlp_ratio,\n",
    "                         drop=drop,\n",
    "                         drop_path=drop_path[i] if isinstance(\n",
    "                             drop_path, list) else drop_path,\n",
    "                         local_conv_size=local_conv_size,\n",
    "                         activation=activation,\n",
    "                         )\n",
    "            for i in range(depth)])\n",
    "\n",
    "        # patch merging layer\n",
    "        if downsample is not None:\n",
    "            self.downsample = downsample(\n",
    "                input_resolution, dim=dim, out_dim=out_dim, activation=activation)\n",
    "        else:\n",
    "            self.downsample = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        for blk in self.blocks:\n",
    "            if self.use_checkpoint:\n",
    "                x = checkpoint.checkpoint(blk, x)\n",
    "            else:\n",
    "                x = blk(x)\n",
    "        if self.downsample is not None:\n",
    "            x = self.downsample(x)\n",
    "        return x\n",
    "\n",
    "    def extra_repr(self) -> str:\n",
    "        return f\"dim={self.dim}, input_resolution={self.input_resolution}, depth={self.depth}\"\n",
    "\n",
    "\n",
    "class TinyViT(nn.Module):\n",
    "    def __init__(self, img_size=224, in_chans=3, num_classes=1000,\n",
    "                 embed_dims=[96, 192, 384, 768], depths=[2, 2, 6, 2],\n",
    "                 num_heads=[3, 6, 12, 24],\n",
    "                 window_sizes=[7, 7, 14, 7],\n",
    "                 mlp_ratio=4.,\n",
    "                 drop_rate=0.,\n",
    "                 drop_path_rate=0.1,\n",
    "                 use_checkpoint=False,\n",
    "                 mbconv_expand_ratio=4.0,\n",
    "                 local_conv_size=3,\n",
    "                 layer_lr_decay=1.0,\n",
    "                 ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "        self.depths = depths\n",
    "        self.num_layers = len(depths)\n",
    "        self.mlp_ratio = mlp_ratio\n",
    "\n",
    "        activation = nn.GELU\n",
    "\n",
    "        self.patch_embed = PatchEmbed(in_chans=in_chans,\n",
    "                                      embed_dim=embed_dims[0],\n",
    "                                      resolution=img_size,\n",
    "                                      activation=activation)\n",
    "\n",
    "        patches_resolution = self.patch_embed.patches_resolution\n",
    "        self.patches_resolution = patches_resolution\n",
    "\n",
    "        # stochastic depth\n",
    "        dpr = [x.item() for x in torch.linspace(0, drop_path_rate,\n",
    "                                                sum(depths))]  # stochastic depth decay rule\n",
    "\n",
    "        # build layers\n",
    "        self.layers = nn.ModuleList()\n",
    "        for i_layer in range(self.num_layers):\n",
    "            kwargs = dict(dim=embed_dims[i_layer],\n",
    "                          input_resolution=(patches_resolution[0] // (2 ** i_layer),\n",
    "                                            patches_resolution[1] // (2 ** i_layer)),\n",
    "                          depth=depths[i_layer],\n",
    "                          drop_path=dpr[sum(depths[:i_layer]):sum(depths[:i_layer + 1])],\n",
    "                          downsample=PatchMerging if (\n",
    "                              i_layer < self.num_layers - 1) else None,\n",
    "                          use_checkpoint=use_checkpoint,\n",
    "                          out_dim=embed_dims[min(\n",
    "                              i_layer + 1, len(embed_dims) - 1)],\n",
    "                          activation=activation,\n",
    "                          )\n",
    "            if i_layer == 0:\n",
    "                layer = ConvLayer(\n",
    "                    conv_expand_ratio=mbconv_expand_ratio,\n",
    "                    **kwargs,\n",
    "                )\n",
    "            else:\n",
    "                layer = BasicLayer(\n",
    "                    num_heads=num_heads[i_layer],\n",
    "                    window_size=window_sizes[i_layer],\n",
    "                    mlp_ratio=self.mlp_ratio,\n",
    "                    drop=drop_rate,\n",
    "                    local_conv_size=local_conv_size,\n",
    "                    **kwargs)\n",
    "            self.layers.append(layer)\n",
    "\n",
    "        # Classifier head\n",
    "        self.norm_head = nn.LayerNorm(embed_dims[-1])\n",
    "        self.head = nn.Linear(\n",
    "            embed_dims[-1], num_classes) if num_classes > 0 else torch.nn.Identity()\n",
    "\n",
    "        # init weights\n",
    "        self.apply(self._init_weights)\n",
    "        self.set_layer_lr_decay(layer_lr_decay)\n",
    "\n",
    "    def set_layer_lr_decay(self, layer_lr_decay):\n",
    "        decay_rate = layer_lr_decay\n",
    "\n",
    "        # layers -> blocks (depth)\n",
    "        depth = sum(self.depths)\n",
    "        lr_scales = [decay_rate ** (depth - i - 1) for i in range(depth)]\n",
    "\n",
    "        def _set_lr_scale(m, scale):\n",
    "            for p in m.parameters():\n",
    "                p.lr_scale = scale\n",
    "\n",
    "        self.patch_embed.apply(lambda x: _set_lr_scale(x, lr_scales[0]))\n",
    "        i = 0\n",
    "        for layer in self.layers:\n",
    "            for block in layer.blocks:\n",
    "                block.apply(lambda x: _set_lr_scale(x, lr_scales[i]))\n",
    "                i += 1\n",
    "            if layer.downsample is not None:\n",
    "                layer.downsample.apply(\n",
    "                    lambda x: _set_lr_scale(x, lr_scales[i - 1]))\n",
    "        assert i == depth\n",
    "        for m in [self.norm_head, self.head]:\n",
    "            m.apply(lambda x: _set_lr_scale(x, lr_scales[-1]))\n",
    "\n",
    "        for k, p in self.named_parameters():\n",
    "            p.param_name = k\n",
    "\n",
    "        def _check_lr_scale(m):\n",
    "            for p in m.parameters():\n",
    "                assert hasattr(p, 'lr_scale'), p.param_name\n",
    "\n",
    "        self.apply(_check_lr_scale)\n",
    "\n",
    "    def _init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            trunc_normal_(m.weight, std=.02)\n",
    "            if isinstance(m, nn.Linear) and m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.LayerNorm):\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "            nn.init.constant_(m.weight, 1.0)\n",
    "\n",
    "    @torch.jit.ignore\n",
    "    def no_weight_decay_keywords(self):\n",
    "        return {'attention_biases'}\n",
    "\n",
    "    def forward_features(self, x):\n",
    "        # x: (N, C, H, W)\n",
    "        x = self.patch_embed(x)\n",
    "\n",
    "        x = self.layers[0](x)\n",
    "        start_i = 1\n",
    "\n",
    "        for i in range(start_i, len(self.layers)):\n",
    "            layer = self.layers[i]\n",
    "            x = layer(x)\n",
    "\n",
    "        x = x.mean(1)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.forward_features(x)\n",
    "        x = self.norm_head(x)\n",
    "        x = self.head(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "_checkpoint_url_format = \\\n",
    "    'https://github.com/wkcn/TinyViT-model-zoo/releases/download/checkpoints/{}.pth'\n",
    "\n",
    "\n",
    "def _create_tiny_vit(variant, pretrained=False, **kwargs):\n",
    "    # pretrained_type: 22kto1k_distill, 1k, 22k_distill\n",
    "    pretrained_type = kwargs.pop('pretrained_type', '22kto1k_distill')\n",
    "    assert pretrained_type in ['22kto1k_distill', '1k', '22k_distill'], \\\n",
    "        'pretrained_type should be one of 22kto1k_distill, 1k, 22k_distill'\n",
    "\n",
    "    img_size = kwargs.get('img_size', 224)\n",
    "    if img_size != 224:\n",
    "        pretrained_type = pretrained_type.replace('_', f'_{img_size}_')\n",
    "\n",
    "    num_classes_pretrained = 21841 if \\\n",
    "        pretrained_type  == '22k_distill' else 1000\n",
    "\n",
    "    variant_without_img_size = '_'.join(variant.split('_')[:-1])\n",
    "    cfg = dict(\n",
    "        url=_checkpoint_url_format.format(\n",
    "            f'{variant_without_img_size}_{pretrained_type}'),\n",
    "        num_classes=num_classes_pretrained,\n",
    "        classifier='head',\n",
    "    )\n",
    "\n",
    "    def _pretrained_filter_fn(state_dict):\n",
    "        state_dict = state_dict['model']\n",
    "        # filter out attention_bias_idxs\n",
    "        state_dict = {k: v for k, v in state_dict.items() if \\\n",
    "            not k.endswith('attention_bias_idxs')}\n",
    "        return state_dict\n",
    "\n",
    "    if timm.__version__ >= \"0.6\":\n",
    "        return build_model_with_cfg(\n",
    "            TinyViT, variant, pretrained,\n",
    "            pretrained_cfg=cfg,\n",
    "            pretrained_filter_fn=_pretrained_filter_fn,\n",
    "            **kwargs)\n",
    "    else:\n",
    "        return build_model_with_cfg(\n",
    "            TinyViT, variant, pretrained,\n",
    "            default_cfg=cfg,\n",
    "            pretrained_filter_fn=_pretrained_filter_fn,\n",
    "            **kwargs)\n",
    "\n",
    "\n",
    "@register_model\n",
    "def tiny_vit_5m_224(pretrained=False, **kwargs):\n",
    "    model_kwargs = dict(\n",
    "        embed_dims=[64, 128, 160, 320],\n",
    "        depths=[2, 2, 6, 2],\n",
    "        num_heads=[2, 4, 5, 10],\n",
    "        window_sizes=[7, 7, 14, 7],\n",
    "        drop_path_rate=0.0,\n",
    "    )\n",
    "    model_kwargs.update(kwargs)\n",
    "    return _create_tiny_vit('tiny_vit_5m_224', pretrained, **model_kwargs)\n",
    "\n",
    "\n",
    "@register_model\n",
    "def tiny_vit_11m_224(pretrained=False, **kwargs):\n",
    "    model_kwargs = dict(\n",
    "        embed_dims=[64, 128, 256, 448],\n",
    "        depths=[2, 2, 6, 2],\n",
    "        num_heads=[2, 4, 8, 14],\n",
    "        window_sizes=[7, 7, 14, 7],\n",
    "        drop_path_rate=0.1,\n",
    "    )\n",
    "    model_kwargs.update(kwargs)\n",
    "    return _create_tiny_vit('tiny_vit_11m_224', pretrained, **model_kwargs)\n",
    "\n",
    "\n",
    "@register_model\n",
    "def tiny_vit_21m_224(pretrained=False, **kwargs):\n",
    "    model_kwargs = dict(\n",
    "        embed_dims=[96, 192, 384, 576],\n",
    "        depths=[2, 2, 6, 2],\n",
    "        num_heads=[3, 6, 12, 18],\n",
    "        window_sizes=[7, 7, 14, 7],\n",
    "        drop_path_rate=0.2,\n",
    "    )\n",
    "    model_kwargs.update(kwargs)\n",
    "    return _create_tiny_vit('tiny_vit_21m_224', pretrained, **model_kwargs)\n",
    "\n",
    "\n",
    "@register_model\n",
    "def tiny_vit_21m_384(pretrained=False, **kwargs):\n",
    "    model_kwargs = dict(\n",
    "        img_size=384,\n",
    "        embed_dims=[96, 192, 384, 576],\n",
    "        depths=[2, 2, 6, 2],\n",
    "        num_heads=[3, 6, 12, 18],\n",
    "        window_sizes=[12, 12, 24, 12],\n",
    "        drop_path_rate=0.1,\n",
    "    )\n",
    "    model_kwargs.update(kwargs)\n",
    "    return _create_tiny_vit('tiny_vit_21m_384', pretrained, **model_kwargs)\n",
    "\n",
    "\n",
    "@register_model\n",
    "def tiny_vit_21m_512(pretrained=False, **kwargs):\n",
    "    model_kwargs = dict(\n",
    "        img_size=512,\n",
    "        embed_dims=[96, 192, 384, 576],\n",
    "        depths=[2, 2, 6, 2],\n",
    "        num_heads=[3, 6, 12, 18],\n",
    "        window_sizes=[16, 16, 32, 16],\n",
    "        drop_path_rate=0.1,\n",
    "    )\n",
    "    model_kwargs.update(kwargs)\n",
    "    return _create_tiny_vit('tiny_vit_21m_512', pretrained, **model_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24357354\n",
      "11179077\n",
      "27523199\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models.vision_transformer\n",
    "model = torchvision.models.inception_v3(weights = None, num_classes = 5)\n",
    "print(sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
    "model = torchvision.models.resnet18(weights = None, num_classes = 5)\n",
    "print(sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
    "model = torchvision.models.swin_t(weights = None, num_classes = 5)\n",
    "print(sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
    "\n",
    "def _vision_transformer(\n",
    "    patch_size: int,\n",
    "    num_layers: int,\n",
    "    num_heads: int,\n",
    "    hidden_dim: int,\n",
    "    mlp_dim: int,\n",
    "    progress: bool,\n",
    "    **kwargs: Any,\n",
    ") -> VisionTransformer:\n",
    "    image_size = kwargs.pop(\"image_size\", 224)\n",
    "\n",
    "    model = VisionTransformer(\n",
    "        image_size=image_size,\n",
    "        patch_size=patch_size,\n",
    "        num_layers=num_layers,\n",
    "        num_heads=num_heads,\n",
    "        hidden_dim=hidden_dim,\n",
    "        mlp_dim=mlp_dim,\n",
    "        **kwargs,\n",
    "    )\n",
    "\n",
    "\n",
    "    return model\n",
    "\n",
    "def vit_t_16(*, weights = None, progress: bool = True, **kwargs: Any) -> VisionTransformer:\n",
    "    \"\"\"\n",
    "    Constructs a vit_l_16 architecture from\n",
    "    `An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale <https://arxiv.org/abs/2010.11929>`_.\n",
    "\n",
    "    Args:\n",
    "        weights (:class:`~torchvision.models.ViT_L_16_Weights`, optional): The pretrained\n",
    "            weights to use. See :class:`~torchvision.models.ViT_L_16_Weights`\n",
    "            below for more details and possible values. By default, no pre-trained weights are used.\n",
    "        progress (bool, optional): If True, displays a progress bar of the download to stderr. Default is True.\n",
    "        **kwargs: parameters passed to the ``torchvision.models.vision_transformer.VisionTransformer``\n",
    "            base class. Please refer to the `source code\n",
    "            <https://github.com/pytorch/vision/blob/main/torchvision/models/vision_transformer.py>`_\n",
    "            for more details about this class.\n",
    "\n",
    "    .. autoclass:: torchvision.models.ViT_L_16_Weights\n",
    "        :members:\n",
    "    \"\"\"\n",
    "    kwargs[image_size] = \"224\"\n",
    "    return _vision_transformer(\n",
    "        patch_size=16,\n",
    "        num_layers=4,\n",
    "        num_heads=12,\n",
    "        hidden_dim=768,\n",
    "        mlp_dim=3072,\n",
    "        progress=progress,\n",
    "        **kwargs,\n",
    "    )\n",
    "\n",
    "\n",
    "#model = vit_t_16(weights = None)\n",
    "#print(sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
    "\n",
    "#model = tiny_vit_21m_224()\n",
    "#print(sum(p.numel() for p in model.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "14cc7597",
    "outputId": "a7219c2e-c03a-4fb4-b142-3ecc665414dd",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aotia\\AppData\\Local\\Temp\\ipykernel_15872\\2059024522.py:78: FutureWarning: The default weight initialization of inception_v3 will be changed in future releases of torchvision. If you wish to keep the old behavior (which leads to long initialization times due to scipy/scipy#11299), please set init_weights=True.\n",
      "  warnings.warn('The default weight initialization of inception_v3 will be changed in future releases of '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 139/139 [00:01<00:00, 89.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[0.0, 91.38461538461539, 86.90582959641256, 20.489296636085626, 24.56140350877193]\n",
      "train Loss: 0.7587 Average Accuracy: 76.9670\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 99.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[0.0, 96.9298245614035, 81.86813186813187, 52.27272727272727, 2.6315789473684212]\n",
      "val Loss: 0.5120 Average Accuracy: 78.9579\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 41/41 [00:00<00:00, 88.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[0.0, 94.71458773784356, 81.18811881188118, 60.204081632653065, 7.936507936507937]\n",
      "test Loss: 0.5175 Average Accuracy: 78.3868\n",
      "\n",
      "Epoch 1/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 139/139 [00:01<00:00, 83.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[76.08695652173913, 95.2, 86.3677130044843, 36.69724770642202, 50.292397660818715]\n",
      "train Loss: 0.4191 Average Accuracy: 83.6637\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 99.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.9298245614035, 87.36263736263736, 20.454545454545453, 47.36842105263158]\n",
      "val Loss: 0.4478 Average Accuracy: 82.9659\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 41/41 [00:00<00:00, 103.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.86892177589851, 88.11881188118812, 29.591836734693878, 57.142857142857146]\n",
      "test Loss: 0.4464 Average Accuracy: 83.2472\n",
      "\n",
      "Epoch 2/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 139/139 [00:01<00:00, 96.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[97.82608695652173, 95.01538461538462, 87.08520179372198, 39.75535168195719, 59.06432748538012]\n",
      "train Loss: 0.3883 Average Accuracy: 85.1652\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 116.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.9298245614035, 86.81318681318682, 20.454545454545453, 50.0]\n",
      "val Loss: 0.4362 Average Accuracy: 82.9659\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 41/41 [00:00<00:00, 116.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 94.08033826638477, 87.7887788778878, 36.734693877551024, 61.904761904761905]\n",
      "test Loss: 0.4295 Average Accuracy: 84.2813\n",
      "\n",
      "Epoch 3/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 139/139 [00:01<00:00, 93.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.76923076923077, 86.18834080717488, 44.342507645259936, 57.30994152046784]\n",
      "train Loss: 0.3803 Average Accuracy: 85.1652\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 111.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 86.26373626373626, 40.90909090909091, 42.10526315789474]\n",
      "val Loss: 0.4405 Average Accuracy: 83.7675\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 41/41 [00:00<00:00, 110.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 94.08033826638477, 86.79867986798679, 47.95918367346939, 46.03174603174603]\n",
      "test Loss: 0.4239 Average Accuracy: 84.0745\n",
      "\n",
      "Epoch 4/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 139/139 [00:01<00:00, 97.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.46153846153847, 87.17488789237669, 44.03669724770642, 62.57309941520468]\n",
      "train Loss: 0.3737 Average Accuracy: 85.5856\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 112.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 97.80701754385964, 80.76923076923077, 22.727272727272727, 47.36842105263158]\n",
      "val Loss: 0.4597 Average Accuracy: 81.1623\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 41/41 [00:00<00:00, 101.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 95.34883720930233, 82.50825082508251, 37.755102040816325, 55.55555555555556]\n",
      "test Loss: 0.4314 Average Accuracy: 82.9369\n",
      "\n",
      "Epoch 5/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 139/139 [00:01<00:00, 85.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.8923076923077, 87.3542600896861, 44.342507645259936, 59.64912280701754]\n",
      "train Loss: 0.3708 Average Accuracy: 85.7357\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 90.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.9298245614035, 84.06593406593407, 38.63636363636363, 44.73684210526316]\n",
      "val Loss: 0.4340 Average Accuracy: 83.1663\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 41/41 [00:00<00:00, 91.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 94.08033826638477, 86.46864686468646, 47.95918367346939, 49.20634920634921]\n",
      "test Loss: 0.4119 Average Accuracy: 84.1779\n",
      "\n",
      "Epoch 6/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 139/139 [00:01<00:00, 88.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.70769230769231, 86.99551569506727, 46.788990825688074, 60.23391812865497]\n",
      "train Loss: 0.3676 Average Accuracy: 85.7958\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 117.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 87.36263736263736, 38.63636363636363, 44.73684210526316]\n",
      "val Loss: 0.4279 Average Accuracy: 84.1683\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 41/41 [00:00<00:00, 102.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 88.11881188118812, 52.04081632653061, 50.79365079365079]\n",
      "test Loss: 0.4179 Average Accuracy: 84.6949\n",
      "\n",
      "Epoch 7/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 139/139 [00:01<00:00, 86.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.8923076923077, 86.54708520179372, 45.56574923547401, 60.8187134502924]\n",
      "train Loss: 0.3678 Average Accuracy: 85.6456\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 93.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.9298245614035, 85.16483516483517, 40.90909090909091, 44.73684210526316]\n",
      "val Loss: 0.4343 Average Accuracy: 83.7675\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 41/41 [00:00<00:00, 98.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 94.08033826638477, 86.46864686468646, 50.0, 44.44444444444444]\n",
      "test Loss: 0.4135 Average Accuracy: 84.0745\n",
      "\n",
      "Epoch 8/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 139/139 [00:01<00:00, 85.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.8923076923077, 86.54708520179372, 47.706422018348626, 61.98830409356725]\n",
      "train Loss: 0.3644 Average Accuracy: 85.9159\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 117.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 97.36842105263158, 80.21978021978022, 36.36363636363637, 50.0]\n",
      "val Loss: 0.4342 Average Accuracy: 82.1643\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 41/41 [00:00<00:00, 118.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 94.71458773784356, 82.17821782178218, 50.0, 58.73015873015873]\n",
      "test Loss: 0.4117 Average Accuracy: 83.9710\n",
      "\n",
      "Epoch 9/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 139/139 [00:01<00:00, 83.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 95.07692307692308, 86.00896860986548, 46.48318042813456, 63.74269005847953]\n",
      "train Loss: 0.3629 Average Accuracy: 85.7958\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 93.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 97.36842105263158, 89.01098901098901, 22.727272727272727, 44.73684210526316]\n",
      "val Loss: 0.4403 Average Accuracy: 83.7675\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 41/41 [00:00<00:00, 90.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.86892177589851, 90.0990099009901, 32.6530612244898, 47.61904761904762]\n",
      "test Loss: 0.4223 Average Accuracy: 83.5574\n",
      "\n",
      "Epoch 10/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 139/139 [00:01<00:00, 88.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.8923076923077, 87.4439461883408, 47.400611620795104, 61.98830409356725]\n",
      "train Loss: 0.3649 Average Accuracy: 86.1862\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 117.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 87.91208791208791, 36.36363636363637, 44.73684210526316]\n",
      "val Loss: 0.4293 Average Accuracy: 84.1683\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 41/41 [00:00<00:00, 113.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 92.60042283298097, 87.45874587458746, 47.95918367346939, 42.857142857142854]\n",
      "test Loss: 0.4171 Average Accuracy: 83.3506\n",
      "\n",
      "Epoch 11/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 139/139 [00:01<00:00, 89.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.76923076923077, 86.63677130044843, 46.48318042813456, 61.98830409356725]\n",
      "train Loss: 0.3641 Average Accuracy: 85.7658\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 90.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 95.6140350877193, 87.91208791208791, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4218 Average Accuracy: 83.9679\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 41/41 [00:00<00:00, 119.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 92.60042283298097, 88.11881188118812, 39.795918367346935, 60.317460317460316]\n",
      "test Loss: 0.4183 Average Accuracy: 83.8676\n",
      "\n",
      "Epoch 12/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 139/139 [00:01<00:00, 93.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.46153846153847, 87.4439461883408, 45.56574923547401, 65.49707602339181]\n",
      "train Loss: 0.3609 Average Accuracy: 85.9760\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 111.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 97.36842105263158, 81.86813186813187, 40.90909090909091, 50.0]\n",
      "val Loss: 0.4307 Average Accuracy: 83.1663\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 41/41 [00:00<00:00, 114.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.446088794926, 82.17821782178218, 50.0, 58.73015873015873]\n",
      "test Loss: 0.4132 Average Accuracy: 83.3506\n",
      "\n",
      "Epoch 13/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 139/139 [00:01<00:00, 90.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 95.01538461538462, 86.00896860986548, 46.48318042813456, 63.74269005847953]\n",
      "train Loss: 0.3592 Average Accuracy: 85.7658\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 88.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.05263157894737, 91.20879120879121, 34.09090909090909, 34.21052631578947]\n",
      "val Loss: 0.4419 Average Accuracy: 84.1683\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 41/41 [00:00<00:00, 95.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 92.38900634249471, 91.74917491749174, 42.857142857142854, 39.682539682539684]\n",
      "test Loss: 0.4303 Average Accuracy: 83.8676\n",
      "\n",
      "Epoch 14/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 139/139 [00:01<00:00, 78.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.83076923076923, 86.63677130044843, 47.400611620795104, 61.40350877192982]\n",
      "train Loss: 0.3589 Average Accuracy: 85.8559\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 102.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 97.36842105263158, 84.61538461538461, 29.545454545454547, 42.10526315789474]\n",
      "val Loss: 0.4403 Average Accuracy: 82.5651\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 41/41 [00:00<00:00, 106.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.86892177589851, 88.44884488448845, 43.87755102040816, 42.857142857142854]\n",
      "test Loss: 0.4212 Average Accuracy: 83.8676\n",
      "\n",
      "Epoch 15/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 139/139 [00:01<00:00, 89.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 95.13846153846154, 86.72645739910314, 42.813455657492355, 61.40350877192982]\n",
      "train Loss: 0.3592 Average Accuracy: 85.5856\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 91.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.05263157894737, 89.01098901098901, 29.545454545454547, 44.73684210526316]\n",
      "val Loss: 0.4262 Average Accuracy: 83.7675\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 41/41 [00:00<00:00, 101.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 92.60042283298097, 90.42904290429043, 41.83673469387755, 50.79365079365079]\n",
      "test Loss: 0.4191 Average Accuracy: 84.1779\n",
      "\n",
      "Epoch 16/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 139/139 [00:01<00:00, 87.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.8923076923077, 87.3542600896861, 44.03669724770642, 65.49707602339181]\n",
      "train Loss: 0.3582 Average Accuracy: 86.0060\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 95.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 97.80701754385964, 81.86813186813187, 36.36363636363637, 50.0]\n",
      "val Loss: 0.4331 Average Accuracy: 82.9659\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 41/41 [00:00<00:00, 109.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.86892177589851, 84.48844884488449, 50.0, 49.20634920634921]\n",
      "test Loss: 0.4093 Average Accuracy: 83.6608\n",
      "\n",
      "Epoch 17/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 139/139 [00:01<00:00, 100.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 95.07692307692308, 86.99551569506727, 49.235474006116206, 63.1578947368421]\n",
      "train Loss: 0.3504 Average Accuracy: 86.3664\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 114.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.9298245614035, 87.36263736263736, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4191 Average Accuracy: 84.3687\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 41/41 [00:00<00:00, 116.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 88.11881188118812, 45.91836734693877, 57.142857142857146]\n",
      "test Loss: 0.4064 Average Accuracy: 84.4881\n",
      "\n",
      "Epoch 18/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 139/139 [00:01<00:00, 86.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.70769230769231, 87.62331838565022, 47.09480122324159, 66.08187134502924]\n",
      "train Loss: 0.3490 Average Accuracy: 86.3363\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 83.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.9298245614035, 86.81318681318682, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4194 Average Accuracy: 84.1683\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 41/41 [00:00<00:00, 82.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.23467230443974, 88.11881188118812, 45.91836734693877, 57.142857142857146]\n",
      "test Loss: 0.4060 Average Accuracy: 84.5915\n",
      "\n",
      "Epoch 19/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 139/139 [00:01<00:00, 79.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.64615384615385, 87.80269058295964, 46.48318042813456, 67.25146198830409]\n",
      "train Loss: 0.3482 Average Accuracy: 86.3664\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 106.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 97.36842105263158, 84.06593406593407, 34.09090909090909, 47.36842105263158]\n",
      "val Loss: 0.4256 Average Accuracy: 83.1663\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 41/41 [00:00<00:00, 93.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.86892177589851, 86.13861386138613, 47.95918367346939, 52.38095238095238]\n",
      "test Loss: 0.4054 Average Accuracy: 84.1779\n",
      "\n",
      "Epoch 20/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 139/139 [00:01<00:00, 93.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 95.13846153846154, 87.4439461883408, 48.92966360856269, 65.49707602339181]\n",
      "train Loss: 0.3472 Average Accuracy: 86.6366\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 92.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.05263157894737, 89.01098901098901, 27.272727272727273, 44.73684210526316]\n",
      "val Loss: 0.4229 Average Accuracy: 83.5671\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 41/41 [00:00<00:00, 111.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 92.60042283298097, 90.42904290429043, 41.83673469387755, 50.79365079365079]\n",
      "test Loss: 0.4138 Average Accuracy: 84.1779\n",
      "\n",
      "Epoch 21/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 139/139 [00:01<00:00, 89.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.95384615384616, 87.80269058295964, 46.17737003058104, 68.42105263157895]\n",
      "train Loss: 0.3482 Average Accuracy: 86.5465\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 114.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 87.91208791208791, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4199 Average Accuracy: 84.3687\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 41/41 [00:00<00:00, 117.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 89.10891089108911, 46.93877551020408, 52.38095238095238]\n",
      "test Loss: 0.4084 Average Accuracy: 84.5915\n",
      "\n",
      "Epoch 22/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 139/139 [00:01<00:00, 91.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.76923076923077, 87.80269058295964, 47.09480122324159, 66.66666666666667]\n",
      "train Loss: 0.3475 Average Accuracy: 86.4565\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 114.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 88.46153846153847, 31.818181818181817, 44.73684210526316]\n",
      "val Loss: 0.4228 Average Accuracy: 83.9679\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 41/41 [00:00<00:00, 117.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 89.76897689768977, 45.91836734693877, 49.20634920634921]\n",
      "test Loss: 0.4099 Average Accuracy: 84.4881\n",
      "\n",
      "Epoch 23/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 139/139 [00:01<00:00, 96.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.76923076923077, 88.07174887892377, 45.87155963302752, 64.91228070175438]\n",
      "train Loss: 0.3482 Average Accuracy: 86.3363\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 91.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.9298245614035, 87.36263736263736, 31.818181818181817, 44.73684210526316]\n",
      "val Loss: 0.4226 Average Accuracy: 83.7675\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 41/41 [00:00<00:00, 115.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.23467230443974, 88.44884488448845, 43.87755102040816, 52.38095238095238]\n",
      "test Loss: 0.4069 Average Accuracy: 84.1779\n",
      "\n",
      "Epoch 24/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 139/139 [00:01<00:00, 91.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.83076923076923, 88.07174887892377, 44.95412844036697, 67.25146198830409]\n",
      "train Loss: 0.3473 Average Accuracy: 86.3964\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 115.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.9298245614035, 82.96703296703296, 40.90909090909091, 50.0]\n",
      "val Loss: 0.4232 Average Accuracy: 83.3667\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 41/41 [00:00<00:00, 105.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 83.82838283828383, 53.06122448979592, 58.73015873015873]\n",
      "test Loss: 0.4063 Average Accuracy: 83.9710\n",
      "\n",
      "Epoch 25/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 139/139 [00:01<00:00, 93.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.76923076923077, 87.62331838565022, 48.92966360856269, 65.49707602339181]\n",
      "train Loss: 0.3478 Average Accuracy: 86.5165\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 112.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.9298245614035, 87.36263736263736, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4222 Average Accuracy: 84.3687\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 41/41 [00:00<00:00, 112.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 88.44884488448845, 45.91836734693877, 52.38095238095238]\n",
      "test Loss: 0.4078 Average Accuracy: 84.2813\n",
      "\n",
      "Epoch 26/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 139/139 [00:01<00:00, 98.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.83076923076923, 88.16143497757848, 45.87155963302752, 67.25146198830409]\n",
      "train Loss: 0.3468 Average Accuracy: 86.5165\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 109.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.9298245614035, 84.06593406593407, 38.63636363636363, 44.73684210526316]\n",
      "val Loss: 0.4229 Average Accuracy: 83.1663\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 41/41 [00:00<00:00, 116.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.446088794926, 84.81848184818482, 53.06122448979592, 52.38095238095238]\n",
      "test Loss: 0.4059 Average Accuracy: 84.0745\n",
      "\n",
      "Epoch 27/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 139/139 [00:01<00:00, 100.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.95384615384616, 87.80269058295964, 48.62385321100918, 63.74269005847953]\n",
      "train Loss: 0.3480 Average Accuracy: 86.5465\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 114.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 86.81318681318682, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4166 Average Accuracy: 83.9679\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 41/41 [00:00<00:00, 122.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 88.11881188118812, 41.83673469387755, 60.317460317460316]\n",
      "test Loss: 0.4051 Average Accuracy: 84.2813\n",
      "\n",
      "Epoch 28/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 139/139 [00:01<00:00, 100.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.95384615384616, 87.62331838565022, 47.400611620795104, 67.83625730994152]\n",
      "train Loss: 0.3472 Average Accuracy: 86.5766\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 111.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 86.81318681318682, 34.09090909090909, 44.73684210526316]\n",
      "val Loss: 0.4213 Average Accuracy: 83.5671\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 41/41 [00:00<00:00, 117.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 92.60042283298097, 86.46864686468646, 54.08163265306123, 50.79365079365079]\n",
      "test Loss: 0.4080 Average Accuracy: 84.1779\n",
      "\n",
      "Epoch 29/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 139/139 [00:01<00:00, 99.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.95384615384616, 87.89237668161435, 45.87155963302752, 67.83625730994152]\n",
      "train Loss: 0.3468 Average Accuracy: 86.5165\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 115.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.05263157894737, 86.81318681318682, 36.36363636363637, 44.73684210526316]\n",
      "val Loss: 0.4196 Average Accuracy: 83.5671\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 41/41 [00:00<00:00, 115.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 92.60042283298097, 88.11881188118812, 47.95918367346939, 50.79365079365079]\n",
      "test Loss: 0.4093 Average Accuracy: 84.0745\n",
      "\n",
      "Epoch 30/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 139/139 [00:01<00:00, 99.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.8923076923077, 87.53363228699551, 49.54128440366973, 64.32748538011695]\n",
      "train Loss: 0.3469 Average Accuracy: 86.5465\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 113.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.05263157894737, 88.46153846153847, 27.272727272727273, 50.0]\n",
      "val Loss: 0.4189 Average Accuracy: 83.7675\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 41/41 [00:00<00:00, 118.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 92.60042283298097, 90.42904290429043, 41.83673469387755, 57.142857142857146]\n",
      "test Loss: 0.4117 Average Accuracy: 84.5915\n",
      "\n",
      "Epoch 31/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 139/139 [00:01<00:00, 100.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.70769230769231, 87.98206278026906, 44.64831804281346, 69.00584795321637]\n",
      "train Loss: 0.3476 Average Accuracy: 86.3664\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 111.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 86.81318681318682, 34.09090909090909, 47.36842105263158]\n",
      "val Loss: 0.4210 Average Accuracy: 83.7675\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 41/41 [00:00<00:00, 116.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 88.11881188118812, 48.97959183673469, 50.79365079365079]\n",
      "test Loss: 0.4072 Average Accuracy: 84.3847\n",
      "\n",
      "Epoch 32/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 139/139 [00:01<00:00, 100.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.83076923076923, 87.80269058295964, 48.92966360856269, 66.66666666666667]\n",
      "train Loss: 0.3470 Average Accuracy: 86.6667\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 111.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.9298245614035, 85.71428571428571, 34.09090909090909, 47.36842105263158]\n",
      "val Loss: 0.4216 Average Accuracy: 83.5671\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 41/41 [00:00<00:00, 117.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 87.12871287128714, 51.02040816326531, 52.38095238095238]\n",
      "test Loss: 0.4055 Average Accuracy: 84.3847\n",
      "\n",
      "Epoch 33/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 139/139 [00:01<00:00, 99.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.83076923076923, 87.71300448430493, 51.07033639143731, 62.57309941520468]\n",
      "train Loss: 0.3464 Average Accuracy: 86.6366\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 116.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.9298245614035, 86.81318681318682, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4173 Average Accuracy: 84.1683\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 41/41 [00:00<00:00, 114.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 88.11881188118812, 44.89795918367347, 58.73015873015873]\n",
      "test Loss: 0.4052 Average Accuracy: 84.4881\n",
      "\n",
      "Epoch 34/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 139/139 [00:01<00:00, 99.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.8923076923077, 88.07174887892377, 45.56574923547401, 68.42105263157895]\n",
      "train Loss: 0.3446 Average Accuracy: 86.5465\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 114.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 86.81318681318682, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4181 Average Accuracy: 83.9679\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 41/41 [00:00<00:00, 114.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 88.11881188118812, 45.91836734693877, 58.73015873015873]\n",
      "test Loss: 0.4060 Average Accuracy: 84.5915\n",
      "\n",
      "Epoch 35/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 139/139 [00:01<00:00, 100.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.83076923076923, 88.4304932735426, 45.87155963302752, 68.42105263157895]\n",
      "train Loss: 0.3443 Average Accuracy: 86.6667\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 112.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 87.36263736263736, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4185 Average Accuracy: 84.1683\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 41/41 [00:00<00:00, 113.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 88.11881188118812, 45.91836734693877, 57.142857142857146]\n",
      "test Loss: 0.4063 Average Accuracy: 84.4881\n",
      "\n",
      "Epoch 36/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 139/139 [00:01<00:00, 100.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.70769230769231, 88.4304932735426, 48.318042813455655, 64.91228070175438]\n",
      "train Loss: 0.3441 Average Accuracy: 86.6667\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 114.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 86.81318681318682, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4181 Average Accuracy: 83.9679\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 41/41 [00:00<00:00, 116.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 88.11881188118812, 45.91836734693877, 58.73015873015873]\n",
      "test Loss: 0.4059 Average Accuracy: 84.5915\n",
      "\n",
      "Epoch 37/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 139/139 [00:01<00:00, 94.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.83076923076923, 87.89237668161435, 46.788990825688074, 67.25146198830409]\n",
      "train Loss: 0.3442 Average Accuracy: 86.5165\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 110.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 86.26373626373626, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4178 Average Accuracy: 83.7675\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 41/41 [00:00<00:00, 111.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 87.7887788778878, 47.95918367346939, 58.73015873015873]\n",
      "test Loss: 0.4053 Average Accuracy: 84.6949\n",
      "\n",
      "Epoch 38/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 139/139 [00:01<00:00, 85.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.83076923076923, 87.89237668161435, 48.01223241590214, 68.42105263157895]\n",
      "train Loss: 0.3441 Average Accuracy: 86.6967\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 109.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 86.81318681318682, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4185 Average Accuracy: 83.9679\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 41/41 [00:00<00:00, 112.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 88.11881188118812, 45.91836734693877, 58.73015873015873]\n",
      "test Loss: 0.4061 Average Accuracy: 84.5915\n",
      "\n",
      "Epoch 39/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 139/139 [00:01<00:00, 95.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.76923076923077, 87.98206278026906, 47.09480122324159, 67.83625730994152]\n",
      "train Loss: 0.3440 Average Accuracy: 86.5766\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 104.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 86.81318681318682, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4185 Average Accuracy: 83.9679\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 41/41 [00:00<00:00, 119.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 87.7887788778878, 47.95918367346939, 58.73015873015873]\n",
      "test Loss: 0.4057 Average Accuracy: 84.6949\n",
      "\n",
      "Epoch 40/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 139/139 [00:01<00:00, 102.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.83076923076923, 87.89237668161435, 48.318042813455655, 68.42105263157895]\n",
      "train Loss: 0.3440 Average Accuracy: 86.7267\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 120.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 86.81318681318682, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4189 Average Accuracy: 83.9679\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 41/41 [00:00<00:00, 119.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 88.11881188118812, 45.91836734693877, 53.96825396825397]\n",
      "test Loss: 0.4061 Average Accuracy: 84.2813\n",
      "\n",
      "Epoch 41/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 139/139 [00:01<00:00, 101.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.76923076923077, 88.34080717488789, 47.400611620795104, 64.91228070175438]\n",
      "train Loss: 0.3442 Average Accuracy: 86.5766\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 117.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 86.81318681318682, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4184 Average Accuracy: 83.9679\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 41/41 [00:00<00:00, 119.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 87.7887788778878, 47.95918367346939, 58.73015873015873]\n",
      "test Loss: 0.4054 Average Accuracy: 84.6949\n",
      "\n",
      "Epoch 42/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 139/139 [00:01<00:00, 88.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.76923076923077, 88.16143497757848, 48.62385321100918, 67.83625730994152]\n",
      "train Loss: 0.3439 Average Accuracy: 86.7868\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 112.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100.0, 96.9298245614035, 86.26373626373626, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4184 Average Accuracy: 83.9679\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 41/41 [00:00<00:00, 106.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 88.11881188118812, 45.91836734693877, 58.73015873015873]\n",
      "test Loss: 0.4055 Average Accuracy: 84.5915\n",
      "\n",
      "Epoch 43/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 139/139 [00:01<00:00, 93.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.83076923076923, 87.98206278026906, 48.01223241590214, 66.66666666666667]\n",
      "train Loss: 0.3441 Average Accuracy: 86.6366\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 92.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.9298245614035, 86.26373626373626, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4186 Average Accuracy: 83.9679\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 41/41 [00:00<00:00, 85.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 87.7887788778878, 47.95918367346939, 58.73015873015873]\n",
      "test Loss: 0.4049 Average Accuracy: 84.6949\n",
      "\n",
      "Epoch 44/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 139/139 [00:01<00:00, 98.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.8923076923077, 87.89237668161435, 47.706422018348626, 67.83625730994152]\n",
      "train Loss: 0.3438 Average Accuracy: 86.6667\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 100.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 86.81318681318682, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4187 Average Accuracy: 83.9679\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 41/41 [00:00<00:00, 89.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 87.7887788778878, 47.95918367346939, 58.73015873015873]\n",
      "test Loss: 0.4057 Average Accuracy: 84.6949\n",
      "\n",
      "Epoch 45/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 139/139 [00:01<00:00, 79.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.76923076923077, 87.89237668161435, 48.92966360856269, 66.08187134502924]\n",
      "train Loss: 0.3439 Average Accuracy: 86.6366\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 106.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.9298245614035, 86.26373626373626, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4189 Average Accuracy: 83.9679\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 41/41 [00:00<00:00, 115.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 87.7887788778878, 47.95918367346939, 58.73015873015873]\n",
      "test Loss: 0.4055 Average Accuracy: 84.6949\n",
      "\n",
      "Epoch 46/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 139/139 [00:01<00:00, 92.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.8923076923077, 87.80269058295964, 48.92966360856269, 68.42105263157895]\n",
      "train Loss: 0.3439 Average Accuracy: 86.7868\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 92.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 86.81318681318682, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4184 Average Accuracy: 83.9679\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 41/41 [00:00<00:00, 107.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 88.11881188118812, 45.91836734693877, 55.55555555555556]\n",
      "test Loss: 0.4064 Average Accuracy: 84.3847\n",
      "\n",
      "Epoch 47/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 139/139 [00:01<00:00, 87.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.76923076923077, 88.25112107623319, 48.62385321100918, 67.83625730994152]\n",
      "train Loss: 0.3438 Average Accuracy: 86.8168\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 91.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.9298245614035, 86.26373626373626, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4186 Average Accuracy: 83.9679\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 41/41 [00:00<00:00, 110.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 88.11881188118812, 45.91836734693877, 58.73015873015873]\n",
      "test Loss: 0.4056 Average Accuracy: 84.5915\n",
      "\n",
      "Epoch 48/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 139/139 [00:01<00:00, 100.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.83076923076923, 88.07174887892377, 48.01223241590214, 67.83625730994152]\n",
      "train Loss: 0.3439 Average Accuracy: 86.7267\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 114.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 86.81318681318682, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4184 Average Accuracy: 83.9679\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 41/41 [00:00<00:00, 119.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 87.7887788778878, 47.95918367346939, 58.73015873015873]\n",
      "test Loss: 0.4055 Average Accuracy: 84.6949\n",
      "\n",
      "Epoch 49/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 139/139 [00:01<00:00, 102.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.83076923076923, 87.71300448430493, 49.235474006116206, 68.42105263157895]\n",
      "train Loss: 0.3438 Average Accuracy: 86.7568\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 114.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 87.36263736263736, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4189 Average Accuracy: 84.1683\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 41/41 [00:00<00:00, 102.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 88.11881188118812, 45.91836734693877, 52.38095238095238]\n",
      "test Loss: 0.4063 Average Accuracy: 84.1779\n",
      "\n",
      "Epoch 50/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 139/139 [00:01<00:00, 97.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.76923076923077, 88.4304932735426, 46.788990825688074, 66.66666666666667]\n",
      "train Loss: 0.3437 Average Accuracy: 86.6366\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 116.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 86.81318681318682, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4188 Average Accuracy: 83.9679\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 41/41 [00:00<00:00, 110.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 88.11881188118812, 45.91836734693877, 57.142857142857146]\n",
      "test Loss: 0.4059 Average Accuracy: 84.4881\n",
      "\n",
      "Epoch 51/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 139/139 [00:01<00:00, 100.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.83076923076923, 87.80269058295964, 49.54128440366973, 68.42105263157895]\n",
      "train Loss: 0.3436 Average Accuracy: 86.8168\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 117.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 86.81318681318682, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4186 Average Accuracy: 83.9679\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 41/41 [00:00<00:00, 99.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 88.11881188118812, 45.91836734693877, 58.73015873015873]\n",
      "test Loss: 0.4060 Average Accuracy: 84.5915\n",
      "\n",
      "Epoch 52/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 139/139 [00:01<00:00, 94.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.83076923076923, 87.98206278026906, 47.706422018348626, 67.83625730994152]\n",
      "train Loss: 0.3438 Average Accuracy: 86.6667\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 115.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 87.36263736263736, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4187 Average Accuracy: 84.1683\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 41/41 [00:00<00:00, 102.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 88.11881188118812, 45.91836734693877, 55.55555555555556]\n",
      "test Loss: 0.4060 Average Accuracy: 84.3847\n",
      "\n",
      "Epoch 53/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 139/139 [00:01<00:00, 95.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.8923076923077, 88.07174887892377, 47.09480122324159, 67.25146198830409]\n",
      "train Loss: 0.3437 Average Accuracy: 86.6366\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 112.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 86.81318681318682, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4190 Average Accuracy: 83.9679\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 41/41 [00:00<00:00, 119.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 88.11881188118812, 45.91836734693877, 52.38095238095238]\n",
      "test Loss: 0.4061 Average Accuracy: 84.1779\n",
      "\n",
      "Epoch 54/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 139/139 [00:01<00:00, 93.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.83076923076923, 87.89237668161435, 48.92966360856269, 65.49707602339181]\n",
      "train Loss: 0.3437 Average Accuracy: 86.6366\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 117.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 86.81318681318682, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4184 Average Accuracy: 83.9679\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 41/41 [00:00<00:00, 117.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 87.7887788778878, 47.95918367346939, 58.73015873015873]\n",
      "test Loss: 0.4057 Average Accuracy: 84.6949\n",
      "\n",
      "Epoch 55/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 139/139 [00:01<00:00, 92.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.76923076923077, 88.07174887892377, 48.01223241590214, 67.83625730994152]\n",
      "train Loss: 0.3435 Average Accuracy: 86.6967\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 87.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 86.81318681318682, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4184 Average Accuracy: 83.9679\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 41/41 [00:00<00:00, 117.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 87.7887788778878, 47.95918367346939, 58.73015873015873]\n",
      "test Loss: 0.4057 Average Accuracy: 84.6949\n",
      "\n",
      "Epoch 56/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 139/139 [00:01<00:00, 94.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.83076923076923, 87.80269058295964, 48.92966360856269, 67.25146198830409]\n",
      "train Loss: 0.3435 Average Accuracy: 86.6967\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 116.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100.0, 96.49122807017544, 86.81318681318682, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4184 Average Accuracy: 83.9679\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 41/41 [00:00<00:00, 118.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 88.11881188118812, 45.91836734693877, 58.73015873015873]\n",
      "test Loss: 0.4060 Average Accuracy: 84.5915\n",
      "\n",
      "Epoch 57/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 139/139 [00:01<00:00, 102.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.76923076923077, 88.07174887892377, 47.09480122324159, 68.42105263157895]\n",
      "train Loss: 0.3435 Average Accuracy: 86.6366\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 117.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 86.81318681318682, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4185 Average Accuracy: 83.9679\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 41/41 [00:00<00:00, 102.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 88.11881188118812, 45.91836734693877, 58.73015873015873]\n",
      "test Loss: 0.4058 Average Accuracy: 84.5915\n",
      "\n",
      "Epoch 58/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 139/139 [00:01<00:00, 95.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.83076923076923, 87.89237668161435, 48.318042813455655, 66.08187134502924]\n",
      "train Loss: 0.3434 Average Accuracy: 86.6066\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 119.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 86.81318681318682, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4183 Average Accuracy: 83.9679\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 41/41 [00:00<00:00, 125.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 88.11881188118812, 46.93877551020408, 57.142857142857146]\n",
      "test Loss: 0.4059 Average Accuracy: 84.5915\n",
      "\n",
      "Epoch 59/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 139/139 [00:01<00:00, 108.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.83076923076923, 87.80269058295964, 48.92966360856269, 66.66666666666667]\n",
      "train Loss: 0.3436 Average Accuracy: 86.6667\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 123.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 87.36263736263736, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4185 Average Accuracy: 84.1683\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 41/41 [00:00<00:00, 124.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 88.11881188118812, 45.91836734693877, 55.55555555555556]\n",
      "test Loss: 0.4060 Average Accuracy: 84.3847\n",
      "\n",
      "Epoch 60/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 139/139 [00:01<00:00, 95.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.76923076923077, 88.07174887892377, 47.400611620795104, 68.42105263157895]\n",
      "train Loss: 0.3434 Average Accuracy: 86.6667\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 114.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 86.81318681318682, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4183 Average Accuracy: 83.9679\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 41/41 [00:00<00:00, 115.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 87.7887788778878, 47.95918367346939, 58.73015873015873]\n",
      "test Loss: 0.4059 Average Accuracy: 84.6949\n",
      "\n",
      "Epoch 61/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 139/139 [00:01<00:00, 93.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.76923076923077, 88.07174887892377, 48.62385321100918, 67.83625730994152]\n",
      "train Loss: 0.3435 Average Accuracy: 86.7568\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 116.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100.0, 96.49122807017544, 86.81318681318682, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4186 Average Accuracy: 83.9679\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 41/41 [00:00<00:00, 118.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 87.7887788778878, 47.95918367346939, 55.55555555555556]\n",
      "test Loss: 0.4059 Average Accuracy: 84.4881\n",
      "\n",
      "Epoch 62/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 139/139 [00:01<00:00, 101.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.83076923076923, 87.80269058295964, 49.54128440366973, 67.25146198830409]\n",
      "train Loss: 0.3434 Average Accuracy: 86.7568\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 117.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 86.81318681318682, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4188 Average Accuracy: 83.9679\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 41/41 [00:00<00:00, 116.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 87.7887788778878, 47.95918367346939, 53.96825396825397]\n",
      "test Loss: 0.4059 Average Accuracy: 84.3847\n",
      "\n",
      "Epoch 63/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 139/139 [00:01<00:00, 102.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.83076923076923, 87.80269058295964, 49.84709480122324, 67.83625730994152]\n",
      "train Loss: 0.3434 Average Accuracy: 86.8168\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 114.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 87.36263736263736, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4190 Average Accuracy: 84.1683\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 41/41 [00:00<00:00, 119.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 88.11881188118812, 45.91836734693877, 52.38095238095238]\n",
      "test Loss: 0.4063 Average Accuracy: 84.1779\n",
      "\n",
      "Epoch 64/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 139/139 [00:01<00:00, 98.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.76923076923077, 87.98206278026906, 47.400611620795104, 66.08187134502924]\n",
      "train Loss: 0.3435 Average Accuracy: 86.5165\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 116.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 86.81318681318682, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4187 Average Accuracy: 83.9679\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 41/41 [00:00<00:00, 116.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 88.11881188118812, 45.91836734693877, 55.55555555555556]\n",
      "test Loss: 0.4059 Average Accuracy: 84.3847\n",
      "\n",
      "Epoch 65/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 139/139 [00:01<00:00, 96.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.76923076923077, 88.07174887892377, 48.318042813455655, 67.83625730994152]\n",
      "train Loss: 0.3434 Average Accuracy: 86.7267\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 94.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 86.26373626373626, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4183 Average Accuracy: 83.7675\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 41/41 [00:00<00:00, 107.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 88.11881188118812, 46.93877551020408, 58.73015873015873]\n",
      "test Loss: 0.4057 Average Accuracy: 84.6949\n",
      "\n",
      "Epoch 66/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 139/139 [00:01<00:00, 95.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.8923076923077, 88.16143497757848, 48.318042813455655, 67.25146198830409]\n",
      "train Loss: 0.3433 Average Accuracy: 86.7868\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 116.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100.0, 96.49122807017544, 86.81318681318682, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4181 Average Accuracy: 83.9679\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 41/41 [00:00<00:00, 118.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 87.7887788778878, 47.95918367346939, 58.73015873015873]\n",
      "test Loss: 0.4056 Average Accuracy: 84.6949\n",
      "\n",
      "Epoch 67/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 139/139 [00:01<00:00, 101.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.76923076923077, 88.07174887892377, 48.62385321100918, 68.42105263157895]\n",
      "train Loss: 0.3433 Average Accuracy: 86.7868\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 116.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 86.81318681318682, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4182 Average Accuracy: 83.9679\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 41/41 [00:00<00:00, 110.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 88.11881188118812, 46.93877551020408, 58.73015873015873]\n",
      "test Loss: 0.4059 Average Accuracy: 84.6949\n",
      "\n",
      "Epoch 68/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 139/139 [00:01<00:00, 92.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.95384615384616, 87.98206278026906, 48.318042813455655, 67.83625730994152]\n",
      "train Loss: 0.3434 Average Accuracy: 86.7868\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 117.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100.0, 96.49122807017544, 86.81318681318682, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4183 Average Accuracy: 83.9679\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 41/41 [00:00<00:00, 118.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 88.11881188118812, 46.93877551020408, 58.73015873015873]\n",
      "test Loss: 0.4059 Average Accuracy: 84.6949\n",
      "\n",
      "Epoch 69/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 139/139 [00:01<00:00, 100.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.76923076923077, 87.98206278026906, 48.318042813455655, 67.83625730994152]\n",
      "train Loss: 0.3434 Average Accuracy: 86.6967\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 91.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 86.81318681318682, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4182 Average Accuracy: 83.9679\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 41/41 [00:00<00:00, 96.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 88.11881188118812, 47.95918367346939, 58.73015873015873]\n",
      "test Loss: 0.4058 Average Accuracy: 84.7983\n",
      "\n",
      "Epoch 70/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 139/139 [00:01<00:00, 76.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.83076923076923, 88.16143497757848, 48.318042813455655, 66.66666666666667]\n",
      "train Loss: 0.3432 Average Accuracy: 86.7267\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 140.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 86.81318681318682, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4183 Average Accuracy: 83.9679\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 41/41 [00:00<00:00, 123.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 88.11881188118812, 47.95918367346939, 58.73015873015873]\n",
      "test Loss: 0.4058 Average Accuracy: 84.7983\n",
      "\n",
      "Epoch 71/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 139/139 [00:01<00:00, 86.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.83076923076923, 87.62331838565022, 49.54128440366973, 67.83625730994152]\n",
      "train Loss: 0.3431 Average Accuracy: 86.7267\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 114.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 86.81318681318682, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4181 Average Accuracy: 83.9679\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 41/41 [00:00<00:00, 104.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 88.11881188118812, 46.93877551020408, 58.73015873015873]\n",
      "test Loss: 0.4058 Average Accuracy: 84.6949\n",
      "\n",
      "Epoch 72/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 139/139 [00:01<00:00, 82.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.76923076923077, 88.25112107623319, 45.87155963302752, 67.83625730994152]\n",
      "train Loss: 0.3434 Average Accuracy: 86.5465\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 113.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 86.81318681318682, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4182 Average Accuracy: 83.9679\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 41/41 [00:00<00:00, 111.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 87.7887788778878, 47.95918367346939, 58.73015873015873]\n",
      "test Loss: 0.4054 Average Accuracy: 84.6949\n",
      "\n",
      "Epoch 73/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 139/139 [00:01<00:00, 95.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.76923076923077, 87.62331838565022, 48.92966360856269, 69.00584795321637]\n",
      "train Loss: 0.3431 Average Accuracy: 86.6967\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 116.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 86.81318681318682, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4186 Average Accuracy: 83.9679\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 41/41 [00:00<00:00, 103.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 88.11881188118812, 46.93877551020408, 57.142857142857146]\n",
      "test Loss: 0.4060 Average Accuracy: 84.5915\n",
      "\n",
      "Epoch 74/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 139/139 [00:01<00:00, 93.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.8923076923077, 88.07174887892377, 48.62385321100918, 65.49707602339181]\n",
      "train Loss: 0.3431 Average Accuracy: 86.6967\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 114.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 86.81318681318682, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4185 Average Accuracy: 83.9679\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 41/41 [00:00<00:00, 117.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 87.7887788778878, 46.93877551020408, 57.142857142857146]\n",
      "test Loss: 0.4059 Average Accuracy: 84.4881\n",
      "\n",
      "Epoch 75/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 139/139 [00:01<00:00, 97.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.83076923076923, 87.80269058295964, 48.92966360856269, 67.83625730994152]\n",
      "train Loss: 0.3430 Average Accuracy: 86.7267\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 114.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 86.81318681318682, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4181 Average Accuracy: 83.9679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 41/41 [00:00<00:00, 99.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 87.7887788778878, 47.95918367346939, 58.73015873015873]\n",
      "test Loss: 0.4056 Average Accuracy: 84.6949\n",
      "\n",
      "Epoch 76/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 139/139 [00:01<00:00, 97.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.76923076923077, 88.07174887892377, 47.400611620795104, 66.66666666666667]\n",
      "train Loss: 0.3432 Average Accuracy: 86.5766\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 114.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 86.81318681318682, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4181 Average Accuracy: 83.9679\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 41/41 [00:00<00:00, 105.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 87.7887788778878, 47.95918367346939, 57.142857142857146]\n",
      "test Loss: 0.4060 Average Accuracy: 84.5915\n",
      "\n",
      "Epoch 77/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 139/139 [00:01<00:00, 97.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.83076923076923, 88.25112107623319, 48.01223241590214, 67.83625730994152]\n",
      "train Loss: 0.3431 Average Accuracy: 86.7868\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 112.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 86.81318681318682, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4184 Average Accuracy: 83.9679\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 41/41 [00:00<00:00, 117.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 87.7887788778878, 47.95918367346939, 57.142857142857146]\n",
      "test Loss: 0.4058 Average Accuracy: 84.5915\n",
      "\n",
      "Epoch 78/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 139/139 [00:01<00:00, 96.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.83076923076923, 87.4439461883408, 49.84709480122324, 65.49707602339181]\n",
      "train Loss: 0.3429 Average Accuracy: 86.5766\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 116.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 86.81318681318682, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4182 Average Accuracy: 83.9679\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 41/41 [00:00<00:00, 103.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 92.81183932346723, 88.11881188118812, 46.93877551020408, 55.55555555555556]\n",
      "test Loss: 0.4066 Average Accuracy: 84.3847\n",
      "\n",
      "Epoch 79/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 139/139 [00:01<00:00, 95.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.76923076923077, 87.98206278026906, 49.54128440366973, 67.25146198830409]\n",
      "train Loss: 0.3431 Average Accuracy: 86.7868\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 102.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 86.81318681318682, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4183 Average Accuracy: 83.9679\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 41/41 [00:00<00:00, 110.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 88.11881188118812, 46.93877551020408, 55.55555555555556]\n",
      "test Loss: 0.4063 Average Accuracy: 84.4881\n",
      "\n",
      "Epoch 80/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 139/139 [00:01<00:00, 93.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.83076923076923, 88.16143497757848, 48.318042813455655, 67.83625730994152]\n",
      "train Loss: 0.3429 Average Accuracy: 86.7868\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 95.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 87.36263736263736, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4176 Average Accuracy: 84.1683\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 41/41 [00:00<00:00, 94.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 92.81183932346723, 88.11881188118812, 45.91836734693877, 58.73015873015873]\n",
      "test Loss: 0.4064 Average Accuracy: 84.4881\n",
      "\n",
      "Epoch 81/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 139/139 [00:01<00:00, 97.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.76923076923077, 87.98206278026906, 49.235474006116206, 67.83625730994152]\n",
      "train Loss: 0.3429 Average Accuracy: 86.7868\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 116.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 87.36263736263736, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4178 Average Accuracy: 84.1683\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 41/41 [00:00<00:00, 118.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 88.11881188118812, 46.93877551020408, 58.73015873015873]\n",
      "test Loss: 0.4060 Average Accuracy: 84.6949\n",
      "\n",
      "Epoch 82/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 139/139 [00:01<00:00, 99.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.76923076923077, 87.98206278026906, 48.62385321100918, 66.66666666666667]\n",
      "train Loss: 0.3431 Average Accuracy: 86.6667\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 114.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 86.81318681318682, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4179 Average Accuracy: 83.9679\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 41/41 [00:00<00:00, 115.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 87.7887788778878, 47.95918367346939, 58.73015873015873]\n",
      "test Loss: 0.4056 Average Accuracy: 84.6949\n",
      "\n",
      "Epoch 83/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 139/139 [00:01<00:00, 98.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.83076923076923, 87.98206278026906, 49.235474006116206, 66.08187134502924]\n",
      "train Loss: 0.3429 Average Accuracy: 86.7267\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 116.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 86.81318681318682, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4181 Average Accuracy: 83.9679\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 41/41 [00:00<00:00, 101.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 87.7887788778878, 47.95918367346939, 58.73015873015873]\n",
      "test Loss: 0.4057 Average Accuracy: 84.6949\n",
      "\n",
      "Epoch 84/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 139/139 [00:01<00:00, 93.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.76923076923077, 87.53363228699551, 50.45871559633027, 67.83625730994152]\n",
      "train Loss: 0.3427 Average Accuracy: 86.7568\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 112.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100.0, 96.49122807017544, 87.36263736263736, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4184 Average Accuracy: 84.1683\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 41/41 [00:00<00:00, 117.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 88.11881188118812, 45.91836734693877, 55.55555555555556]\n",
      "test Loss: 0.4065 Average Accuracy: 84.3847\n",
      "\n",
      "Epoch 85/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 139/139 [00:01<00:00, 95.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.83076923076923, 88.16143497757848, 47.706422018348626, 67.83625730994152]\n",
      "train Loss: 0.3428 Average Accuracy: 86.7267\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 115.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 87.36263736263736, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4184 Average Accuracy: 84.1683\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 41/41 [00:00<00:00, 119.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 88.11881188118812, 45.91836734693877, 55.55555555555556]\n",
      "test Loss: 0.4065 Average Accuracy: 84.3847\n",
      "\n",
      "Epoch 86/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 139/139 [00:01<00:00, 93.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.83076923076923, 88.07174887892377, 47.400611620795104, 67.83625730994152]\n",
      "train Loss: 0.3429 Average Accuracy: 86.6667\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 99.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 87.36263736263736, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4178 Average Accuracy: 84.1683\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 41/41 [00:00<00:00, 101.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 92.81183932346723, 88.11881188118812, 45.91836734693877, 57.142857142857146]\n",
      "test Loss: 0.4065 Average Accuracy: 84.3847\n",
      "\n",
      "Epoch 87/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 139/139 [00:01<00:00, 100.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.83076923076923, 88.25112107623319, 48.92966360856269, 67.25146198830409]\n",
      "train Loss: 0.3427 Average Accuracy: 86.8468\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 109.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 86.81318681318682, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4175 Average Accuracy: 83.9679\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 41/41 [00:00<00:00, 108.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 88.11881188118812, 46.93877551020408, 58.73015873015873]\n",
      "test Loss: 0.4058 Average Accuracy: 84.6949\n",
      "\n",
      "Epoch 88/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 139/139 [00:01<00:00, 90.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.76923076923077, 88.16143497757848, 47.706422018348626, 68.42105263157895]\n",
      "train Loss: 0.3428 Average Accuracy: 86.7267\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 86.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 86.81318681318682, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4176 Average Accuracy: 83.9679\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 41/41 [00:00<00:00, 121.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 88.11881188118812, 46.93877551020408, 58.73015873015873]\n",
      "test Loss: 0.4060 Average Accuracy: 84.6949\n",
      "\n",
      "Epoch 89/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 139/139 [00:01<00:00, 100.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.83076923076923, 87.98206278026906, 49.54128440366973, 67.25146198830409]\n",
      "train Loss: 0.3427 Average Accuracy: 86.8168\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 155.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 86.81318681318682, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4179 Average Accuracy: 83.9679\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 41/41 [00:00<00:00, 157.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 88.11881188118812, 47.95918367346939, 58.73015873015873]\n",
      "test Loss: 0.4058 Average Accuracy: 84.7983\n",
      "\n",
      "Epoch 90/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 139/139 [00:01<00:00, 123.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.76923076923077, 87.98206278026906, 48.318042813455655, 68.42105263157895]\n",
      "train Loss: 0.3427 Average Accuracy: 86.7267\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 143.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 86.81318681318682, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4178 Average Accuracy: 83.9679\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 41/41 [00:00<00:00, 107.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 88.11881188118812, 47.95918367346939, 58.73015873015873]\n",
      "test Loss: 0.4059 Average Accuracy: 84.7983\n",
      "\n",
      "Epoch 91/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 139/139 [00:01<00:00, 114.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.8923076923077, 88.07174887892377, 48.01223241590214, 66.08187134502924]\n",
      "train Loss: 0.3427 Average Accuracy: 86.6667\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 140.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 97.36842105263158, 86.26373626373626, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4188 Average Accuracy: 84.1683\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 41/41 [00:00<00:00, 143.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 87.7887788778878, 47.95918367346939, 57.142857142857146]\n",
      "test Loss: 0.4057 Average Accuracy: 84.5915\n",
      "\n",
      "Epoch 92/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 139/139 [00:01<00:00, 95.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.83076923076923, 87.62331838565022, 48.92966360856269, 67.25146198830409]\n",
      "train Loss: 0.3426 Average Accuracy: 86.6366\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 135.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 86.81318681318682, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4177 Average Accuracy: 83.9679\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 41/41 [00:00<00:00, 121.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 87.7887788778878, 47.95918367346939, 58.73015873015873]\n",
      "test Loss: 0.4061 Average Accuracy: 84.6949\n",
      "\n",
      "Epoch 93/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 139/139 [00:01<00:00, 93.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.83076923076923, 88.16143497757848, 48.01223241590214, 67.83625730994152]\n",
      "train Loss: 0.3426 Average Accuracy: 86.7568\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 117.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 87.36263736263736, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4180 Average Accuracy: 84.1683\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 41/41 [00:00<00:00, 115.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 92.81183932346723, 88.11881188118812, 45.91836734693877, 55.55555555555556]\n",
      "test Loss: 0.4069 Average Accuracy: 84.2813\n",
      "\n",
      "Epoch 94/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 139/139 [00:01<00:00, 96.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.8923076923077, 87.89237668161435, 48.92966360856269, 66.08187134502924]\n",
      "train Loss: 0.3426 Average Accuracy: 86.6967\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 108.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 86.81318681318682, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4186 Average Accuracy: 83.9679\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 41/41 [00:00<00:00, 105.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 88.11881188118812, 46.93877551020408, 55.55555555555556]\n",
      "test Loss: 0.4064 Average Accuracy: 84.4881\n",
      "\n",
      "Epoch 95/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 139/139 [00:01<00:00, 95.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.83076923076923, 88.16143497757848, 46.788990825688074, 67.25146198830409]\n",
      "train Loss: 0.3426 Average Accuracy: 86.6066\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 114.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100.0, 96.49122807017544, 86.81318681318682, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4177 Average Accuracy: 83.9679\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 41/41 [00:00<00:00, 119.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 87.7887788778878, 47.95918367346939, 58.73015873015873]\n",
      "test Loss: 0.4057 Average Accuracy: 84.6949\n",
      "\n",
      "Epoch 96/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 139/139 [00:01<00:00, 98.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.83076923076923, 88.16143497757848, 48.318042813455655, 67.83625730994152]\n",
      "train Loss: 0.3427 Average Accuracy: 86.7868\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 116.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 86.81318681318682, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4177 Average Accuracy: 83.9679\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 41/41 [00:00<00:00, 116.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 87.7887788778878, 47.95918367346939, 58.73015873015873]\n",
      "test Loss: 0.4059 Average Accuracy: 84.6949\n",
      "\n",
      "Epoch 97/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 139/139 [00:01<00:00, 92.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.76923076923077, 87.62331838565022, 49.84709480122324, 66.66666666666667]\n",
      "train Loss: 0.3425 Average Accuracy: 86.6667\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 111.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100.0, 96.49122807017544, 86.81318681318682, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4181 Average Accuracy: 83.9679\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 41/41 [00:00<00:00, 114.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 87.7887788778878, 47.95918367346939, 57.142857142857146]\n",
      "test Loss: 0.4059 Average Accuracy: 84.5915\n",
      "\n",
      "Epoch 98/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 139/139 [00:01<00:00, 95.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.8923076923077, 88.07174887892377, 48.62385321100918, 66.66666666666667]\n",
      "train Loss: 0.3426 Average Accuracy: 86.7568\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 116.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 86.81318681318682, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4181 Average Accuracy: 83.9679\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 41/41 [00:00<00:00, 114.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 88.11881188118812, 47.95918367346939, 57.142857142857146]\n",
      "test Loss: 0.4062 Average Accuracy: 84.6949\n",
      "\n",
      "Epoch 99/99\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 139/139 [00:01<00:00, 103.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92.0, 1625.0, 1115.0, 327.0, 171.0]\n",
      "[100.0, 94.76923076923077, 88.07174887892377, 47.706422018348626, 68.42105263157895]\n",
      "train Loss: 0.3425 Average Accuracy: 86.6967\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 21/21 [00:00<00:00, 117.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.0, 228.0, 182.0, 44.0, 38.0]\n",
      "[100.0, 96.49122807017544, 86.81318681318682, 34.09090909090909, 50.0]\n",
      "val Loss: 0.4181 Average Accuracy: 83.9679\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 41/41 [00:00<00:00, 118.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 473.0, 303.0, 98.0, 63.0]\n",
      "[96.66666666666667, 93.02325581395348, 88.11881188118812, 46.93877551020408, 57.142857142857146]\n",
      "test Loss: 0.4060 Average Accuracy: 84.5915\n",
      "\n",
      "Training complete in 3m 25s\n",
      "Best Accuracy: 84.368736\n"
     ]
    }
   ],
   "source": [
    "#@title Train Baseline\n",
    "# specify loss function\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "inception = inception_v3_merge(pretrained=False)#, metadata_size=64)\n",
    "\n",
    "state_dict = load_state_dict_from_url(model_urls[\"inception_v3_google\"], progress=True)\n",
    "inception.load_state_dict(state_dict, strict=False)\n",
    "inception.to(device)\n",
    "\n",
    " \n",
    "#model = torchvision.models.swin_t(weights = None, num_classes = 5)\n",
    "#weights = load_state_dict_from_url(\"https://download.pytorch.org/models/resnet18-f37072fd.pth\", progress=True)\n",
    "#weights = load_state_dict_from_url(\"https://download.pytorch.org/models/vit_b_16-c867db91.pth\", progress=True)\n",
    "#weights = load_state_dict_from_url(\"https://github.com/wkcn/TinyViT-model-zoo/releases/download/checkpoints/tiny_vit_21m_1k.pth\", progress=True)\n",
    "#weights = load_state_dict_from_url(\"https://download.pytorch.org/models/inception_v3_google-0cc3c7bd.pth\", progress=True)\n",
    "\n",
    "#model = torchvision.models.vit_b_16(weights = None, num_classes = 5)\n",
    "#model = tiny_vit_21m_224(num_classes = 5)\n",
    "#model = torchvision.models.resnet34(weights = None, num_classes = 5)\n",
    "#model = torchvision.models.inception_v3(weights = None, num_classes = 5)\n",
    "#model = torchvision.models.swin_t(weights = None, num_classes = 5)\n",
    "model = SimpleNet()\n",
    "for name, param in weights.items():\n",
    "  if name not in model.state_dict() or model.state_dict()[name].size() != param.size():\n",
    "    continue\n",
    "    # backwards compatibility for serialized parameters\n",
    "  param = param.data\n",
    "  #model.state_dict()[name].copy_(param)\n",
    "#model.load_state_dict(torch.load( 'F:/Scales/inception_v3_classification_image_only_temp.pth'))\n",
    "#model.load_state_dict(weights, strict= False)\n",
    "#model = mobilenetv2(num_classes=5, width_mult=0.2)\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()#weight = torch.Tensor([2949/1561,2949/1034,2949/271,2949/83,2949/20]).to(device))\n",
    "#criterion = CBFocalLoss(gamma = 0.5)\n",
    "#criterion = FocalLoss2(gamma = 2)\n",
    "#criterion = CBCrossEntropy()\n",
    "#inception.load_state_dict(torch.load( 'F:/Scales/Gulf Menhaden/inception_v3_classification_source2.pth'))\n",
    "# specify optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
    "#scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 25, gamma=0.2)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, [50, 100], gamma=0.2)\n",
    "model_name = \"inception\"\n",
    "\n",
    "loss_list = []\n",
    "acc_list = []\n",
    "res = []\n",
    "training_res = []\n",
    "\n",
    "[inception, loss_list, acc_list, res, training_res] = train_model_classification(\n",
    "    model,\n",
    "    dataloaders,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    scheduler,\n",
    "    device,\n",
    "    num_epochs=100,\n",
    "    is_inception=(model_name == \"inception\"),\n",
    ")  # train model\n",
    "\n",
    "torch.save(inception.state_dict(), 'F:/Scales/Classification_Atlantic.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rYxZls57x3si",
    "outputId": "76160dd5-19cc-4702-9ba9-a26b47526417"
   },
   "outputs": [],
   "source": [
    "#model = inception_v3_merge(pretrained=False)\n",
    "model = SimpleNet()\n",
    "model.load_state_dict(torch.load( 'F:/Scales/Classification_Atlantic.pth'))\n",
    "infile = open(val_csv_path,'r')\n",
    "outfile = open(val_csv_path[:-4] + \"_results_meta_only.csv\",'w')\n",
    "lines = infile.readlines()\n",
    "infile.close()\n",
    "outfile.write(lines[0].strip()+\", model age\\n\")\n",
    "model.to(device)\n",
    "for i in range(1,len(lines)):\n",
    "  if(len(lines[i])>0):\n",
    "    (image, wt), age = val_loader.dataset.__getitem__(i-1)\n",
    "    image = image.to(device).unsqueeze(0)\n",
    "\n",
    "    wt = wt.to(device).float().unsqueeze(0)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "      outputs = model( wt)\n",
    "      outputs = torch.squeeze(outputs)\n",
    "      _, preds = torch.max(outputs, 0)\n",
    "      #print(i,preds)\n",
    "      outfile.write(lines[i].strip()+\",%d\\n\"%(preds))\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z7N8TAGmNs1O",
    "jupyter": {
     "source_hidden": true
    },
    "outputId": "a1d0e675-740d-462c-ea33-e11673175998"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/39\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 92/92 [00:42<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.5767 Average Accuracy: 88.9115\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 132/132 [00:04<00:00, 32.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.2611 Average Accuracy: 94.7236\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 266/266 [00:08<00:00, 31.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.4402 Average Accuracy: 89.8623\n",
      "\n",
      "Epoch 1/39\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 92/92 [00:41<00:00,  2.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.4942 Average Accuracy: 90.8104\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 132/132 [00:04<00:00, 32.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.2970 Average Accuracy: 91.4573\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 266/266 [00:08<00:00, 32.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.4460 Average Accuracy: 86.9837\n",
      "\n",
      "Epoch 2/39\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 92/92 [00:42<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.5005 Average Accuracy: 90.8783\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 132/132 [00:04<00:00, 30.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.2949 Average Accuracy: 91.2060\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 266/266 [00:08<00:00, 32.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.5216 Average Accuracy: 87.1089\n",
      "\n",
      "Epoch 3/39\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 92/92 [00:43<00:00,  2.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6128 Average Accuracy: 87.7247\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 132/132 [00:04<00:00, 30.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.3419 Average Accuracy: 86.9347\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 266/266 [00:08<00:00, 31.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.4285 Average Accuracy: 86.3579\n",
      "\n",
      "Epoch 4/39\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 92/92 [00:41<00:00,  2.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.5175 Average Accuracy: 89.9288\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 132/132 [00:04<00:00, 32.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.3197 Average Accuracy: 91.2060\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 266/266 [00:08<00:00, 32.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.4341 Average Accuracy: 88.8611\n",
      "\n",
      "Epoch 5/39\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 92/92 [00:41<00:00,  2.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.4246 Average Accuracy: 92.5059\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 132/132 [00:04<00:00, 32.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.2648 Average Accuracy: 92.4623\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 266/266 [00:08<00:00, 31.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.3793 Average Accuracy: 88.4856\n",
      "\n",
      "Epoch 6/39\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 92/92 [00:42<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.3528 Average Accuracy: 93.5232\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 132/132 [00:04<00:00, 31.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.2165 Average Accuracy: 93.9698\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 266/266 [00:08<00:00, 31.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.3961 Average Accuracy: 88.6108\n",
      "\n",
      "Epoch 7/39\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 92/92 [00:41<00:00,  2.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2964 Average Accuracy: 94.9814\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 132/132 [00:04<00:00, 32.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1888 Average Accuracy: 96.4824\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 266/266 [00:08<00:00, 30.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.4327 Average Accuracy: 90.3630\n",
      "\n",
      "Epoch 8/39\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 92/92 [00:42<00:00,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2608 Average Accuracy: 95.2187\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 132/132 [00:04<00:00, 30.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1971 Average Accuracy: 95.4774\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 266/266 [00:08<00:00, 31.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.4154 Average Accuracy: 89.4869\n",
      "\n",
      "Epoch 9/39\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 92/92 [00:42<00:00,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2316 Average Accuracy: 95.8630\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 132/132 [00:04<00:00, 30.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1935 Average Accuracy: 95.4774\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 266/266 [00:08<00:00, 31.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.4810 Average Accuracy: 88.4856\n",
      "\n",
      "Epoch 10/39\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 92/92 [00:42<00:00,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2148 Average Accuracy: 96.6429\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 132/132 [00:04<00:00, 32.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1734 Average Accuracy: 94.9749\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 266/266 [00:08<00:00, 31.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.4748 Average Accuracy: 88.9862\n",
      "\n",
      "Epoch 11/39\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 92/92 [00:42<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1632 Average Accuracy: 97.1177\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 132/132 [00:04<00:00, 31.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1961 Average Accuracy: 96.2312\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 266/266 [00:08<00:00, 31.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.5096 Average Accuracy: 89.7372\n",
      "\n",
      "Epoch 12/39\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 92/92 [00:42<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1708 Average Accuracy: 96.9820\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 132/132 [00:04<00:00, 30.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1782 Average Accuracy: 96.2312\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 266/266 [00:08<00:00, 31.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.5358 Average Accuracy: 89.4869\n",
      "\n",
      "Epoch 13/39\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 92/92 [00:42<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1278 Average Accuracy: 97.2872\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 132/132 [00:04<00:00, 31.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1883 Average Accuracy: 96.7337\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 266/266 [00:08<00:00, 31.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.5499 Average Accuracy: 89.3617\n",
      "\n",
      "Epoch 14/39\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 92/92 [00:41<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1514 Average Accuracy: 97.3889\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 132/132 [00:04<00:00, 32.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1794 Average Accuracy: 96.4824\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 266/266 [00:08<00:00, 32.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.5679 Average Accuracy: 89.7372\n",
      "\n",
      "Epoch 15/39\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 92/92 [00:42<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1297 Average Accuracy: 97.4568\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 132/132 [00:04<00:00, 32.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1896 Average Accuracy: 96.7337\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 266/266 [00:08<00:00, 31.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.5488 Average Accuracy: 89.7372\n",
      "\n",
      "Epoch 16/39\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 92/92 [00:42<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1297 Average Accuracy: 97.4568\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 132/132 [00:04<00:00, 32.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1928 Average Accuracy: 96.9849\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 266/266 [00:08<00:00, 32.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.5669 Average Accuracy: 89.7372\n",
      "\n",
      "Epoch 17/39\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 92/92 [00:42<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1275 Average Accuracy: 97.1516\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 132/132 [00:04<00:00, 30.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1587 Average Accuracy: 97.2362\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 266/266 [00:08<00:00, 30.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.5641 Average Accuracy: 89.4869\n",
      "\n",
      "Epoch 18/39\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 92/92 [00:42<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1060 Average Accuracy: 98.2367\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 132/132 [00:04<00:00, 30.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1645 Average Accuracy: 96.9849\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 266/266 [00:08<00:00, 31.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.5400 Average Accuracy: 89.6120\n",
      "\n",
      "Epoch 19/39\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 92/92 [00:42<00:00,  2.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1248 Average Accuracy: 97.5246\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 132/132 [00:04<00:00, 31.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1764 Average Accuracy: 96.9849\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 266/266 [00:08<00:00, 30.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.5723 Average Accuracy: 89.4869\n",
      "\n",
      "Epoch 20/39\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 92/92 [00:42<00:00,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1299 Average Accuracy: 97.5924\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 132/132 [00:04<00:00, 31.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1852 Average Accuracy: 97.2362\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 266/266 [00:08<00:00, 31.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.5510 Average Accuracy: 89.4869\n",
      "\n",
      "Epoch 21/39\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 92/92 [00:42<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1210 Average Accuracy: 97.5924\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 132/132 [00:04<00:00, 32.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1850 Average Accuracy: 96.7337\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 266/266 [00:08<00:00, 31.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.5819 Average Accuracy: 89.4869\n",
      "\n",
      "Epoch 22/39\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 92/92 [00:42<00:00,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1351 Average Accuracy: 97.6602\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 132/132 [00:04<00:00, 31.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1747 Average Accuracy: 96.9849\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 266/266 [00:08<00:00, 31.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.5669 Average Accuracy: 89.7372\n",
      "\n",
      "Epoch 23/39\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 92/92 [00:42<00:00,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1307 Average Accuracy: 97.9315\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 132/132 [00:04<00:00, 31.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1461 Average Accuracy: 96.9849\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 266/266 [00:08<00:00, 31.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.5657 Average Accuracy: 89.4869\n",
      "\n",
      "Epoch 24/39\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 92/92 [00:42<00:00,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1239 Average Accuracy: 97.4568\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 132/132 [00:04<00:00, 30.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1625 Average Accuracy: 97.2362\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 266/266 [00:08<00:00, 31.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.5462 Average Accuracy: 89.6120\n",
      "\n",
      "Epoch 25/39\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 92/92 [00:42<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0976 Average Accuracy: 97.8976\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 132/132 [00:04<00:00, 31.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1820 Average Accuracy: 96.7337\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 266/266 [00:08<00:00, 31.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.5457 Average Accuracy: 89.6120\n",
      "\n",
      "Epoch 26/39\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 92/92 [00:42<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1270 Average Accuracy: 97.6602\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 132/132 [00:04<00:00, 30.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1895 Average Accuracy: 97.2362\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 266/266 [00:08<00:00, 30.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.5932 Average Accuracy: 89.4869\n",
      "\n",
      "Epoch 27/39\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 92/92 [00:42<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1153 Average Accuracy: 97.9315\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 132/132 [00:04<00:00, 31.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1826 Average Accuracy: 96.9849\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 266/266 [00:08<00:00, 31.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.5597 Average Accuracy: 89.6120\n",
      "\n",
      "Epoch 28/39\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 92/92 [00:42<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1111 Average Accuracy: 97.6941\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 132/132 [00:04<00:00, 31.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1300 Average Accuracy: 96.9849\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 266/266 [00:08<00:00, 32.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.5802 Average Accuracy: 89.3617\n",
      "\n",
      "Epoch 29/39\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 92/92 [00:41<00:00,  2.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1294 Average Accuracy: 97.4907\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 132/132 [00:04<00:00, 32.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1611 Average Accuracy: 96.9849\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 266/266 [00:08<00:00, 31.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.5519 Average Accuracy: 89.6120\n",
      "\n",
      "Epoch 30/39\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 92/92 [00:41<00:00,  2.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1224 Average Accuracy: 97.6602\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 132/132 [00:04<00:00, 32.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1953 Average Accuracy: 97.2362\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 266/266 [00:08<00:00, 32.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.6108 Average Accuracy: 89.4869\n",
      "\n",
      "Epoch 31/39\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 92/92 [00:41<00:00,  2.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1186 Average Accuracy: 97.6263\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 132/132 [00:04<00:00, 31.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1793 Average Accuracy: 97.2362\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 266/266 [00:08<00:00, 32.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.5937 Average Accuracy: 89.3617\n",
      "\n",
      "Epoch 32/39\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 92/92 [00:41<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1097 Average Accuracy: 97.5585\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 132/132 [00:04<00:00, 32.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1845 Average Accuracy: 97.2362\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 266/266 [00:08<00:00, 32.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.5667 Average Accuracy: 89.6120\n",
      "\n",
      "Epoch 33/39\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 92/92 [00:41<00:00,  2.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1174 Average Accuracy: 97.6602\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 132/132 [00:04<00:00, 30.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1607 Average Accuracy: 97.2362\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 266/266 [00:08<00:00, 31.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.5572 Average Accuracy: 89.7372\n",
      "\n",
      "Epoch 34/39\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 92/92 [00:41<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1323 Average Accuracy: 97.3550\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 132/132 [00:04<00:00, 31.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1736 Average Accuracy: 97.2362\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 266/266 [00:08<00:00, 32.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.5909 Average Accuracy: 89.7372\n",
      "\n",
      "Epoch 35/39\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 92/92 [00:42<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1282 Average Accuracy: 97.4229\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 132/132 [00:04<00:00, 31.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1799 Average Accuracy: 97.2362\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 266/266 [00:08<00:00, 31.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.5747 Average Accuracy: 89.8623\n",
      "\n",
      "Epoch 36/39\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 92/92 [00:42<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1116 Average Accuracy: 97.9654\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 132/132 [00:04<00:00, 32.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1802 Average Accuracy: 97.2362\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 266/266 [00:08<00:00, 32.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.5782 Average Accuracy: 89.2365\n",
      "\n",
      "Epoch 37/39\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 92/92 [00:42<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1248 Average Accuracy: 97.6941\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 132/132 [00:04<00:00, 31.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1882 Average Accuracy: 96.9849\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 266/266 [00:08<00:00, 31.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.5608 Average Accuracy: 89.4869\n",
      "\n",
      "Epoch 38/39\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 92/92 [00:42<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1392 Average Accuracy: 97.4907\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 132/132 [00:04<00:00, 32.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1869 Average Accuracy: 97.2362\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 266/266 [00:08<00:00, 32.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.5839 Average Accuracy: 89.4869\n",
      "\n",
      "Epoch 39/39\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 92/92 [00:42<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1209 Average Accuracy: 97.6602\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 132/132 [00:04<00:00, 32.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.1689 Average Accuracy: 96.9849\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 266/266 [00:08<00:00, 31.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.5689 Average Accuracy: 89.6120\n",
      "\n",
      "Training complete in 37m 6s\n",
      "Best Accuracy: 97.236183\n"
     ]
    }
   ],
   "source": [
    "#@title Train Stage 2\n",
    "# specify loss function\n",
    "\n",
    "#criterion = nn.CrossEntropyLoss()#weight = torch.Tensor([2949/1561,2949/1034,2949/271,2949/83,2949/20]).to(device))\n",
    "#criterion = CBFocalLoss(gamma = 0.5)\n",
    "criterion = CBCrossEntropy()\n",
    "\n",
    "# load model\n",
    "inception.load_state_dict(torch.load( 'F:/Scales/inception_v3_classification_ce_baseline.pth'))\n",
    "\n",
    "# specify optimizer\n",
    "optimizer = torch.optim.Adam(inception.parameters(), lr=0.0005)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 15, gamma=0.2)\n",
    "\n",
    "model_name = \"inception\"\n",
    "\n",
    "loss_list = []\n",
    "acc_list = []\n",
    "res = []\n",
    "training_res = []\n",
    "\n",
    "[inception, loss_list, acc_list, res, training_res] = train_model_classification(\n",
    "    inception,\n",
    "    dataloaders,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    scheduler,\n",
    "    device,\n",
    "    num_epochs=40,\n",
    "    is_inception=(model_name == \"inception\"),\n",
    ")  # train model\n",
    "\n",
    "torch.save(inception.state_dict(), 'F:/Scales/inception_v3_classification.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bdb2ba1e"
   },
   "outputs": [],
   "source": [
    "inception.load_state_dict(torch.load( 'F:/Scales/Gulf Menhaden/inception_v3_classification_source2.pth'))\n",
    "inception = inception.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "DlkmMwdbT8kh"
   },
   "outputs": [],
   "source": [
    "#@title Test Model\n",
    "def test_model_classification(\n",
    "    model, dataloaders, criterion, device, is_inception=False\n",
    "):\n",
    "    loss_list = []\n",
    "    acc_list = []\n",
    "    res = []\n",
    "    training_res = []\n",
    "\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0\n",
    "    best_train_acc = 0\n",
    "\n",
    "    running_corr = [0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "    running_total = [0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "    running_res = []\n",
    "\n",
    "    # Each epoch has a training and validation phase\n",
    "    phase = \"test\"\n",
    "    if phase == \"train\":\n",
    "        model.train()  # Set model to training mode\n",
    "    else:\n",
    "        model.eval()  # Set model to evaluate mode\n",
    "\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    count_3 = 0\n",
    "\n",
    "    print(\"Phase %s\"%(phase))\n",
    "    print(\"-\" * 10)\n",
    "\n",
    "    # Iterate over data.\n",
    "    print(\"expecting data\")\n",
    "    cm = np.zeros((5,5))\n",
    "    for (inputs, wt_l), labels in tqdm(dataloaders):\n",
    "\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        wt_l = wt_l.to(device).float()\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # forward\n",
    "        # track history if only in train\n",
    "        with torch.set_grad_enabled(phase == \"train\"):\n",
    "            # Get model outputs and calculate loss\n",
    "            # Special case for inception because in training it has an auxiliary output. In train\n",
    "            #   mode we calculate the loss by summing the final output and the auxiliary output\n",
    "            #   but in testing we only consider the final output.\n",
    "            if is_inception and phase == \"train\":\n",
    "                # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
    "                outputs, aux_outputs = model(inputs)#, wt_l)\n",
    "\n",
    "                loss1 = criterion(outputs, labels)\n",
    "                loss2 = criterion(aux_outputs, labels)\n",
    "                loss = loss1 + 0.4 * loss2\n",
    "            else:\n",
    "                outputs = model(wt_l)#, wt_l)\n",
    "                outputs = torch.squeeze(outputs)\n",
    "\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            # backward + optimize only if in training phase\n",
    "            if phase == \"train\":\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "\n",
    "        # statistics\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        for i in range(0, len(preds)):\n",
    "            if labels.data[i].cpu().detach().numpy() == 3:\n",
    "                count_3 += 1\n",
    "\n",
    "            if preds[i] == labels.data[i]:\n",
    "                running_corr[int(labels.data[i].cpu().detach().numpy())] += 1.0\n",
    "            cm[preds[i], labels.data[i]] +=1\n",
    "            running_total[int(labels.data[i].cpu().detach().numpy())] += 1.0\n",
    "\n",
    "\n",
    "        epoch_loss = running_loss / len(dataloaders.dataset)\n",
    "        epoch_acc = 100.0 * running_corrects / len(dataloaders.dataset)\n",
    "        running_res = [100.0 * i / max(1,j) for i, j in zip(running_corr, running_total)]\n",
    "        \n",
    "        print(\"{} Loss: {:.4f} Average Accuracy: {:.4f}\".format(phase, epoch_loss, epoch_acc))\n",
    "        print(running_res)\n",
    "        # deep copy the model\n",
    "        if phase == \"train\" and epoch_acc > best_train_acc:\n",
    "            best_train_acc = epoch_acc\n",
    "            training_res = running_res.copy()\n",
    "\n",
    "        if (phase == \"val\" or phase == \"test\") and epoch_acc > best_acc:\n",
    "            best_acc = epoch_acc\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            res = running_res.copy()\n",
    "\n",
    "        if phase == \"val\" or phase == \"test\":\n",
    "            loss_list.append(epoch_loss)\n",
    "            acc_list.append(epoch_acc.cpu().clone().numpy())\n",
    "\n",
    "    print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(\n",
    "        \"Training complete in {:.0f}m {:.0f}s\".format(\n",
    "            time_elapsed // 60, time_elapsed % 60\n",
    "        )\n",
    "    )\n",
    "    print(\"Best Accuracy: {:4f}\".format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "\n",
    "    # plt.plot(loss_list, error_list)\n",
    "    return [acc_list, res], cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "hsjzHYm7t7_k",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#@title Get Feature and Test Model\n",
    "def test_model_classification_feature(\n",
    "    model, dataloader, criterion, device, is_inception=False\n",
    "):\n",
    "    loss_list = []\n",
    "    acc_list = []\n",
    "    res = []\n",
    "    training_res = []\n",
    "\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0\n",
    "    best_train_acc = 0\n",
    "\n",
    "    running_corr = [0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "    running_total = [0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "    running_res = []\n",
    "\n",
    "    # Each epoch has a training and validation phase\n",
    "    phase = \"test\"\n",
    "    if phase == \"train\":\n",
    "        model.train()  # Set model to training mode\n",
    "    else:\n",
    "        model.eval()  # Set model to evaluate mode\n",
    "\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    count_3 = 0\n",
    "\n",
    "    print(\"Phase %s\"%(phase))\n",
    "    print(\"-\" * 10)\n",
    "\n",
    "    # Iterate over data.\n",
    "    print(\"expecting data\")\n",
    "    cm = np.zeros((5,5))\n",
    "    train_fea = []\n",
    "    train_label = []\n",
    "    for (inputs, wt_l), labels in tqdm(dataloader):\n",
    "\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        wt_l = wt_l.to(device).float()\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # forward\n",
    "        # track history if only in train\n",
    "        with torch.set_grad_enabled(phase == \"train\"):\n",
    "            # Get model outputs and calculate loss\n",
    "            # Special case for inception because in training it has an auxiliary output. In train\n",
    "            #   mode we calculate the loss by summing the final output and the auxiliary output\n",
    "            #   but in testing we only consider the final output.\n",
    "            outputs, feature = model.get_fea(inputs, wt_l)\n",
    "            outputs = torch.squeeze(outputs)\n",
    "\n",
    "            features = feature.detach().cpu().numpy()\n",
    "            gt = labels.detach().cpu().numpy()\n",
    "            for i in range(features.shape[0]):\n",
    "                train_fea.append(features[i,:])\n",
    "                train_label.append(gt[i])\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            # backward + optimize only if in training phase\n",
    "            if phase == \"train\":\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "\n",
    "        # statistics\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        for i in range(0, len(preds)):\n",
    "            if labels.data[i].cpu().detach().numpy() == 3:\n",
    "                count_3 += 1\n",
    "\n",
    "            if preds[i] == labels.data[i]:\n",
    "                running_corr[int(labels.data[i].cpu().detach().numpy())] += 1.0\n",
    "            cm[preds[i], labels.data[i]] +=1\n",
    "            running_total[int(labels.data[i].cpu().detach().numpy())] += 1.0\n",
    "\n",
    "\n",
    "        epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "        epoch_acc = 100.0 * running_corrects / len(dataloaders[phase].dataset)\n",
    "        running_res = [100.0 * i / max(1,j) for i, j in zip(running_corr, running_total)]\n",
    "\n",
    "        print(\"{} Loss: {:.4f} Average Accuracy: {:.4f}\".format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "        # deep copy the model\n",
    "        if phase == \"train\" and epoch_acc > best_train_acc:\n",
    "            best_train_acc = epoch_acc\n",
    "            training_res = running_res.copy()\n",
    "\n",
    "        if (phase == \"val\" or phase == \"test\") and epoch_acc > best_acc:\n",
    "            best_acc = epoch_acc\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            res = running_res.copy()\n",
    "\n",
    "        if phase == \"val\" or phase == \"test\":\n",
    "            loss_list.append(epoch_loss)\n",
    "            acc_list.append(epoch_acc.cpu().clone().numpy())\n",
    "\n",
    "    print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(\n",
    "        \"Training complete in {:.0f}m {:.0f}s\".format(\n",
    "            time_elapsed // 60, time_elapsed % 60\n",
    "        )\n",
    "    )\n",
    "    print(\"Best Accuracy: {:4f}\".format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "\n",
    "    # plt.plot(loss_list, error_list)\n",
    "    return [acc_list, res], cm, train_fea, train_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 327
    },
    "id": "rt_M90E9zOlR",
    "outputId": "5573c4a7-a62b-40f8-e8b7-e4785baaa31d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase test\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|██▌                                                                                                        | 1/41 [00:01<00:51,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.0112 Average Accuracy: 2.1717\n",
      "[100.0, 83.33333333333333, 88.88888888888889, 0.0, 100.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|█████▏                                                                                                     | 2/41 [00:02<00:41,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.0196 Average Accuracy: 4.2399\n",
      "[100.0, 86.36363636363636, 88.88888888888889, 75.0, 66.66666666666667]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|███████▊                                                                                                   | 3/41 [00:03<00:36,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.0243 Average Accuracy: 6.4116\n",
      "[100.0, 90.3225806451613, 89.28571428571429, 71.42857142857143, 50.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|██████████▍                                                                                                | 4/41 [00:03<00:33,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.0292 Average Accuracy: 8.6867\n",
      "[100.0, 92.3076923076923, 92.3076923076923, 66.66666666666667, 40.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█████████████                                                                                              | 5/41 [00:04<00:33,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.0321 Average Accuracy: 11.0652\n",
      "[100.0, 94.23076923076923, 93.47826086956522, 72.72727272727273, 42.857142857142854]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|███████████████▋                                                                                           | 6/41 [00:05<00:33,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.0480 Average Accuracy: 12.9266\n",
      "[100.0, 95.3125, 90.19607843137256, 61.111111111111114, 42.857142857142854]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|██████████████████▎                                                                                        | 7/41 [00:06<00:31,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.0610 Average Accuracy: 14.8914\n",
      "[100.0, 93.05555555555556, 91.2280701754386, 62.5, 54.54545454545455]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████████▉                                                                                      | 8/41 [00:07<00:30,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.0714 Average Accuracy: 16.8563\n",
      "[100.0, 93.82716049382717, 90.625, 58.62068965517241, 57.142857142857146]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|███████████████████████▍                                                                                   | 9/41 [00:08<00:30,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.0754 Average Accuracy: 19.2347\n",
      "[100.0, 94.56521739130434, 92.0, 56.666666666666664, 60.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|█████████████████████████▊                                                                                | 10/41 [00:09<00:29,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.0863 Average Accuracy: 21.4064\n",
      "[100.0, 95.14563106796116, 91.56626506024097, 57.57575757575758, 56.25]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|████████████████████████████▍                                                                             | 11/41 [00:10<00:29,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.0929 Average Accuracy: 23.7849\n",
      "[100.0, 95.76271186440678, 91.11111111111111, 60.0, 56.25]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|███████████████████████████████                                                                           | 12/41 [00:11<00:28,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.1012 Average Accuracy: 26.0600\n",
      "[100.0, 95.45454545454545, 90.9090909090909, 61.111111111111114, 56.25]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|█████████████████████████████████▌                                                                        | 13/41 [00:12<00:26,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.1138 Average Accuracy: 27.9214\n",
      "[100.0, 95.1048951048951, 91.50943396226415, 57.5, 50.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|████████████████████████████████████▏                                                                     | 14/41 [00:13<00:24,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.1170 Average Accuracy: 30.1965\n",
      "[100.0, 94.96855345911949, 91.66666666666667, 57.142857142857146, 57.142857142857146]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|██████████████████████████████████████▊                                                                   | 15/41 [00:14<00:23,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.1242 Average Accuracy: 32.2647\n",
      "[100.0, 94.28571428571429, 91.96428571428571, 55.55555555555556, 57.142857142857146]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|█████████████████████████████████████████▎                                                                | 16/41 [00:15<00:24,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.1435 Average Accuracy: 34.0228\n",
      "[100.0, 93.44262295081967, 90.9090909090909, 54.166666666666664, 58.333333333333336]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|███████████████████████████████████████████▉                                                              | 17/41 [00:16<00:23,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.1503 Average Accuracy: 36.1944\n",
      "[100.0, 93.33333333333333, 91.33858267716535, 55.76923076923077, 57.69230769230769]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|██████████████████████████████████████████████▌                                                           | 18/41 [00:17<00:21,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.1551 Average Accuracy: 38.3661\n",
      "[100.0, 93.20388349514563, 91.36690647482014, 55.76923076923077, 55.55555555555556]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|█████████████████████████████████████████████████                                                         | 19/41 [00:18<00:20,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.1584 Average Accuracy: 40.7446\n",
      "[100.0, 93.57798165137615, 91.83673469387755, 55.55555555555556, 57.142857142857146]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|███████████████████████████████████████████████████▋                                                      | 20/41 [00:18<00:19,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.1618 Average Accuracy: 42.9162\n",
      "[100.0, 93.96551724137932, 92.15686274509804, 55.357142857142854, 53.333333333333336]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|██████████████████████████████████████████████████████▎                                                   | 21/41 [00:20<00:19,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.1661 Average Accuracy: 45.1913\n",
      "[100.0, 94.26229508196721, 91.92546583850931, 55.932203389830505, 54.83870967741935]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|████████████████████████████████████████████████████████▉                                                 | 22/41 [00:20<00:18,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.1761 Average Accuracy: 47.3630\n",
      "[90.0, 94.55252918287938, 92.21556886227545, 56.666666666666664, 52.94117647058823]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|███████████████████████████████████████████████████████████▍                                              | 23/41 [00:21<00:16,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.1787 Average Accuracy: 49.8449\n",
      "[91.66666666666667, 94.81481481481481, 92.39766081871345, 58.73015873015873, 55.55555555555556]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|██████████████████████████████████████████████████████████████                                            | 24/41 [00:23<00:17,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.1886 Average Accuracy: 52.0165\n",
      "[92.85714285714286, 94.6236559139785, 92.26519337016575, 59.09090909090909, 55.55555555555556]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|████████████████████████████████████████████████████████████████▋                                         | 25/41 [00:23<00:15,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.1962 Average Accuracy: 54.0848\n",
      "[93.75, 93.81443298969072, 92.55319148936171, 58.208955223880594, 57.89473684210526]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|███████████████████████████████████████████████████████████████████▏                                      | 26/41 [00:24<00:14,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.2101 Average Accuracy: 56.2565\n",
      "[94.44444444444444, 94.05940594059406, 91.87817258883248, 57.35294117647059, 57.89473684210526]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|█████████████████████████████████████████████████████████████████████▊                                    | 27/41 [00:25<00:13,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.2140 Average Accuracy: 58.5315\n",
      "[94.73684210526316, 94.28571428571429, 92.07920792079207, 59.15492957746479, 56.09756097560975]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|████████████████████████████████████████████████████████████████████████▍                                 | 28/41 [00:26<00:12,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.2191 Average Accuracy: 60.8066\n",
      "[94.73684210526316, 94.46153846153847, 92.01877934272301, 58.333333333333336, 58.13953488372093]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|██████████████████████████████████████████████████████████████████████████▉                               | 29/41 [00:27<00:11,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.2223 Average Accuracy: 63.1851\n",
      "[95.0, 94.73684210526316, 91.74311926605505, 58.9041095890411, 58.13953488372093]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|█████████████████████████████████████████████████████████████████████████████▌                            | 30/41 [00:28<00:10,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.2326 Average Accuracy: 65.2534\n",
      "[95.0, 94.90084985835693, 91.62995594713657, 58.666666666666664, 55.55555555555556]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|████████████████████████████████████████████████████████████████████████████████▏                         | 31/41 [00:29<00:09,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.2362 Average Accuracy: 67.5284\n",
      "[95.0, 94.78021978021978, 91.91489361702128, 58.97435897435897, 57.4468085106383]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|██████████████████████████████████████████████████████████████████████████████████▋                       | 32/41 [00:30<00:08,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.2432 Average Accuracy: 69.8035\n",
      "[95.0, 94.96021220159152, 91.66666666666667, 59.25925925925926, 60.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|█████████████████████████████████████████████████████████████████████████████████████▎                    | 33/41 [00:31<00:08,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.2564 Average Accuracy: 71.7684\n",
      "[95.45454545454545, 94.83204134366925, 91.2, 59.25925925925926, 57.69230769230769]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|███████████████████████████████████████████████████████████████████████████████████████▉                  | 34/41 [00:32<00:06,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.2668 Average Accuracy: 73.8366\n",
      "[95.83333333333333, 94.5, 91.40625, 58.53658536585366, 57.407407407407405]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|██████████████████████████████████████████████████████████████████████████████████████████▍               | 35/41 [00:33<00:05,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.2800 Average Accuracy: 75.9049\n",
      "[96.0, 94.63414634146342, 90.83969465648855, 59.09090909090909, 58.18181818181818]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|█████████████████████████████████████████████████████████████████████████████████████████████             | 36/41 [00:34<00:04,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.2915 Average Accuracy: 78.0765\n",
      "[92.3076923076923, 94.5754716981132, 90.74074074074075, 59.550561797752806, 58.18181818181818]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|███████████████████████████████████████████████████████████████████████████████████████████████▋          | 37/41 [00:35<00:04,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.3004 Average Accuracy: 80.2482\n",
      "[92.3076923076923, 94.70046082949308, 90.3225806451613, 60.43956043956044, 58.62068965517241]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|██████████████████████████████████████████████████████████████████████████████████████████████████▏       | 38/41 [00:36<00:02,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.3069 Average Accuracy: 82.3164\n",
      "[92.5925925925926, 94.40715883668904, 90.55944055944056, 59.78260869565217, 58.333333333333336]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|████████████████████████████████████████████████████████████████████████████████████████████████████▊     | 39/41 [00:37<00:01,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.3320 Average Accuracy: 84.0745\n",
      "[89.65517241379311, 94.10480349344978, 90.03436426116839, 60.0, 58.73015873015873]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|███████████████████████████████████████████████████████████████████████████████████████████████████████▍  | 40/41 [00:38<00:01,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.3377 Average Accuracy: 86.2461\n",
      "[90.0, 94.01709401709402, 89.70099667774086, 61.224489795918366, 58.73015873015873]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 41/41 [00:38<00:00,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.3414 Average Accuracy: 86.8666\n",
      "[90.0, 94.08033826638477, 89.43894389438944, 61.224489795918366, 58.73015873015873]\n",
      "\n",
      "Training complete in 0m 39s\n",
      "Best Accuracy: 86.866600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()#weight = torch.Tensor([1,1,1,10,10]).to(device))\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#weights = load_state_dict_from_url(\"https://download.pytorch.org/models/swin_t-704ceda3.pth\", progress=True)\n",
    "#model = torchvision.models.swin_t(weights = None, num_classes = 5).to(device)\n",
    "#weights = load_state_dict_from_url(\"https://download.pytorch.org/models/resnet18-f37072fd.pth\", progress=True)\n",
    "model = torchvision.models.resnet18(weights = None, num_classes = 5).to(device)\n",
    "\n",
    "#weights = load_state_dict_from_url(\"https://download.pytorch.org/models/vit_b_16-c867db91.pth\", progress=True)\n",
    "#model = torchvision.models.vit_b_16(weights = None, num_classes = 5)\n",
    "#model.load_state_dict(torch.load( 'F:/Scales/Atlantic_menhaden_swint_temp.pth'))\n",
    "model.load_state_dict(torch.load( 'F:/Scales/Atlantic_menhaden_resnet.pth'))\n",
    "model_name = \"inception\"\n",
    "optimizer = torch.optim.Adam(inception.parameters(), lr=0.001)\n",
    "loss_list = []\n",
    "acc_list = []\n",
    "res = []\n",
    "training_res = []\n",
    "\n",
    "[acc_list, res], cm = test_model_classification(\n",
    "    model,\n",
    "    dataloaders[\"test\"],\n",
    "    criterion,\n",
    "    device,\n",
    "    is_inception=(model_name == \"inception\"),\n",
    ")  # train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "utrK1oShUNop",
    "jupyter": {
     "source_hidden": true
    },
    "outputId": "bd3df520-2c16-49d8-f3aa-d6a54bee21cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase test\n",
      "----------\n",
      "expecting data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|███▌                                                                                                                                                   | 1/42 [00:00<00:32,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.0381 Average Accuracy: 0.6545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|███████▏                                                                                                                                               | 2/42 [00:01<00:25,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.0813 Average Accuracy: 1.3091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|██████████▊                                                                                                                                            | 3/42 [00:01<00:23,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.1215 Average Accuracy: 2.0364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|██████████████▍                                                                                                                                        | 4/42 [00:02<00:22,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.1666 Average Accuracy: 2.4727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█████████████████▉                                                                                                                                     | 5/42 [00:03<00:21,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.2190 Average Accuracy: 2.9818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█████████████████████▌                                                                                                                                 | 6/42 [00:03<00:20,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.2672 Average Accuracy: 3.7818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█████████████████████████▏                                                                                                                             | 7/42 [00:04<00:19,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.3143 Average Accuracy: 4.3636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|████████████████████████████▊                                                                                                                          | 8/42 [00:04<00:19,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.3614 Average Accuracy: 4.8000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|████████████████████████████████▎                                                                                                                      | 9/42 [00:05<00:18,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.4207 Average Accuracy: 4.8727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|███████████████████████████████████▋                                                                                                                  | 10/42 [00:05<00:18,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.4703 Average Accuracy: 5.3818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|███████████████████████████████████████▎                                                                                                              | 11/42 [00:06<00:17,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.5144 Average Accuracy: 6.1091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██████████████████████████████████████████▊                                                                                                           | 12/42 [00:06<00:17,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.5639 Average Accuracy: 6.6182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|██████████████████████████████████████████████▍                                                                                                       | 13/42 [00:07<00:16,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.6056 Average Accuracy: 7.2727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|██████████████████████████████████████████████████                                                                                                    | 14/42 [00:08<00:15,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.6587 Average Accuracy: 7.7091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|█████████████████████████████████████████████████████▌                                                                                                | 15/42 [00:08<00:15,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.7084 Average Accuracy: 8.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|█████████████████████████████████████████████████████████▏                                                                                            | 16/42 [00:09<00:14,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.7483 Average Accuracy: 8.6545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████████████████████████████████████████████████████████████▋                                                                                         | 17/42 [00:09<00:14,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.7984 Average Accuracy: 9.1636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|████████████████████████████████████████████████████████████████▎                                                                                     | 18/42 [00:10<00:13,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.8381 Average Accuracy: 9.7455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|███████████████████████████████████████████████████████████████████▊                                                                                  | 19/42 [00:10<00:12,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.8876 Average Accuracy: 10.4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|███████████████████████████████████████████████████████████████████████▍                                                                              | 20/42 [00:11<00:12,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.9320 Average Accuracy: 10.9818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|███████████████████████████████████████████████████████████████████████████                                                                           | 21/42 [00:11<00:11,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.9792 Average Accuracy: 11.5636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|██████████████████████████████████████████████████████████████████████████████▌                                                                       | 22/42 [00:12<00:11,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 1.0159 Average Accuracy: 12.4364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|██████████████████████████████████████████████████████████████████████████████████▏                                                                   | 23/42 [00:13<00:10,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 1.0727 Average Accuracy: 12.8000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|█████████████████████████████████████████████████████████████████████████████████████▋                                                                | 24/42 [00:13<00:10,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 1.1183 Average Accuracy: 13.1636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████████████████████████████████████████████████████████████▎                                                            | 25/42 [00:14<00:09,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 1.1645 Average Accuracy: 13.6727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|████████████████████████████████████████████████████████████████████████████████████████████▊                                                         | 26/42 [00:14<00:09,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 1.2067 Average Accuracy: 14.3273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|████████████████████████████████████████████████████████████████████████████████████████████████▍                                                     | 27/42 [00:15<00:08,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 1.2709 Average Accuracy: 14.6182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|████████████████████████████████████████████████████████████████████████████████████████████████████                                                  | 28/42 [00:15<00:07,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 1.3176 Average Accuracy: 14.9818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|███████████████████████████████████████████████████████████████████████████████████████████████████████▌                                              | 29/42 [00:16<00:07,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 1.3625 Average Accuracy: 15.7091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                          | 30/42 [00:17<00:06,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 1.4043 Average Accuracy: 16.2909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                       | 31/42 [00:17<00:06,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 1.4418 Average Accuracy: 16.8727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                   | 32/42 [00:18<00:05,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 1.4883 Average Accuracy: 17.5273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 79%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                | 33/42 [00:18<00:05,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 1.5340 Average Accuracy: 17.8909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 81%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                            | 34/42 [00:19<00:04,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 1.5642 Average Accuracy: 18.9091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                         | 35/42 [00:19<00:03,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 1.6151 Average Accuracy: 19.4909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                     | 36/42 [00:20<00:03,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 1.6593 Average Accuracy: 20.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                 | 37/42 [00:21<00:02,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 1.7042 Average Accuracy: 20.4364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋              | 38/42 [00:21<00:02,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 1.7495 Average Accuracy: 20.8000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎          | 39/42 [00:22<00:01,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 1.7951 Average Accuracy: 21.2364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊       | 40/42 [00:22<00:01,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 1.8371 Average Accuracy: 21.7455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍   | 41/42 [00:23<00:00,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 1.8821 Average Accuracy: 22.1818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 42/42 [00:24<00:00,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 1.9250 Average Accuracy: 22.6182\n",
      "\n",
      "Training complete in 0m 24s\n",
      "Best Accuracy: 22.618181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "criterion = nn.CrossEntropyLoss()#weight = torch.Tensor([1,1,1,10,10]).to(device))\n",
    "\n",
    "model_name = \"inception\"\n",
    "optimizer = torch.optim.Adam(inception.parameters(), lr=0.001)\n",
    "loss_list = []\n",
    "acc_list = []\n",
    "res = []\n",
    "training_res = []\n",
    "\n",
    "[acc_list, res], cm, fea, label = test_model_classification_feature(\n",
    "    inception,\n",
    "    dataloaders[\"test\"],\n",
    "    criterion,\n",
    "    device,\n",
    "    is_inception=(model_name == \"inception\"),\n",
    ")  # train model\n",
    "with open(\"val_feas.npy\",'wb') as f:\n",
    "    np.save(f, np.array(fea))\n",
    "with open(\"val_labels.npy\",'wb') as f:\n",
    "    np.save(f, np.array(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "8f704836",
    "jupyter": {
     "source_hidden": true
    },
    "outputId": "15d8ed39-8e67-43b7-baa0-f19cd24a8012"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(res))\n\u001b[0;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m10\u001b[39m))\n\u001b[1;32m----> 3\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbar\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining_res\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwidth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClassification Age Training Set Prediction Result\u001b[39m\u001b[38;5;124m'\u001b[39m, fontsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m)\n\u001b[0;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAge Group (years old)\u001b[39m\u001b[38;5;124m'\u001b[39m, fontsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\deepda\\lib\\site-packages\\matplotlib\\pyplot.py:2387\u001b[0m, in \u001b[0;36mbar\u001b[1;34m(x, height, width, bottom, align, data, **kwargs)\u001b[0m\n\u001b[0;32m   2383\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mbar)\n\u001b[0;32m   2384\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbar\u001b[39m(\n\u001b[0;32m   2385\u001b[0m         x, height, width\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.8\u001b[39m, bottom\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m, align\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcenter\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   2386\u001b[0m         data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m-> 2387\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgca\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbar\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2388\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwidth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwidth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbottom\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbottom\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malign\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malign\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2389\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\deepda\\lib\\site-packages\\matplotlib\\__init__.py:1412\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[1;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1409\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m   1410\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(ax, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   1411\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1412\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43max\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msanitize_sequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1414\u001b[0m     bound \u001b[38;5;241m=\u001b[39m new_sig\u001b[38;5;241m.\u001b[39mbind(ax, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1415\u001b[0m     auto_label \u001b[38;5;241m=\u001b[39m (bound\u001b[38;5;241m.\u001b[39marguments\u001b[38;5;241m.\u001b[39mget(label_namer)\n\u001b[0;32m   1416\u001b[0m                   \u001b[38;5;129;01mor\u001b[39;00m bound\u001b[38;5;241m.\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(label_namer))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\deepda\\lib\\site-packages\\matplotlib\\axes\\_axes.py:2342\u001b[0m, in \u001b[0;36mAxes.bar\u001b[1;34m(self, x, height, width, bottom, align, **kwargs)\u001b[0m\n\u001b[0;32m   2339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m yerr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2340\u001b[0m         yerr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_dx(yerr, y0, y, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_yunits)\n\u001b[1;32m-> 2342\u001b[0m x, height, width, y, linewidth, hatch \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbroadcast_arrays\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2343\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Make args iterable too.\u001b[39;49;00m\n\u001b[0;32m   2344\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43matleast_1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlinewidth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2346\u001b[0m \u001b[38;5;66;03m# Now that units have been converted, set the tick locations.\u001b[39;00m\n\u001b[0;32m   2347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m orientation \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvertical\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[1;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36mbroadcast_arrays\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\deepda\\lib\\site-packages\\numpy\\lib\\stride_tricks.py:538\u001b[0m, in \u001b[0;36mbroadcast_arrays\u001b[1;34m(subok, *args)\u001b[0m\n\u001b[0;32m    531\u001b[0m \u001b[38;5;66;03m# nditer is not used here to avoid the limit of 32 arrays.\u001b[39;00m\n\u001b[0;32m    532\u001b[0m \u001b[38;5;66;03m# Otherwise, something like the following one-liner would suffice:\u001b[39;00m\n\u001b[0;32m    533\u001b[0m \u001b[38;5;66;03m# return np.nditer(args, flags=['multi_index', 'zerosize_ok'],\u001b[39;00m\n\u001b[0;32m    534\u001b[0m \u001b[38;5;66;03m#                  order='C').itviews\u001b[39;00m\n\u001b[0;32m    536\u001b[0m args \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39marray(_m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, subok\u001b[38;5;241m=\u001b[39msubok) \u001b[38;5;28;01mfor\u001b[39;00m _m \u001b[38;5;129;01min\u001b[39;00m args]\n\u001b[1;32m--> 538\u001b[0m shape \u001b[38;5;241m=\u001b[39m \u001b[43m_broadcast_shape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    540\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(array\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m shape \u001b[38;5;28;01mfor\u001b[39;00m array \u001b[38;5;129;01min\u001b[39;00m args):\n\u001b[0;32m    541\u001b[0m     \u001b[38;5;66;03m# Common case where nothing needs to be broadcasted.\u001b[39;00m\n\u001b[0;32m    542\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m args\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\deepda\\lib\\site-packages\\numpy\\lib\\stride_tricks.py:420\u001b[0m, in \u001b[0;36m_broadcast_shape\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    415\u001b[0m \u001b[38;5;124;03m\"\"\"Returns the shape of the arrays that would result from broadcasting the\u001b[39;00m\n\u001b[0;32m    416\u001b[0m \u001b[38;5;124;03msupplied arrays against each other.\u001b[39;00m\n\u001b[0;32m    417\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    418\u001b[0m \u001b[38;5;66;03m# use the old-iterator because np.nditer does not handle size 0 arrays\u001b[39;00m\n\u001b[0;32m    419\u001b[0m \u001b[38;5;66;03m# consistently\u001b[39;00m\n\u001b[1;32m--> 420\u001b[0m b \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbroadcast\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    421\u001b[0m \u001b[38;5;66;03m# unfortunately, it cannot handle 32 or more arguments directly\u001b[39;00m\n\u001b[0;32m    422\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pos \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m32\u001b[39m, \u001b[38;5;28mlen\u001b[39m(args), \u001b[38;5;241m31\u001b[39m):\n\u001b[0;32m    423\u001b[0m     \u001b[38;5;66;03m# ironically, np.broadcast does not properly handle np.broadcast\u001b[39;00m\n\u001b[0;32m    424\u001b[0m     \u001b[38;5;66;03m# objects (it treats them as scalars)\u001b[39;00m\n\u001b[0;32m    425\u001b[0m     \u001b[38;5;66;03m# use broadcasting to avoid allocating the full array\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: shape mismatch: objects cannot be broadcast to a single shape"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(len(res))\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.bar([0, 1, 2, 3, 4], training_res, width=0.5)\n",
    "\n",
    "plt.title('Classification Age Training Set Prediction Result', fontsize=15)\n",
    "plt.xlabel('Age Group (years old)', fontsize=15)\n",
    "plt.ylabel('Prediction Accuracy (%)', fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 645
    },
    "id": "6znhvLKsc7BI",
    "jupyter": {
     "source_hidden": true
    },
    "outputId": "2a47543a-75f0-402b-9ba4-978ae905bf6d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100.0, 98.0295566502463, 84.0, 71.7948717948718, 65.0]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmkAAAJjCAYAAABX6oa0AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAA5P0lEQVR4nO3deZgsVX3/8fdHQEFQFFlEAS/+gnuMJkgkbiCugOIGQlwwMWISTDRqIsYNoyZqjEuIC6gsbqioKIoLBEFFDQqCiYgICgLKvgiyinx/f5waaZqZuX3vneVc5v16nn6mu6q66tvVPdOfOXVOVaoKSZIk9eV2i12AJEmSbs2QJkmS1CFDmiRJUocMaZIkSR0ypEmSJHXIkCZJktQhQ5oWRZJnJPl6kiuSXJ/kp0nenGTDYf6yJJVk5wWu6+wk7xib9vokv0xyU5KDk2w31PagOd72E5K8bJrpByc5cS63NWE96ya5Osk1Se60gNud2r+z3lZxG7dPsm+Sh4xNX/DP3bCf35Tk9CTXJrkwyTeSvHAF17Px8JqWTbDsC8b250VJvpbkj1f6hSx/mw8atrXdyLRK8pIVWEcXvyPD9qb23U1Jzkty6CT7fp7qmXo/1xseT/xZUN/WXOwCtPQk+Q/gZcBBwLuAK4EHAH8NPBB4+qIV17Z96dSDJFsDbwT+GTgOuAi4GNgW+Nkcb/sJwLOAd49NfxOwzhxvaxK7AHccuf+xBdruD2j7d8ojgHcAzwDOn6Nt3B54A3A2cMrI9POHbf9kjrYzic8CDwXeDPwI2Bh4NLAj8OEVWM/GtNd0HO11TeKxwLXApsDrgGOT3L+qfrUC210V2wJnrcDyPf2O/AT4C1pjx/2AtwBfTvKQqrphgWsZtzKfBXXIkKYFleQpwMuBF1bVgSOzvpHkANof4UVTVSePTbrf8PO9VXXlyPT/WaCSqKq5DoOT2oObv0D3YIFC2rCff79/p1pXgZOr6ux53vb1LOB7m2Qr4InAblV12MisTyXJApTw/ar6zVDLicAvgOcA/z5NrWsBN1XV7+Zq41U1J/t6kX5Hrh6p/ztJrgEOBbYGvrMI9eg2yMOdWmj/APxgLKABUFW/q6qvzPTEJM9PcnySy5JcnuTYoaVrdJkHJvnqsMzVSU5LsvfI/Ecm+VaSK4fbKUl2HZn/+8OdSQ4GPjrM+vXUoZrpDncmWSPJq4fDttcPhz8OHpm/U5Kjh8NKVyb5nyRPGJm/L/AK4F4jh1EOnqpj/FBOkockOWY4FHl5ko8n2WRk/tRhu92S7J/k10NNb0yy3N/7JHelhYdPDrcnJLnbNMvtmuSM4TDdsUkeOmz3BWPL/VWSU4d984sk/7S8GpZT39pJ3p7k3GGdP0yy49gyT01y0vA5uDzJCUkeM8y+avh50Mj+XpZpDndOfSaS/MOwDy9P8skkdxnb3oOTfCfJdcNr3THJiaOfg2lMreOC8Rk1djmYJFsM271seN+/luS+w7xlwP8Nix6blTgkXFXn0lqJlw3rPC7JZ5LsleRnwHXAPYZ5y30/k/zt8P5cneSLtNa68WVudbgzydOTfG/4TF2a5MtJ7tXb78g0fjj83HxkG7dLsk+SM3Nzt449x+pc3t+k6fbRvkkuma6IufgsqB+GNC2YtP/E/wz46kquYhnwEWBX4M+B84BvJrn3yDJHAL8Dngs8FdgPuNOw/TsDXwJ+DjyTdtjko9z8RTnuTbRDUNAOC21LOxQ3nf1ph0U/DexM+zJZd2T+lsAXgecN2/4O8JUkjxjmfwj4BO3Letvh9qbpNpRkI9phjDsO++HvgMcARye5/djibwd+M7zWjwGvH+4vz7OAtWgB7VBaq/stnpcWkD9J2ydPp+37T01T7z8C7wc+T9s37wfeNP7Fs4I+A7wA+FfgKcD3gSMy9DFL8v+GZb4+zH8O7b3fYHj+Y4efb+bm/T3bodTdgB2AvYBXDa/jX0de4x2Br9EOue0xrPddwBbLeR2nA1cD707rb7X2dAsl2QA4HrgvrVvAbrTP138nWWeo/TnD4nuPvKaJpfU73IBbBsZHAH9De81Pof2zstz3M8kuwHtp+/wZtNBwq3/MpqnhecDnaF0JdqMdTvwpsBH9/Y6Mm3qvRw/f7ge8FjgA2Ak4HDhw6p+AlfibNIlV/iyoI1XlzduC3IC7AwW8eIJllw3L7jzD/NvRgsNPgNcP0zYcnvOHMzxn62H+nWbZ7tnAO0Yev2B4znoj07Ybpj1oeHy/4fHfT7gfpmr/GnDgyPR3AGdPs/zBwIkjj98KXAHceWTaNkMNe4ztv4+MresU4JMT1Ph14Mcjj08Fjhtb5jBaH6qMTPunYbsvGB7fmfYF+Iax5/4L7ct2jQlq2XlY57Lh8Q7D48eMLfdN4LDh/rOAS2dZ53qjdc72uRs+Ez8D1hyZ9m7ggpHHewM3APec5j05eDmvb49hH9Wwjm8CLxrbr2+i9ZXcYGTaXYFfA3sPjx80rGO7Cfbp1Od6/eGzuDktYN8IPGRY5jhaf7W7jzxvovcT+B7wlbFlPjhe3/D4JSO/F78EPjdL3V38jkxtb9h3awEPBk4efc3AHwA3AXuOPfcjtMPMMNnfpN/vo5Fp+wKXTPN+rreinwVvfd9sSdNiWKmm9yT3T3J4kgtprWW/pbUs3GdY5DLgXOADSZ6dZOOxVfyM9gXziSS7jB+uWgXbDz8PnqX2zZIckuSXtC/C39L6391npufMYhvgqBrpI1dV36OFiUeOLXvU2OMfA5vNtvIkm9JaHT45MvlQ4NFJ7jky7WHAF2v4VhgcMba6bWktPoclWXPqRguBmyyvlhk8jhYIvj22zmNoX3rQWm7WH/b5E5KsO9PKJnRsVd048vjHwMYjrTIPA06qql9OLTC8Jxcub8VVdShwL+Avafv8PrSWl0+MLPY44GjgypHXexVwEje/5pVxBe2zeA6tdfEvq+qUkfknVdVoy9py388ka9AGQnxhbFufW04t96UdTj1oJV/LqHn9HRn8CW3f3UA71HlnWuCesgMtpB0+zef0IcN+mq+/SbqNMKRpIV0KXM/yDwHdynAo5ijaf/wvBx5F+2L8IbA2QFXdRAs+F9AOrVww9PV46DD/8mH+WrTDkhcnOXLscOnKuButE/GV080c+rccQTvU+3paqHsY8JWp2lfQpkz/5X8hNx/Om3LF2OMbJtjms2l/G76a5C7DF8dXgAzzptyd1odp1PjjqU7/p9K+0KZuxw7TN2fFbThs+7djt32n1ldVp9NGpN4b+DJwSZJPDIfBVsYVY49voO2PqZA23b5ghmm3UlWXVtVBVfV82ms4CNg9yR8Ni2xI2/fjr3l7Vm4fTnk0LeQtAzapqo+MzR//nE3yfm5Ea2G6aOy544/HTfV5nIsRvPP9OwJwGu33+M9oLchb0Lo9TNkQWIPW2jm6rw6m7Z9N5/Fvkm4jHN2pBVNVv03ybVqH9Neu4NO3pf13+/iq+v3pEZKsP7aNnwDPHPq/PQp4G3Bkks2q6qaq+i7wpKEfz+OAd9JaLB6+sq+LFj7XTXLnGYLaH9BaFp5cVb/vjzfUsDLOpw2xH7cJrWVlVU21Bpwww7x3DvcvoH0hjxp/fNnwc2em/9I8fSXqu4x2WOxpsy1UVUfS3vv1af2B3k3rI7T7SmxzeS6gtQSNW+FQOPyevIvWH+t+tH9ELqMF/en6YF01zbRJnVzD6M6Zyhl7PMn7eQ2ttXj8MzrdZ3bU1KlvbjXAYCXM9+8IwDVVNTVY4btDf8J/SfLOqjqBtq9upPXru2ma518EMMHfpOu5+Z+BKeNBU7dRtqRpob0b2Hp8hBP8fiTUk2Z43lSguX5k+T9jGIk2rqp+W1Vfp/3B25SxjrhVdW1VfZHW4vaAFXsJt/L14efzZ5g/Xe33ov3xHjXpf/AnAE/MyAlmkzyMti+On+D5Mxr+g9+G1ul9+7Hb22nv3VbD4t8HnpLc4lQRTx1b5Xdp/ZruUVUnTnNbmYBxDK3l6jfTrXN84ar6dVV9gtZpe+q9njqP1cq0ZE7n+7R98/vDwUm2oYWCGSW50wxhfWofTwWhY2jnEDx1mtc8FXTn+jVNZ7nvZ7VTdJxCa8kc9YzlrPt0Wvi+1d+GEYv+OzKL/wAuoQ2ygPZ3YQ1g/Rn21S3OpTbL36TzgPuPvI7bcfPAl5ksxGdBC8CWNC2oqvpikncCHx5GNn6B1ifjfrRRa2cz/ejP/xmW+2CSt9Na1fal/VEH2ikQaB2LP0UbLXVX2h/MH1bVZUl2ovX7+TytD849gRdzc8ha2dd0eto53v5j6Af3TVoofFZV7U4b3HDeMP91tNGmbxytffATYJO001f8iNYx+OxpNvlO2oi7ryV5G60T/Ftp/bA+uyqvhdZSdhNt8MQtTmia5Me0Q82701p03kb7MvxkkoNoXyQvGha/CaCqrkg7dcJ7hmD6Tdo/h/cBtq+qlTlx8dG0QRdHD6//VFp/oIcAa1fVq5O8mNb6+lXgV7TQsyut0zZVdUOSs4DdkvyIdnqJ/12JWqYcRGsd/lKSN9KC+Rtphzuna0WZcl/aqNQDaSN+rxlex2toQWcqULyTNmL560n2o312NqH1HTx+6Nd2Di1A7Znk18Bvpwutq2IF3s9/BT6X5P20cPwYYKZ/wKbWfVPaqTw+nuTjtH6QRQskhw6vpYffkZnqv2ZoAX1TkvsMfxc+QPv9eDttoMHatLB9n6r6qwn/Jh0O7J3kZNrftb+ifd5nM++fBS2QxR654G1p3mjDzY+l9de4gTbM/h0MI8mYfpTdk2h/mK+lfaHuSBuB9plh/sa04es/p33pXkD7Q7/FMP++tNMynEtr1ToP+AC3HDF3Nis4unOYtgbtqgQ/H17PecBBI/MfRhvxdi1wxrDeg7nliLS1aV/2FzEyKnB8uWHaQ2l/yK+h9an5BK1PETPtv5nWNTb/R7QO1zPN/zK3HPW5G3DmsL+Ppx2uKeBpY897Lu0w07XA5bRw9/IJPyu3GN05TLsDLQSdOezvC2iBbKdh/rbAkbSAdh3ttAhvA+4wso4nDJ+j66bWP91+G/9MzPK5+CNa0Lqe1ir0NNrn+t2zvLa70kZGnkA73HcNLYi8jZHP5bDsVKf6C4dtnE07ZcQDR5Z5zrDNGxhOtTbDdm9V/zTLHMfwuzXNvOW+n8BLaL8H1wyfmycwy+jOkWnPGNZ93bBPjgTu1cvvyGzL0MLT5cD+w+PQrq5y6vCeXQx8A3j+CvxNWg84hHb49ALaPwP7MsvozhX5LHjr+5bhzZSkVZbkubSgfO+qOmux61lMSbakfUnuVVVzMWJR0hJjSJO00obDWUfTWg/+mPZf/rerasEuUN6LJK+mtdz9gjbS79W085Ddr2YY+StJs7FPmqRVcTfgfcPPS2n9AVfpkk+rsaJd1PoetENX3wJeaUCTtLJsSZMkSeqQp+CQJEnq0G3ucOeGG25Yy5YtW+wyJEmSluukk066pKqmPfH1bS6kLVu2jBNP9HQwkiSpf0l+MdM8D3dKkiR1yJAmSZLUIUOaJElShwxpkiRJHTKkSZIkdciQJkmS1CFDmiRJUocMaZIkSR0ypEmSJHXIkCZJktQhQ5okSVKHDGmSJEkdMqRJkiR1yJAmSZLUIUOaJElShwxpkiRJHTKkSZIkdciQJkmS1CFDmiRJUocMaZIkSR0ypEmSJHVoQUNakgOTXJTkRyPTNkhydJIzhp93HZn36iRnJjk9yRMXslZJkqTFtNAtaQcDTxqbtg9wTFVtBRwzPCbJA4DdgQcOz3lfkjUWrlRJkqTFs6Ahraq+CVw2NnkX4JDh/iHA00amf7Kqrq+qs4AzgW0Wok5JkqTFtuZiFwBsUlXnA1TV+Uk2HqbfE/ifkeXOG6bdSpK9gL0Atthii3ks9WbL9jlyQbazWM5+606LXYIkSUtazwMHMs20mm7Bqjqgqrauqq032mijeS5LkiRp/vUQ0i5MsinA8POiYfp5wOYjy20G/GqBa5MkSVoUPYS0I4A9h/t7Al8Ymb57kjsk2RLYCvjeItQnSZK04Ba0T1qSQ4HtgA2TnAe8AXgr8OkkLwTOAXYFqKpTk3wa+DFwI7B3Vf1uIeuVJElaLAsa0qpqjxlm7TDD8m8B3jJ/FUmSJPWph8OdkiRJGmNIkyRJ6pAhTZIkqUOGNEmSpA71cMUBacHd1q8YAV41QpJWd7akSZIkdciQJkmS1CFDmiRJUocMaZIkSR0ypEmSJHXIkCZJktQhQ5okSVKHDGmSJEkdMqRJkiR1yJAmSZLUIUOaJElShwxpkiRJHTKkSZIkdciQJkmS1CFDmiRJUocMaZIkSR0ypEmSJHXIkCZJktQhQ5okSVKHDGmSJEkdMqRJkiR1yJAmSZLUIUOaJElShwxpkiRJHTKkSZIkdciQJkmS1CFDmiRJUocMaZIkSR0ypEmSJHXIkCZJktQhQ5okSVKHDGmSJEkdMqRJkiR1yJAmSZLUIUOaJElShwxpkiRJHTKkSZIkdciQJkmS1CFDmiRJUocMaZIkSR0ypEmSJHXIkCZJktQhQ5okSVKHDGmSJEkdMqRJkiR1yJAmSZLUIUOaJElShwxpkiRJHTKkSZIkdciQJkmS1CFDmiRJUocMaZIkSR0ypEmSJHXIkCZJktQhQ5okSVKHDGmSJEkdMqRJkiR1yJAmSZLUIUOaJElShwxpkiRJHTKkSZIkdciQJkmS1CFDmiRJUocMaZIkSR0ypEmSJHXIkCZJktQhQ5okSVKHDGmSJEkdMqRJkiR1yJAmSZLUIUOaJElShwxpkiRJHVpzsQuQpJWxbJ8jF7uEeXf2W3da7BIkLSJb0iRJkjpkSJMkSeqQIU2SJKlDhjRJkqQOGdIkSZI6ZEiTJEnqkCFNkiSpQ4Y0SZKkDhnSJEmSOmRIkyRJ6pAhTZIkqUOGNEmSpA4Z0iRJkjpkSJMkSeqQIU2SJKlDhjRJkqQOGdIkSZI61E1IS/IPSU5N8qMkhyZZO8kGSY5Ocsbw866LXackSdJC6CKkJbkn8PfA1lX1IGANYHdgH+CYqtoKOGZ4LEmSdJvXRUgbrAmsk2RN4I7Ar4BdgEOG+YcAT1uc0iRJkhZWFyGtqn4JvAM4Bzgf+HVVHQVsUlXnD8ucD2w83fOT7JXkxCQnXnzxxQtVtiRJ0rzpIqQNfc12AbYE7gGsm+S5kz6/qg6oqq2rauuNNtpovsqUJElaMF2ENOBxwFlVdXFV/Rb4HPBnwIVJNgUYfl60iDVKkiQtmF5C2jnAw5PcMUmAHYDTgCOAPYdl9gS+sEj1SZIkLag1F7sAgKo6IclngB8ANwInAwcA6wGfTvJCWpDbdfGqlCRJWjhdhDSAqnoD8IaxydfTWtUkSZKWlF4Od0qSJGmEIU2SJKlDhjRJkqQOGdIkSZI6ZEiTJEnqkCFNkiSpQ4Y0SZKkDhnSJEmSOmRIkyRJ6pAhTZIkqUOGNEmSpA4Z0iRJkjpkSJMkSeqQIU2SJKlDhjRJkqQOGdIkSZI6ZEiTJEnqkCFNkiSpQ4Y0SZKkDhnSJEmSOmRIkyRJ6pAhTZIkqUOGNEmSpA4Z0iRJkjpkSJMkSeqQIU2SJKlDhjRJkqQOGdIkSZI6ZEiTJEnqkCFNkiSpQ4Y0SZKkDhnSJEmSOmRIkyRJ6pAhTZIkqUOGNEmSpA4Z0iRJkjq05mIXIElampbtc+RilzCvzn7rTotdglZztqRJkiR1yJAmSZLUIUOaJElShwxpkiRJHTKkSZIkdciQJkmS1CFDmiRJUocMaZIkSR0ypEmSJHXIkCZJktQhQ5okSVKHDGmSJEkdMqRJkiR1aM1JFkryAGAHYBvg7sDawGXAT4HjgaOq6tr5KlKSJGmpmbElLc3zk3wf+BGwL7AZcAXwC2AN4MnAZ4ELkhyQZMt5r1iSJGkJmK0l7bTh50eB51XVT6ZbKMkdgScCuwL/l+Svq+pjc1umJEnS0jJbSHst8NmqqtlWUFXXAIcDhyfZjNbaJkmSpFUwY0irqs+s6Mqq6jzgvFWqSJIkSZMNHBiXZCPaIIIAJ1TVxXNalSRJ0hK3wiEtydOAQ2gjO9cFtkjyvKo6fI5rkyRJWrJW5jxpbwd2rKqHVdUDgH8B/mNuy5IkSVraZjsFx0lJHjnNrPWAM0ce/3yYJkmSpDky2+HO9wCHJvkO8MqqOneYfiBwfJLDgTsCewD7z2+ZkiRJS8uMLWlV9RHgvrRWs1OSvDHJOlX1WuAVtIB3A/CXVfXPC1KtJEnSEjHrwIHhHGivSfJBWl+0nyZ5VVV9AjhiIQqUJElaiiYaOFBVZ1fVbsBzgVcm+W6Sh81vaZIkSUvXjC1pSW4H/CXweOD2wPeB/YA/Af4KOCLJUcCrquqCBahVkiRpyZitJe0/gdcDJwHHAE8Djqrmg8B9gIuBHyWxT5okSdIcmq1P2p8Dz62qLwMk+QzwyyT3rqqfV9VVtEOf+wPvWIBaJUmSlozZWtJ+CWw/8ngH4He01rPfq6ozqmqXeahNkiRpyZqtJe3FtPOkvYh2qo3bAy8eWtAkSZI0j2YMaVX1nST/j3autNsDP62qqxesMkmSpCVseedJuxE4dYFqkSRJ0mC2a3e+Lsn6K7KyJI9N8pRVL0uSJGlpm60lbRvg3CRfAD4DfKeqbjFoIMlawB8CTwaeDWwE7DlPtUqSpI4s2+fIxS5hXp391p0Wdfuz9Ul7SpI/Bf4O+ASwdpJLgEuA64G7APcA1qIdEj0QOGC4lJQkSZJWwfL6pJ0AnJBkPeARwB8DdwfWBi4DTge+XVVnzHehkiRJS8msIW1KVf0G+NpwkyRJ0jyb6ALrkiRJWliGNEmSpA4Z0iRJkjpkSJMkSeqQIU2SJKlDE4W0JCcm+dskd53vgiRJkjR5S9qpwNuAXyX5VJInJMk81iVJkrSkTRTSqmpP2kls9x5+fhU4J8lbkmw1j/VJkiQtSRP3Sauqq6vqwKp6DLAVcBDwHOAnSb6Z5AVJ1p6vQiVJkpaSlR04cBNQw/3fAQHeB5yd5PFzUZgkSdJSNnFIS3LHJHsmORY4A3g2LZhtXlWPAjYDvg7sPy+VSpIkLSGTju78MHAB8F7gF8D2VXW/qnp7VV0IUFWXAe8Bls1TrZIkSUvGRBdYB/4QeCVwaFVdNctypwLbr3JVkiRJS9xEIa2qtplwud8A31iliiRJkjTx4c7dk/zjDPNemWS3uS1LkiRpaZt04MCrgetmmHfNMF+SJElzZNKQ9gfAj2aYdxrtvGmSJEmaI5OGtGtop9iYzubA9XNTjiRJkmDykPbfwOuSbDw6MclGwGuAo+a6MEmSpKVs0pD2KmA94GdJDkvyn0kOA34GrAP806oWkuQuST6T5CdJTkuybZINkhyd5Izh511XdTuSJEmrg0kvsH4O8EfAf9EObz55+Lkf8MdVde4c1PIe4KtVdb9hW6cB+wDHVNVWwDHDY0mSpNu8SU9mS1VdzDyN4kxyZ+DRwAuGbd0A3JBkF2C7YbFDgONorXqSJEm3aSt7gfW5dm/gYuCgJCcn+VCSdYFNqup8gOHnxtM9OcleSU5McuLFF1+8cFVLkiTNkxW5wPqzk/x3knOSXDR+W8U61gT+GHh/VT0UuJoVOLRZVQdU1dZVtfVGG220iqVIkiQtvkmvOPDntMONZ9JOxXEE8KXh+VfS+qqtivOA86rqhOHxZ2ih7cIkmw41bAqsahiUJElaLUzakvaPwJuAvYfH76uqvwS2BC6hnUdtpVXVBcC5Se47TNoB+DEtDO45TNsT+MKqbEeSJGl1MenAga2Ab1fV75L8DrgzQFVdleRtwLuAd6xiLX8HfDzJ7YGfA39BC5GfTvJC4Bxg11XchiRJ0mph0pD2a+AOw/1fAvenjbQECHC3VS2kqk4Btp5m1g6rum5JkqTVzaQh7UTgwcDXaIcgX5/kRuAG4PXACbM8V5IkSSto0pD2b8C9hvuvH+6/D1gD+D6w19yXJkmStHRNFNKq6n+A/xnuXwHskuQOwB2q6sr5K0+SJGlpWu7oziRrJ7k+ydNGp1fV9QY0SZKk+bHckFZV19HOT3bj/JcjSZIkmPw8afsDf59krfksRpIkSc2kAwfuAjwIODvJMcCFQI3Mr6rywueSJElzZNKQ9kzg+uH+o6aZX4AhTZIkaY5MOrpzy/kuRJIkSTebtE+aJEmSFtBELWlJ/nZ5y1TV+1a9HEmSJMHkfdL+a5Z5UwMIDGmSJElzZKLDnVV1u/EbsAGwB/BD4AHzWaQkSdJSM2lL2q0Ml4f6VJL1aedR226OapIkSVry5mLgwFnA1nOwHkmSJA1WKaQl2RR4BS2oSZIkaY5MOrrzYm55hQGA2wN3Aq4DnjHHdUmSJC1pk/ZJey+3DmnXAecBX62qS+e0KkmSpCVu0isO7DvPdUiSJGnERH3SkvxRkh1nmLdjkgfPbVmSJElL26QDB94F/OkM8x42zJckSdIcmTSk/THw7RnmfRd46NyUI0mSJJg8pK0BrDvDvHVpIz0lSZI0RyYNad8H9pph3l7AiXNTjiRJkmDyU3DsC/x3khOAQ4ALgE2B5wN/BDx+XqqTJElaoiY9Bcc3kzwB+DdgPyDATcAJwOOr6lvzV6IkSdLSM/EF1qvqOGDbJHcE7gpcXlXXzFdhkiRJS9mkl4W6E7BeVZ0/BLNrRuZtClxVVb+ZpxolSZKWnElb0j4M/Bp40TTz9gXWB3afo5okSZKWvElHdz4aOHKGeV8e5kuSJGmOTBrS1mfkEOeY62h91CRJkjRHJg1pZwA7zTBvR+Bnc1OOJEmSYPI+afsBH0hyA3AwcD7tPGl7AnsDfzMv1UmSJC1Rk54n7YNJNgFeDbx8ZNZ1wGur6oPzUZwkSdJStSLnSXtzkv2AbYG7AZcC362qX89XcZIkSUvVxCENYAhkX516nGTdJM8B/ryqZuqzJkmSpBW0QiENIMntaYMF9gB2BtYBTp3juiRJkpa0Sa84cDtgB1owezrtlBwFfBR4T1WdPG8VSpIkLUGzhrQkf0YLZrsCGwFXAJ+hncD2s8CBBjRJkqS5N2NIS3I2sDlwNfBF4FDga1X12yTrL0x5kiRJS9NsLWlbDD//DzgW+HZV/Xb+S5IkSdJsVxy4N/Aa4E7AAcAFSb40jOa800IUJ0mStFTNGNKq6uyq+reqejDwh8A7gPvRBgucSRs48LAkay1IpZIkSUvIRNfurKpTq+o1VfUHtJPZfgC4APh3Wgvb++exRkmSpCVn0gus/15VnVBVLwM2Ax4HfA7YbY7rkiRJWtJWOKRNqebrVfUiYJM5rEmSJGnJW+mQNqqqbpyL9UiSJKmZk5AmSZKkuWVIkyRJ6pAhTZIkqUOGNEmSpA7NeoH1UUm2Bp5BO/XG2mOzq6qePZeFSZIkLWUThbQkfwP8F3ApcAZww3wWJUmStNRN2pL2SuAg4K893YYkSdL8m7RP2sbAoQY0SZKkhTFpSPsK8KfzWYgkSZJuNunhzvcCByRZCzgauGJ8gar68RzWJUmStKRNGtKOHX6+AXj92LwABawxV0VJkiQtdZOGtO3ntQpJkiTdwkQhraq+Md+FSJIk6WYTn8wWIMmfAo8ENgAuA46vqhPmozBJkqSlbNKT2a4LHAY8CbiRdlLbuwFrJPkqsGtVXTNvVUqSJC0xk56C4+3AtsCzgbWralPapaF2H6a/bX7KkyRJWpomDWnPBF5VVYdV1U0AVXVTVR0G7APsOl8FSpIkLUWThrT1gXNnmHcucOe5KUeSJEkweUj7IfA3STI6cXj8N8N8SZIkzZFJR3f+M+3SUD9JcjhwIe16nk8HlgFPnpfqJEmSlqhJz5P29SQPpV1tYFdgU+B84ATgGV4SSpIkaW5NfJ60IYjtPo+1SJIkaTBpnzRJkiQtoBlb0pJ8Gnh1Vf1suD+bqqpnz21pkiRJS9dshzs3AtYa7m8M1PyXI0mSJJglpFXV9iP3t1uQaiRJkgRM2CctyeuT3GOGeZsmef3cliVJkrS0TTpw4A3AZjPMu8cwX5IkSXNk0pAWZu6Tthlw+dyUI0mSJJh9dOeewJ7DwwLen+TKscXWBv4QOGp+ypMkSVqaZhvdeQ1w6XA/wK+By8aWuYF2uaj3zX1pkiRJS9dsozsPAw4DSHIQ8C9VddZCFSZJkrSUTdon7aXAddPNGEZ3rjd3JUmSJGnSa3d+iHa480XTzNsXWB+v6ylJkjRnJm1JezRw5AzzvjzMlyRJ0hyZNKStTxtIMJ3rgLvOTTmSJEmCyUPaGcBOM8zbEfjZ3JQjSZIkmLxP2n7AB5LcABwMnA9sSjuP2t7A38xLdZIkSUvURCGtqj6YZBPg1cDLR2ZdB7y2qj44H8VJkiQtVZO2pFFVb06yH7AtcDfaiW6/W1W/nq/iJEmSlqqJQxrAEMi+Ok+1SJIkaTDbtTt3BI6vqiuH+7Oqqi/PaWWSJElL2GwtaV8CHg58b7hftGt4TqeANea2NEmSpKVrtpC2JW0U59R9SZIkLZDZLrD+i+nuS5Ikaf7N1idtixVZUVWds+rlSJIkCWY/3Hk2ra/ZpOyTJkmSNEdmC2lPGbl/Z+DtwGnA54CLgI2BZwL3A/5xvgqUJElaimbrk3bk1P0kBwNfqqrxyz99IMkHaNf1/OSqFpNkDeBE4JdVtXOSDYBPActoLXu7VdXlq7odSZKk3k16gfVn0FrQpvNZ4KlzUw4vpbXWTdkHOKaqtgKOGR5LkiTd5k0a0q4FHjnDvEfRruG5SpJsRmuR+9DI5F2AQ4b7hwBPW9XtSJIkrQ4mvSzU+4HXJbkbcAQ390nbBXgx8JY5qOXdwD8BdxqZtklVnQ9QVecn2Xi6JybZC9gLYIstVmhQqiRJUpcmCmlVtW+Sy2kh6m+5+eoDFwCvrKp3r0oRSXYGLqqqk5Jst6LPr6oDgAMAtt566xUZkSpJktSliS+wXlXvSbIfsAWwCS2gnVtVN81BHY8AnjpcI3Rt4M5JPgZcmGTToRVtU1oLniRJ0m3epH3SABgC2S+Ac2kjMOcioFFVr66qzapqGbA78PWqei7t0Oqew2J7Al+Yi+1JkiT1buKQlmTHJCfQBgmcAzx4mH5AkufOU31vBR6f5Azg8cNjSZKk27yJQlqS59NatX5C66A/+rwzgBfOVUFVdVxV7Tzcv7SqdqiqrYafl83VdiRJkno2aUvaa4B/r6o9gY+NzTsVeMCcViVJkrTETRrS7gUcPcO862iXjZIkSdIcmTSknQs8dIZ5WwNnzk05kiRJgslD2oeBNwwDBNYZpiXJDrRzp31wPoqTJElaqiY9T9rbgM1pl2b63TDtO8AawP5V9Z/zUJskSdKSNekVBwrYO8k7gR2ADYHLaOcz++k81idJkrQkLTekJVkb+DXw7Kr6PPCz+S5KkiRpqVtun7Squo52OaYb578cSZIkweQDB/YH/j7JWvNZjCRJkppJBw7cBXgQcHaSY4ALgRqZX1X1qjmuTZIkacmaNKQ9E7h+uP+oaeYXYEiTJEmaI5OO7txyvguRJEnSzWYNaUnWAXYElgHnA8dU1YULUJckSdKSNmNIS3Jv4L9pAW3KlUl2q6qj5rswSZKkpWy20Z1vB26i9UG7I/BA4GTaSE9JkiTNo9lC2rbAa6vq21V1XVWdBrwY2CLJpgtTniRJ0tI0W0jbFPj52LSfAQHuPm8VSZIkabkns63lzJckSdI8WN4pOL6WZLrLQR0zPr2qNp67siRJkpa22ULaGxesCkmSJN3CjCGtqgxpkiRJi2TSC6xLkiRpARnSJEmSOmRIkyRJ6pAhTZIkqUOGNEmSpA4Z0iRJkjpkSJMkSeqQIU2SJKlDhjRJkqQOGdIkSZI6ZEiTJEnqkCFNkiSpQ4Y0SZKkDhnSJEmSOmRIkyRJ6pAhTZIkqUOGNEmSpA4Z0iRJkjpkSJMkSeqQIU2SJKlDhjRJkqQOGdIkSZI6ZEiTJEnqkCFNkiSpQ4Y0SZKkDhnSJEmSOmRIkyRJ6pAhTZIkqUOGNEmSpA4Z0iRJkjpkSJMkSeqQIU2SJKlDhjRJkqQOGdIkSZI6ZEiTJEnqkCFNkiSpQ4Y0SZKkDhnSJEmSOmRIkyRJ6pAhTZIkqUOGNEmSpA4Z0iRJkjpkSJMkSeqQIU2SJKlDhjRJkqQOGdIkSZI6ZEiTJEnqkCFNkiSpQ4Y0SZKkDhnSJEmSOmRIkyRJ6pAhTZIkqUOGNEmSpA4Z0iRJkjpkSJMkSeqQIU2SJKlDhjRJkqQOGdIkSZI6ZEiTJEnqkCFNkiSpQ4Y0SZKkDhnSJEmSOmRIkyRJ6pAhTZIkqUOGNEmSpA4Z0iRJkjpkSJMkSeqQIU2SJKlDhjRJkqQOGdIkSZI6ZEiTJEnqkCFNkiSpQ4Y0SZKkDnUR0pJsnuTYJKclOTXJS4fpGyQ5OskZw8+7LnatkiRJC6GLkAbcCLyiqu4PPBzYO8kDgH2AY6pqK+CY4bEkSdJtXhchrarOr6ofDPevAk4D7gnsAhwyLHYI8LRFKVCSJGmBdRHSRiVZBjwUOAHYpKrOhxbkgI1neM5eSU5McuLFF1+8YLVKkiTNl65CWpL1gM8CL6uqKyd9XlUdUFVbV9XWG2200fwVKEmStEC6CWlJ1qIFtI9X1eeGyRcm2XSYvylw0WLVJ0mStJC6CGlJAnwYOK2q3jky6whgz+H+nsAXFro2SZKkxbDmYhcweATwPOD/kpwyTPtn4K3Ap5O8EDgH2HVxypMkSVpYXYS0qjoeyAyzd1jIWiRJknrQxeFOSZIk3ZIhTZIkqUOGNEmSpA4Z0iRJkjpkSJMkSeqQIU2SJKlDhjRJkqQOGdIkSZI6ZEiTJEnqkCFNkiSpQ4Y0SZKkDhnSJEmSOmRIkyRJ6pAhTZIkqUOGNEmSpA4Z0iRJkjpkSJMkSeqQIU2SJKlDhjRJkqQOGdIkSZI6ZEiTJEnqkCFNkiSpQ4Y0SZKkDhnSJEmSOmRIkyRJ6pAhTZIkqUOGNEmSpA4Z0iRJkjpkSJMkSeqQIU2SJKlDhjRJkqQOGdIkSZI6ZEiTJEnqkCFNkiSpQ4Y0SZKkDhnSJEmSOmRIkyRJ6pAhTZIkqUOGNEmSpA4Z0iRJkjpkSJMkSeqQIU2SJKlDhjRJkqQOGdIkSZI6ZEiTJEnqkCFNkiSpQ4Y0SZKkDhnSJEmSOmRIkyRJ6pAhTZIkqUOGNEmSpA4Z0iRJkjpkSJMkSeqQIU2SJKlDhjRJkqQOGdIkSZI6ZEiTJEnqkCFNkiSpQ4Y0SZKkDhnSJEmSOmRIkyRJ6pAhTZIkqUOGNEmSpA4Z0iRJkjpkSJMkSeqQIU2SJKlDhjRJkqQOGdIkSZI6ZEiTJEnqkCFNkiSpQ4Y0SZKkDhnSJEmSOmRIkyRJ6pAhTZIkqUOGNEmSpA4Z0iRJkjpkSJMkSeqQIU2SJKlDhjRJkqQOGdIkSZI6ZEiTJEnqkCFNkiSpQ4Y0SZKkDhnSJEmSOmRIkyRJ6pAhTZIkqUOGNEmSpA4Z0iRJkjpkSJMkSeqQIU2SJKlDhjRJkqQOGdIkSZI6ZEiTJEnqkCFNkiSpQ4Y0SZKkDq0WIS3Jk5KcnuTMJPssdj2SJEnzrfuQlmQN4L3Ak4EHAHskecDiViVJkjS/ug9pwDbAmVX186q6AfgksMsi1yRJkjSvUlWLXcOskjwLeFJV/dXw+HnAn1bVS0aW2QvYa3h4X+D0BS90/m0IXLLYRWiV+B6u3nz/Vn++h6u/2+J7eK+q2mi6GWsudCUrIdNMu0WyrKoDgAMWppzFkeTEqtp6sevQyvM9XL35/q3+fA9Xf0vtPVwdDneeB2w+8ngz4FeLVIskSdKCWB1C2veBrZJsmeT2wO7AEYtckyRJ0rzq/nBnVd2Y5CXA14A1gAOr6tRFLmsx3KYP5y4RvoerN9+/1Z/v4epvSb2H3Q8ckCRJWopWh8OdkiRJS44hTZIkqUOGtM55SazVX5IDk1yU5EeLXYtWXJLNkxyb5LQkpyZ56WLXpBWTZO0k30vyw+E9fONi16QVl2SNJCcn+dJi17JQDGkd85JYtxkHA09a7CK00m4EXlFV9wceDuzt7+Fq53rgsVX1R8BDgCclefjilqSV8FLgtMUuYiEZ0vrmJbFuA6rqm8Bli12HVk5VnV9VPxjuX0X7krjn4lalFVHNb4aHaw03R82tRpJsBuwEfGixa1lIhrS+3RM4d+TxefjlIC2aJMuAhwInLHIpWkHDobJTgIuAo6vK93D18m7gn4CbFrmOBWVI69tyL4klaWEkWQ/4LPCyqrpysevRiqmq31XVQ2hXrdkmyYMWuSRNKMnOwEVVddJi17LQDGl985JYUgeSrEULaB+vqs8tdj1aeVV1BXAc9hNdnTwCeGqSs2ndfh6b5GOLW9LCMKT1zUtiSYssSYAPA6dV1TsXux6tuCQbJbnLcH8d4HHATxa1KE2sql5dVZtV1TLa9+DXq+q5i1zWgjCkdayqbgSmLol1GvDpJXpJrNVakkOB7wL3TXJekhcudk1aIY8Ankf77/2U4bbjYhelFbIpcGyS/6X983t0VS2Z0zho9eVloSRJkjpkS5okSVKHDGmSJEkdMqRJkiR1yJAmSZLUIUOaJElShwxp0hKS5qwkleQPFqmG2yX5iyTfSnJFkhuSnJ3kQ0kevBg1rawkz0xyZpI1FruWhTC8T+9YzjIPGj5f2w2P10lyUZJHLUSN0m2JIU1aWrYFlg33d1/ojSe5HfBp4P3AD4DnAo8H3gLcD/jh6hJ4htfyRuDfq+p3i11Pr6rqWmA/4E2LXYu0ujGkSUvLHsDVtAuE77EI2/874OnATlX10qr6UlV9o6o+WFWPBF4025OHs8X3Ygfg/wGfWOxCpnS2f0YdDDw6yR8udiHS6sSQJi0RQwvVrrRLix0IPGC6w4tJtkvyv0muS/L9JNskuSTJvmPL7ZLkxGG5C5K8fbjG5WxeBny2qo6ZbmZVfWiqVSrJsuGw2XOSfCTJFcAXh3lbJvl8kiuTXJXki6OHb0eeu/NYzQcnOXHk8b7Da3tEkh8Mr+WUJI9czusA2BM4qqquGta1wfD8Pce2OXWI+Z0j0x6U5Mih9quSHJbk7iPz103yX0lOT3LN8Pz3Jrnz2LorycuTvDvJxcD/DdMfORxOvnK4nZJk19leTJINkxyS5NJhm8cl2Xp5OyHJ3yY5N8nVSb5IO7v/LVTVubQz/T9/eeuTdDNDmrR0PBbYhHaB4s8Av2WsNS3JPYEvAxcBzwL2Bz4OrDO23G7A54DvAU+lHfbbC/i3mTaeZHPaodajVrDudwBX0QLmvya5A3AMcH9ay9sLgC2BbyTZYAXXDXBH4GPAB4ZtXAF8ZTQ0zeCxwHemHlTVZcDhwF+MLbcd7XUfBDCEyW8Da9MuN/UC4IHAF5NkpKY1gNcATwZeN2zvsGnq+EdaMHoe8PdDkPsS8HPgmbT38aPAXZbzej4PPBF4JfBs2vfDsbP1XUyyC/DeYXvPoIXEA2dY/Du0a2ZKmlRVefPmbQncaF+elwO3Hx4fCZzFcHm4Ydq/A5cA64xM2w0oYN/hcYBfAAeNrf8vgWuBu82w/T8d1vPEsem3A9YcuU1drm7ZsPzhY8v/NXAjcO+RaZsBNwCvHnvuzmPPPRg4ceTxvsNyfz4ybT3gMuCts+zLewzP22ls+uOAm8Zq+8jYNj8KnD71PgzTtgJ+N76+kflr0q4hWsAWI9MLOHls2a2H6Xdagc/Gk4bnPGZk2rrAxcD+I9POBt4x8vh7wFfG1vXBYV3bjU1/wfC+rb3YvwvevK0uN1vSpCVgaH16Oi3w3DBMPpQWZh4+sujDaBefvnZk2hFjq7sPsAXw6SRrTt2Ar9Nahx40UxnDz/ELBv8nrVVv6rbT2Pwjxx5vA/ygqn4+NaGqzqO1Tk1ymHI6h4+s6zfA0cN2ZjLVynbJ2PRjaAF2T4Akd6K1MB00sszjhu3dNLLvzqIFoN8fXkzyvCQnJ/kNbb8cP8y6z9g2x/fPz4DfAJ8YDknfZZbXMWUb4OKq+sbUhKq6mtZCNu0+HQ6fPxT4wtisz82wjUtorYMbTVCPJDzcKS0VT6Yd7vpykrsMX9zHAddzy0Oed6e1nvxeVV1H+9KfsuHw88vcMlydNUzffIYafjn83Gxs+ttp4fCpMzzvwrHHm04zbWq5lTnc+ZuxUArtcO+t+laNWHv4ef3oxKoqWiDbczh0uRutFWx0cMGGwKu45b77LXBvhn2X5Om0Frjv0g7BPpwWske3PeUW+6KqLgeeAKxFG0l78dD/7d6zvJ6V2acbDa/torHp44+nTO2r8folzWDNxS5A0oKYCmLT9WnaLck/VOuwfwFjLR1J1qYdApxy2fBzL+DkadZ31jTTqKpzk5xNCxAHjkw/BzgnybIZah9veTuf1odr3CYjtV03/Lz92DLTBY71kqwzFtQ2HrYzk6nt3GWaeQcBbwC2px3i+/wQnEafezjwoWmeO9UytytwQlX97dSMJI+ZoZbx/UNVfRd40jDa83HAO2lB8eHjyw7Op73mcaP7dNzFtMOX48+bbj1w876aaX2SxtiSJt3GJVkP2Jl2eHP7sdvLaV/E2w+Lfx94/NipHMZbuE6ntYotq6oTp7ldOks57waeleFEpyvpBOBPkmw5NWEY8PBn3HxI8CJa69T9R5ZZj3aeuOk8fWy5x9P6W83kLFofuC3HZ1QbyXgUbTDFI7nloU5oh0QfBJw0zb47e1hmHcZa6YDnzFLPtKrq2qr6IsNo3lkWPQHYOMmjpyYkuSPt0PPx0z1hCPWnALuMzXrGDNtYBly6nM+HpBG2pEm3fbvQRgu+p6pOGJ2R5Nu0EYR7AP9NC1F700Yavot2+HMf4Bpah3iq6qYkrwA+Oowk/AotsNwbeBrwrKq6ZoZa9gMeTRs9uT+t79dVtNaXZw3LXL2c13Mw7XDhV5K8ntbhfl9aK9T+IzV+AfiHJL+gjdh8BW1gw7hrgbcM4exXtNGNtwfeM1MBVXV9kpOAP+HWIQzgw7RWy/OG1zhqX1oAPDLJgUPd96QFw4Or6rjhOe9N8hpagNqRdl625UqyE20Qx+eBc4Z1v5jWZ3Cm1/O14bPwqST7AJfS9sM6tMEkM/lX4HNJ3k9rHXwMbRDCdLZmZDSspAks9sgFb968ze+N1vn7p7PMfx9t1OcdhsfbA/9La8k5BXgU7fDhy8ae92TgW7RQdeWw7JuBNZdTz+1oIeL44Xk30DrNfxTYdmS5ZUwzQnOYd29aCLmK1l/uS8BWY8tsQuvUfiWtM/9eTD+685LhNZ4yvOYfAo+eYL++Ejhzhnlr01ry3jzD/PvRToNyGS0knkkLmJsN89egnXrkoqH+z3Lz6NidR9ZTwEvG1n3fYd3nDq/nPNrpRTZYzuvZiNYP7vKhpm8ADxtb5mxGRncO014ybOMaWj/FJzA2upPWIHAJsOdi/z5487Y63aaGukvStIYTu34LeGxVHbvY9cyltBP0vqSqNlzestM8dxNaS9Ujq+r7Y/N2pAXH+1TVmXNR6+osyRNpgxjuUW3UqKQJeLhT0i0keRttQMAFtFaZ19Fa1r4x2/OWmqq6MMmHgJfSrkFKknvQznn2VuDLBrTf+wfgXQY0acU4cEDSuDvQ+iEdRetz9C3gSVV106JW1ac3Aafl5ovC70UbGHAd7TqlS94wCOW7tBGmklaAhzslSZI6ZEuaJElShwxpkiRJHTKkSZIkdciQJkmS1CFDmiRJUof+P2rGkjeme72eAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.bar([0, 1, 2, 3, 4], res[:5], width=0.5)\n",
    "print(res)\n",
    "plt.title('Classification Age Testing Set Prediction Result', fontsize=15)\n",
    "plt.xlabel('Age Group (years old)', fontsize=15)\n",
    "plt.ylabel('Prediction Accuracy (%)', fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BWX3Gh-xZJsK",
    "jupyter": {
     "source_hidden": true
    },
    "outputId": "ae737ab4-67c0-4df7-8ca2-9ccc141dbcc2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 23.   1.   0.   0.   0.]\n",
      " [  0. 398.  13.   0.   0.]\n",
      " [  0.   7. 210.   7.   0.]\n",
      " [  0.   0.  23.  56.   7.]\n",
      " [  0.   0.   4.  15.  13.]]\n"
     ]
    }
   ],
   "source": [
    "print(cm)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
